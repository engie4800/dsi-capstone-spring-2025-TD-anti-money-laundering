{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD:  c:\\repos\\dsi-capstone-spring-2025-TD-anti-money-laundering\\Code\\notebooks\\Sophie\n",
      "content_base:  c:\\repos\\dsi-capstone-spring-2025-TD-anti-money-laundering\\Code\n",
      "data_dir:  c:\\repos\\dsi-capstone-spring-2025-TD-anti-money-laundering\\Code\\data\n",
      "src_path  c:\\repos\\dsi-capstone-spring-2025-TD-anti-money-laundering\\Code\\src\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n",
    "from IPython import get_ipython\n",
    "from IPython.display import display\n",
    "from time import monotonic\n",
    "from pprint import pprint\n",
    "\n",
    "# GNNs \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, EdgeConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Project Source Code\n",
    "cwd = os.getcwd()\n",
    "content_base = os.path.dirname(os.path.dirname(cwd))\n",
    "data_dir = os.path.join(content_base, \"data\")\n",
    "src_path = os.path.join(content_base, \"src\")\n",
    "sys.path.append(src_path)\n",
    "from helpers import add_cell_timer\n",
    "from pipeline import ModelPipeline\n",
    "\n",
    "print(\"CWD: \", cwd)\n",
    "print(\"content_base: \", content_base)\n",
    "print(\"data_dir: \", data_dir)\n",
    "print(\"src_path \", src_path)\n",
    "\n",
    "add_cell_timer()\n",
    "\n",
    "data_file = os.path.join(data_dir, \"HI-XS.csv\") # random strat 10% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Running preprocessing pipeline<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Running preprocessing pipeline\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preprocessing completed successfully!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Preprocessing completed successfully!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'renamed'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'duplicates_removed'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'unique_ids_created'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'currency_normalized'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'time_features_extracted'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cyclical_encoded'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'weekend_encoded'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'features_encoded'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'neighbor_context_computed'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'normalized'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'renamed'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'duplicates_removed'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'unique_ids_created'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'currency_normalized'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'time_features_extracted'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'cyclical_encoded'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'weekend_encoded'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'features_encoded'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[32m'neighbor_context_computed'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[32m'normalized'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ Execution time: 10.22s\n"
     ]
    }
   ],
   "source": [
    "# Initialize pipeline with dataset\n",
    "pl = ModelPipeline(data_file)\n",
    "pl.run_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'renamed': True,\n",
       " 'duplicates_removed': True,\n",
       " 'unique_ids_created': True,\n",
       " 'currency_normalized': True,\n",
       " 'time_features_extracted': True,\n",
       " 'cyclical_encoded': True,\n",
       " 'weekend_encoded': True,\n",
       " 'features_encoded': False,\n",
       " 'neighbor_context_computed': False,\n",
       " 'normalized': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ Execution time: 0.02s\n"
     ]
    }
   ],
   "source": [
    "pl.preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['from_bank', 'to_bank', 'received_amount', 'received_currency',\n",
       "       'sent_amount', 'sent_currency', 'payment_type', 'is_laundering',\n",
       "       'from_account_id', 'to_account_id', 'from_account_idx',\n",
       "       'to_account_idx', 'sent_amount_usd', 'received_amount_usd',\n",
       "       'hour_of_day', 'day_of_week', 'seconds_since_midnight', 'timestamp_int',\n",
       "       'timestamp_scaled', 'day_sin', 'day_cos', 'time_of_day_sin',\n",
       "       'time_of_day_cos', 'is_weekend'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ Execution time: 0.02s\n"
     ]
    }
   ],
   "source": [
    "pl.df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ Execution time: 18.95s\n"
     ]
    }
   ],
   "source": [
    "pl.apply_label_encoding([\"received_currency\", \"sent_currency\", \"payment_type\"])\n",
    "pl.extract_graph_features(weight_col= 'sent_amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ Execution time: 0.48s\n"
     ]
    }
   ],
   "source": [
    "X_cols = ['from_bank', 'to_bank', 'received_amount', 'received_currency',\n",
    "       'sent_amount', 'sent_currency', 'payment_type',\n",
    "       'from_account_id', 'to_account_id', 'from_account_idx',\n",
    "       'to_account_idx', 'sent_amount_usd', 'received_amount_usd',\n",
    "       'hour_of_day', 'day_of_week', 'seconds_since_midnight', 'timestamp_int',\n",
    "       'timestamp_scaled', 'day_sin', 'day_cos', 'time_of_day_sin',\n",
    "       'time_of_day_cos', 'is_weekend']\n",
    "y_col = 'is_laundering'\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = pl.split_train_test_val(X_cols, y_col, test_size=0.15, val_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[355483, 17], edge_index=[2, 355483], y=[355483]),\n",
       " Data(x=[76175, 17], edge_index=[2, 76175], y=[76175]),\n",
       " Data(x=[76176, 17], edge_index=[2, 76176], y=[76176]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ Execution time: 0.09s\n"
     ]
    }
   ],
   "source": [
    "edge_features = ['received_amount', 'received_currency','sent_amount', 'sent_currency', \n",
    "                 'payment_type','sent_amount_usd', 'received_amount_usd', 'hour_of_day', \n",
    "                 'day_of_week', 'seconds_since_midnight', 'timestamp_int', 'timestamp_scaled', \n",
    "                 'day_sin', 'day_cos', 'time_of_day_sin', 'time_of_day_cos', 'is_weekend']\n",
    "pl.generate_tensors(edge_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.apply_label_encoding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ Execution time: 0.05s\n"
     ]
    }
   ],
   "source": [
    "def generate_tensors(X, y, edge_features, edges = [\"from_account_idx\", \"to_account_idx\"]):\n",
    "    \"\"\"Convert data to PyTorch tensor format for GNNs\"\"\"\n",
    "\n",
    "    # Edge index (defining graph structure)\n",
    "    edge_index = torch.tensor(X[edges].values.T, dtype=torch.long)  # Shape: [2, num_edges]\n",
    "\n",
    "    # Edge attributes (transaction-based features)\n",
    "    edge_attr = torch.tensor(X[edge_features].values, dtype=torch.float)  # Shape: [num_edges, num_features]\n",
    "\n",
    "    # Labels for edges (transaction classification: laundering or not)\n",
    "    edge_labels = torch.tensor(y.values, dtype=torch.long)  # Shape: [num_edges]\n",
    "\n",
    "    # Create PyG Data object\n",
    "    data = Data(edge_index=edge_index, edge_attr=edge_attr, y=edge_labels)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Assuming X_train, y_train are preprocessed dataframes\n",
    "train_data = generate_tensors(X_train, y_train, edge_features=[\"sent_amount\", \"received_amount\", \"day_of_week\"])\n",
    "val_data = generate_tensors(X_val, y_val, edge_features=[\"sent_amount\", \"received_amount\", \"day_of_week\"])\n",
    "test_data = generate_tensors(X_test, y_test, edge_features=[\"sent_amount\", \"received_amount\", \"day_of_week\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sophi\\anaconda3\\envs\\capstone_env\\lib\\site-packages\\torch_geometric\\data\\storage.py:452: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'y', 'edge_attr', 'edge_index'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [355483, 3] but got: [355483, 32].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m model \u001b[38;5;241m=\u001b[39m EdgeGNN(in_edge_dim\u001b[38;5;241m=\u001b[39mtrain_data\u001b[38;5;241m.\u001b[39medge_attr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Forward Pass (Example)\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEdge Predictions Shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, out\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Should be [num_edges, num_classes]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sophi\\anaconda3\\envs\\capstone_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sophi\\anaconda3\\envs\\capstone_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[19], line 44\u001b[0m, in \u001b[0;36mEdgeGNN.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((data\u001b[38;5;241m.\u001b[39mnum_nodes, data\u001b[38;5;241m.\u001b[39medge_attr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), device\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39medge_attr\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Apply NNConv layers to update node representations using edge features\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrelu()\n\u001b[0;32m     45\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39medge_attr)\u001b[38;5;241m.\u001b[39mrelu()\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Gather source & destination node representations\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sophi\\anaconda3\\envs\\capstone_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sophi\\anaconda3\\envs\\capstone_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\sophi\\anaconda3\\envs\\capstone_env\\lib\\site-packages\\torch_geometric\\nn\\conv\\nn_conv.py:108\u001b[0m, in \u001b[0;36mNNConv.forward\u001b[1;34m(self, x, edge_index, edge_attr, size)\u001b[0m\n\u001b[0;32m    105\u001b[0m     x \u001b[38;5;241m=\u001b[39m (x, x)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_weight:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\torch_geometric.nn.conv.nn_conv_NNConv_propagate_66stshn6.py:183\u001b[0m, in \u001b[0;36mpropagate\u001b[1;34m(self, edge_index, x, edge_attr, size)\u001b[0m\n\u001b[0;32m    174\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m CollectArgs(\n\u001b[0;32m    175\u001b[0m                 x_j\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_j\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    176\u001b[0m                 edge_attr\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_attr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mdim_size,\n\u001b[0;32m    180\u001b[0m             )\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# End Message Forward Pre Hook #########################################\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_j\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_j\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# Begin Message Forward Hook ###########################################\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[1;32mc:\\Users\\sophi\\anaconda3\\envs\\capstone_env\\lib\\site-packages\\torch_geometric\\nn\\conv\\nn_conv.py:122\u001b[0m, in \u001b[0;36mNNConv.message\u001b[1;34m(self, x_j, edge_attr)\u001b[0m\n\u001b[0;32m    120\u001b[0m weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn(edge_attr)\n\u001b[0;32m    121\u001b[0m weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_channels_l, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channels)\n\u001b[1;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_j\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [355483, 3] but got: [355483, 32]."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ Execution time: 1.8s\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "# Node-level GNN for embedding learning\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(GNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        return x\n",
    "\n",
    "# Edge-level classifier using dot product similarity\n",
    "class Classifier(torch.nn.Module):\n",
    "    def forward(self, node_embeddings, edge_index):\n",
    "        src, dest = edge_index  # Extract node indices for each edge\n",
    "        \n",
    "        # Compute dot product between source and destination node embeddings\n",
    "        return (node_embeddings[src] * node_embeddings[dest]).sum(dim=-1)\n",
    "\n",
    "# Full Model Combining GNN and Edge Classification\n",
    "class EdgeGNN(torch.nn.Module):\n",
    "    def __init__(self, in_edge_dim, hidden_dim):\n",
    "        super(EdgeGNN, self).__init__()\n",
    "        \n",
    "        # Node embeddings initialized randomly\n",
    "        self.node_emb = torch.nn.Embedding(num_embeddings=data.num_nodes, embedding_dim=hidden_dim)\n",
    "        \n",
    "        # GNN for learning node representations\n",
    "        self.gnn = GNN(hidden_dim)\n",
    "        \n",
    "        # Edge Classifier\n",
    "        self.classifier = Classifier()\n",
    "\n",
    "    def forward(self, data):\n",
    "        # Initialize node embeddings\n",
    "        x = self.node_emb.weight  # Learnable node embeddings\n",
    "        \n",
    "        # Update node embeddings using GNN\n",
    "        x = self.gnn(x, data.edge_index)\n",
    "        \n",
    "        # Compute edge-level predictions\n",
    "        return self.classifier(x, data.edge_index)\n",
    "\n",
    "# Model Initialization\n",
    "model = EdgeGNN(in_edge_dim=data.edge_attr.shape[1], hidden_dim=32)\n",
    "\n",
    "# Forward Pass (Example)\n",
    "out = model(data)\n",
    "print(\"Edge Predictions Shape:\", out.shape)  # Should be [num_edges]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hetero graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A heterogeneous graph with two types of nodes—**transactions** and **accounts**—can be structured such that **edges represent relationships** between them (e.g., an account initiates a transaction, a transaction is received by an account). Given this setup, we can develop a **Graph Neural Network (GNN)-based framework** to classify transaction nodes and identify suspicious activity.\n",
    "\n",
    "---\n",
    "\n",
    "### **Proposed Framework for Transaction Node Classification**\n",
    "#### **1. Graph Construction**\n",
    "- **Nodes**\n",
    "  - **Transaction Nodes (T)**: Represent individual financial transactions.\n",
    "  - **Account Nodes (A)**: Represent entities that send or receive transactions.\n",
    "- **Edges**\n",
    "  - **(A → T)**: Account initiates a transaction.\n",
    "  - **(T → A)**: Transaction is received by an account.\n",
    "  - **(A ↔ A)**: Accounts that frequently transact with each other (optional, for richer context).\n",
    "  - **(T ↔ T)**: Similar transactions (e.g., same amount, time window, or recipient).\n",
    "\n",
    "#### **2. Node and Edge Feature Engineering**\n",
    "- **Transaction Node Features**\n",
    "  - Amount, time, location, type of transaction\n",
    "  - Statistical features (e.g., frequency of transactions, deviation from mean transaction amount)\n",
    "  - Relationship-based features (e.g., how often a sender has sent transactions of similar size)\n",
    "- **Account Node Features**\n",
    "  - Account type (individual, corporate, etc.)\n",
    "  - Transaction history (e.g., total volume, count of unique counterparties)\n",
    "  - Risk score (if available from previous AML checks)\n",
    "- **Edge Features**\n",
    "  - Time difference between linked transactions\n",
    "  - Relationship strength (e.g., frequency of interaction)\n",
    "\n",
    "#### **3. Model Architecture**\n",
    "- **Heterogeneous Graph Neural Network (HGNN)**\n",
    "  - **Relational Graph Convolutional Network (R-GCN)** to handle different node and edge types.\n",
    "  - **Heterogeneous Graph Transformer (HGT)** for learning cross-type interactions.\n",
    "  - **Graph Attention Network (GAT)** for capturing important transaction flows.\n",
    "\n",
    "- **Hierarchical Message Passing**\n",
    "  - **Step 1:** Transactions receive signals from linked accounts to encode account behavior.\n",
    "  - **Step 2:** Transactions aggregate information from similar transactions to detect patterns.\n",
    "  - **Step 3:** Accounts update their embeddings based on transaction patterns.\n",
    "  - **Step 4:** Final transaction embeddings are passed through a classifier.\n",
    "\n",
    "#### **4. Training and Classification**\n",
    "- **Supervised Learning**\n",
    "  - Labels: Suspicious vs. non-suspicious transactions.\n",
    "  - Loss function: Binary cross-entropy for classification.\n",
    "- **Semi-Supervised Learning**\n",
    "  - Use a small set of labeled suspicious transactions and propagate risk signals through the graph.\n",
    "- **Self-Supervised Learning**\n",
    "  - Contrastive learning to learn transaction representations based on normal vs. anomalous transaction patterns.\n",
    "\n",
    "#### **5. Post-processing and Risk Scoring**\n",
    "- Once transaction nodes are classified, assign a **risk score** based on:\n",
    "  - Model confidence in classification\n",
    "  - Proximity to high-risk accounts\n",
    "  - Transaction anomaly score\n",
    "\n",
    "---\n",
    "\n",
    "### **Advantages of This Framework**\n",
    "✅ **Captures contextual dependencies**: Uses account behavior and transaction relationships.  \n",
    "✅ **Flexible to new patterns**: Can adapt to changes in laundering methods.  \n",
    "✅ **Graph augmentation**: Can incorporate external data like blacklists or known fraud networks.\n",
    "\n",
    "Would you like help implementing any specific part of this in Python? 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ Execution time: 0.11s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "bank_encoder = LabelEncoder()\n",
    "from_banks = pl.df[\"from_bank\"].drop_duplicates().reset_index(drop=True)\n",
    "to_banks = pl.df[\"to_bank\"].drop_duplicates().reset_index(drop=True)\n",
    "all_banks = pd.concat([from_banks, to_banks]).drop_duplicates().reset_index(drop=True)\n",
    "bank_encoder.fit(all_banks)\n",
    "pl.df[\"from_bank\"] = bank_encoder.transform(pl.df[\"from_bank\"]) # Use same encoder\n",
    "pl.df[\"to_bank\"] = bank_encoder.transform(pl.df[\"to_bank\"])  # Use same encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.utils import from_networkx\n",
    "import networkx as nx\n",
    "\n",
    "def construct_heterogeneous_graph(df):\n",
    "    \"\"\"\n",
    "    Constructs a heterogeneous graph from the preprocessed dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the heterogeneous data object\n",
    "    data = HeteroData()\n",
    "\n",
    "    # Extract unique accounts and transactions\n",
    "    transaction_nodes = df.index  # Assuming each row is a unique transaction\n",
    "    \n",
    "    # Create mappings for indexing\n",
    "    transaction_mapping = {idx: idx for idx in transaction_nodes}\n",
    "    df[\"transaction_idx\"] = df.index.map(transaction_mapping)\n",
    "\n",
    "    # Account nodes\n",
    "    data[\"account\"].x = torch.tensor(df.groupby(\"from_account_id\").mean()[[\"degree_centrality\", \"pagerank\"]].values, dtype=torch.float)\n",
    "\n",
    "    # Transaction nodes\n",
    "    transaction_features = [\"sent_amount_usd\", \"received_amount_usd\", \"hour_of_day\", \"is_weekend\"]\n",
    "    data[\"transaction\"].x = torch.tensor(df[transaction_features].values, dtype=torch.float)\n",
    "\n",
    "    # Edges from account → transaction (initiates)\n",
    "    edge_index_initiates = torch.tensor([df[\"from_account_idx\"].values, df[\"transaction_idx\"].values], dtype=torch.long)\n",
    "    data[\"account\", \"initiates\", \"transaction\"].edge_index = edge_index_initiates\n",
    "\n",
    "    # Edges from transaction → account (received_by)\n",
    "    edge_index_received_by = torch.tensor([df[\"transaction_idx\"].values, df[\"to_account_idx\"].values], dtype=torch.long)\n",
    "    data[\"transaction\", \"received_by\", \"account\"].edge_index = edge_index_received_by\n",
    "\n",
    "    # Labels for transaction classification (1 = laundering, 0 = normal)\n",
    "    data[\"transaction\"].y = torch.tensor(df[\"is_laundering\"].values, dtype=torch.long)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Construct the heterogeneous graph\n",
    "hetero_graph = construct_heterogeneous_graph(ModelPipeline(\"your_dataset.csv\").df)\n",
    "print(hetero_graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GINe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GINEConv, BatchNorm, Linear, GATConv, PNAConv, RGCNConv\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "class GINe(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_gnn_layers, n_classes=2, \n",
    "                n_hidden=100, edge_updates=False, residual=True, \n",
    "                edge_dim=None, dropout=0.0, final_dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.num_gnn_layers = num_gnn_layers\n",
    "        self.edge_updates = edge_updates\n",
    "        self.final_dropout = final_dropout\n",
    "\n",
    "        self.node_emb = nn.Linear(num_features, n_hidden)\n",
    "        self.edge_emb = nn.Linear(edge_dim, n_hidden)\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.emlps = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        for _ in range(self.num_gnn_layers):\n",
    "            conv = GINEConv(nn.Sequential(\n",
    "                nn.Linear(self.n_hidden, self.n_hidden), \n",
    "                nn.ReLU(), \n",
    "                nn.Linear(self.n_hidden, self.n_hidden)\n",
    "                ), edge_dim=self.n_hidden)\n",
    "            if self.edge_updates: self.emlps.append(nn.Sequential(\n",
    "                nn.Linear(3 * self.n_hidden, self.n_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(self.n_hidden, self.n_hidden),\n",
    "            ))\n",
    "            self.convs.append(conv)\n",
    "            self.batch_norms.append(BatchNorm(n_hidden))\n",
    "\n",
    "        self.mlp = nn.Sequential(Linear(n_hidden*3, 50), nn.ReLU(), nn.Dropout(self.final_dropout),Linear(50, 25), nn.ReLU(), nn.Dropout(self.final_dropout),\n",
    "                              Linear(25, n_classes))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        src, dst = edge_index\n",
    "\n",
    "        x = self.node_emb(x)\n",
    "        edge_attr = self.edge_emb(edge_attr)\n",
    "\n",
    "        for i in range(self.num_gnn_layers):\n",
    "            x = (x + F.relu(self.batch_norms[i](self.convs[i](x, edge_index, edge_attr)))) / 2\n",
    "            if self.edge_updates: \n",
    "                edge_attr = edge_attr + self.emlps[i](torch.cat([x[src], x[dst], edge_attr], dim=-1)) / 2\n",
    "\n",
    "        x = x[edge_index.T].reshape(-1, 2 * self.n_hidden).relu()\n",
    "        x = torch.cat((x, edge_attr.view(-1, edge_attr.shape[1])), 1)\n",
    "        out = x\n",
    "        \n",
    "        return self.mlp(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
