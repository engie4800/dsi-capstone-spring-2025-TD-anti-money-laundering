{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Practice GNN"
      ],
      "metadata": {
        "id": "mCZwI-Z2ZQCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook configuration"
      ],
      "metadata": {
        "id": "U5njmE3R1nPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from tabulate import tabulate\n",
        "from tqdm import trange\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "from time import monotonic\n",
        "from pprint import pprint\n",
        "from google.colab import drive\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.nn import BCEWithLogitsLoss, Sequential, Linear, ReLU\n",
        "!pip install torch-geometric\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, EdgeConv, GINEConv\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "!pip install torchmetrics\n",
        "from torchmetrics.classification import Recall, Accuracy, AUROC, Precision\n",
        "\n",
        "content_base = \"/content/drive\"\n",
        "drive.mount(content_base)\n",
        "\n",
        "# Project data\n",
        "data_dir = os.path.join(content_base, \"My Drive/Capstone/data\")\n",
        "data_file = os.path.join(data_dir, \"HI-Small_Trans.csv\")\n",
        "\n",
        "# # Project Source Code\n",
        "# src_path = os.path.join(content_base, \"My Drive/Capstone/src\")\n",
        "# sys.path.append(src_path)\n",
        "# from helpers import add_cell_timer\n",
        "# from pipeline import ModelPipeline\n",
        "\n",
        "# add_cell_timer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rlo9F0NmZ04j",
        "outputId": "f8d9b713-f9c4-4f34-e745-9c460a1def74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.13)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.6.2)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.5.1+cu124)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colaboratory executes in an environment with a file system\n",
        "# that has a Linux topography, but where the user should work under\n",
        "# the `/content` directory\n",
        "COLAB_ROOT = \"/content\"\n",
        "\n",
        "REPO_URL = \"https://github.com/engie4800/dsi-capstone-spring-2025-TD-anti-money-laundering.git\"\n",
        "REPO_ROOT = os.path.join(COLAB_ROOT, REPO_URL.split(\"/\")[-1].split(\".\")[0])\n",
        "REPO_BRANCH = \"sophie\"\n",
        "\n",
        "# Clones the repository at `/content/dsi-capstone-spring-2025-TD-anti-money-laundering`\n",
        "if not os.path.exists(REPO_ROOT):\n",
        "  os.chdir(COLAB_ROOT)\n",
        "  !git clone {REPO_URL}\n",
        "\n",
        "# Pulls the latest code from the provided branch and adds the\n",
        "# analysis pipeline source code to the Python system path\n",
        "os.chdir(REPO_ROOT)\n",
        "!git pull\n",
        "!git checkout {REPO_BRANCH}\n",
        "sys.path.append(os.path.join(REPO_ROOT, \"Code/src\"))\n",
        "os.chdir(COLAB_ROOT)"
      ],
      "metadata": {
        "id": "TXY9iPVgflc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e0c3cec-e180-4154-ffd8-e81ac77d9c85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dsi-capstone-spring-2025-TD-anti-money-laundering'...\n",
            "remote: Enumerating objects: 431, done.\u001b[K\n",
            "remote: Counting objects: 100% (266/266), done.\u001b[K\n",
            "remote: Compressing objects: 100% (163/163), done.\u001b[K\n",
            "remote: Total 431 (delta 151), reused 177 (delta 94), pack-reused 165 (from 1)\u001b[K\n",
            "Receiving objects: 100% (431/431), 27.67 MiB | 15.09 MiB/s, done.\n",
            "Resolving deltas: 100% (191/191), done.\n",
            "Already up to date.\n",
            "Branch 'sophie' set up to track remote branch 'sophie' from 'origin'.\n",
            "Switched to a new branch 'sophie'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helpers import add_cell_timer\n",
        "from pipeline import ModelPipeline\n",
        "add_cell_timer()"
      ],
      "metadata": {
        "id": "CrlM3wUFj_EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "Guq15nJi1hSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize pipeline with dataset\n",
        "pl = ModelPipeline(data_file)\n",
        "pl.run_preprocessing()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "pSS_Z8FTZ2kj",
        "outputId": "14773910-0654-4e90-8482-219b61894c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running preprocessing pipeline\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Running preprocessing pipeline<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Preprocessing completed successfully!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preprocessing completed successfully!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'renamed'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'duplicates_removed'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'unique_ids_created'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'currency_normalized'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'time_features_extracted'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'cyclical_encoded'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'weekend_encoded'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'features_encoded'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
              "    \u001b[32m'neighbor_context_computed'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
              "    \u001b[32m'normalized'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'renamed'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'duplicates_removed'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'unique_ids_created'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'currency_normalized'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'time_features_extracted'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'cyclical_encoded'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'weekend_encoded'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'features_encoded'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'neighbor_context_computed'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'normalized'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 98.73s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "bank_encoder = LabelEncoder()\n",
        "from_banks = pl.df[\"from_bank\"].drop_duplicates().reset_index(drop=True)\n",
        "to_banks = pl.df[\"to_bank\"].drop_duplicates().reset_index(drop=True)\n",
        "all_banks = pd.concat([from_banks, to_banks]).drop_duplicates().reset_index(drop=True)\n",
        "bank_encoder.fit(all_banks)\n",
        "pl.df[\"from_bank\"] = bank_encoder.transform(pl.df[\"from_bank\"]) # Use same encoder\n",
        "pl.df[\"to_bank\"] = bank_encoder.transform(pl.df[\"to_bank\"])  # Use same encoder"
      ],
      "metadata": {
        "id": "WBOIotQOp8PO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b3d5bfd-6812-4eae-efb6-fbb61eaa6bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.78s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def encode_from_to(df, colfrom, colto):\n",
        "  encoder = LabelEncoder()\n",
        "  from_unique = df[colfrom].drop_duplicates().reset_index(drop=True)\n",
        "  to_unique = df[colto].drop_duplicates().reset_index(drop=True)\n",
        "  all_unique = pd.concat([from_unique, to_unique]).drop_duplicates().reset_index(drop=True)\n",
        "  encoder.fit(all_unique)\n",
        "  df[colfrom] = encoder.transform(df[colfrom])\n",
        "  df[colto] = encoder.transform(df[colto])\n",
        "  return df, encoder\n",
        "\n",
        "pl.df, _ = encode_from_to(pl.df, \"from_bank\", \"to_bank\")\n",
        "pl.df, _ = encode_from_to(pl.df, \"sent_currency\", \"received_currency\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU2Ccet1rHfw",
        "outputId": "80ecd22c-7913-4007-ca5f-ab98a24718d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 2.14s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pl.apply_label_encoding([\"payment_type\",\"day_of_week\"])\n",
        "pl.extract_graph_features(weight_col=\"sent_amount\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jF4FF2fcsI-U",
        "outputId": "04c5dfd5-13b3-40bf-e6d8-bfe3e80b9034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 214.55s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_cols = ['from_bank', 'to_bank', 'received_amount', 'received_currency',\n",
        "#        'sent_amount', 'sent_currency', 'payment_type',\n",
        "#        'from_account_id', 'to_account_id', 'from_account_idx',\n",
        "#        'to_account_idx', 'sent_amount_usd', 'received_amount_usd',\n",
        "#        'hour_of_day', 'day_of_week', 'seconds_since_midnight', 'timestamp_int',\n",
        "#        'timestamp_scaled', 'day_sin', 'day_cos', 'time_of_day_sin',\n",
        "#        'time_of_day_cos', 'is_weekend']\n",
        "\n",
        "X_cols = ['from_account_idx', 'to_account_idx','received_amount', 'sent_amount',\n",
        "          'sent_currency', 'payment_type','day_of_week','timestamp_int']\n",
        "y_col = 'is_laundering'\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = pl.split_train_test_val(X_cols, y_col, test_size=0.15, val_size=0.15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt5KgjWAs__t",
        "outputId": "6be2ba70-3d3b-4839-c258-6b26463fb49f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 3.3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# edge_features = ['received_amount', 'received_currency','sent_amount', 'sent_currency',\n",
        "#                  'payment_type','sent_amount_usd', 'received_amount_usd', 'hour_of_day',\n",
        "#                  'day_of_week', 'seconds_since_midnight', 'timestamp_int']\n",
        "# edge_features = ['received_amount', 'received_currency','sent_amount', 'sent_currency',\n",
        "#                  'payment_type','sent_amount_usd', 'received_amount_usd', 'hour_of_day',\n",
        "#                  'day_of_week', 'seconds_since_midnight', 'timestamp_int', 'timestamp_scaled',\n",
        "#                  'day_sin', 'day_cos', 'time_of_day_sin', 'time_of_day_cos', 'is_weekend']\n",
        "edge_features = ['received_amount', 'sent_amount', 'sent_currency',\n",
        "                 'payment_type','day_of_week','timestamp_int']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m463oljUtClk",
        "outputId": "5f130224-dbba-4f62-f1f4-e9121f17756f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_tensors(X, y, edge_features, edges = [\"from_account_idx\", \"to_account_idx\"]):\n",
        "    \"\"\"Convert data to PyTorch tensor format for GNNs\"\"\"\n",
        "\n",
        "    # Edge index (defining graph structure)\n",
        "    edge_index = torch.tensor(X[edges].values.T, dtype=torch.long)  # Shape: [2, num_edges]\n",
        "\n",
        "    # Edge attributes (transaction-based features)\n",
        "    edge_attr = torch.tensor(X[edge_features].values, dtype=torch.float)  # Shape: [num_edges, num_features]\n",
        "\n",
        "    # Labels for edges (transaction classification: laundering or not)\n",
        "    edge_labels = torch.tensor(y.values, dtype=torch.long)  # Shape: [num_edges]\n",
        "\n",
        "    # Infer number of nodes based on highest index in edge_index\n",
        "    num_nodes = edge_index.max().item() + 1  # Ensure it captures all nodes\n",
        "\n",
        "    # Create PyG Data object\n",
        "    data = Data(edge_index=edge_index, edge_attr=edge_attr, y=edge_labels, num_nodes=num_nodes)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Assuming X_train, y_train are preprocessed dataframes\n",
        "train_data = generate_tensors(X_train, y_train, edge_features)\n",
        "val_data = generate_tensors(X_val, y_val, edge_features)\n",
        "test_data = generate_tensors(X_test, y_test, edge_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XvFGVCttaPk",
        "outputId": "f983bb3a-2c97-453a-c79c-edd2935306ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.28s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = generate_tensors(pl.df[X_cols], pl.df[y_col], edge_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2xXwxzuUhkn",
        "outputId": "b6bf6ab7-a51f-400f-d80a-10cc4ef949f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.47s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GNNs"
      ],
      "metadata": {
        "id": "XYsAXFzI4fGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cannot use GCN or GAT!\n",
        "\n",
        "* The Graph Convolutional Network (GCN), implemented with `GCNConv`, only aggregates features from neighboring nodes and does not use edge attributes in its message passing.\n",
        "* Graph Attention Networks (GAT), implemented with `GATConv`, allows edge attention weights, which can indirectly incorporate edge attributes. Problem: If all nodes have the same feature vector (e.g., initialized to 1), then the computed attention scores will be the same for all edges. We'd need to modify GAT to use edge features meaningfully in the attention computation.\n",
        "\n",
        "`GINeConv`\n",
        "* Directly includes edge attributes in message passing using an MLP-based edge transformation.\n",
        "\n",
        "`EdgeConv`\n",
        "* dynamically computes edge embeddings and updates node features based on edges\n",
        "\n"
      ],
      "metadata": {
        "id": "ZykVSu2wzzra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GINeConv\n",
        "\n",
        "Modified GINConv that includes edge features in message passing.\n",
        "Update rule is:\n",
        "h (l+1) = h (l) + sum (MLP(h(l + e\n"
      ],
      "metadata": {
        "id": "jW94nuYtwism"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If on GPU, do as below\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK8WuSjbAUHO",
        "outputId": "50caa270-9ce1-4d59-9d4b-3473ab01aecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "\n",
            "⏱️ Execution time: 0.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EdgeGINE(nn.Module):\n",
        "    def __init__(self, n_node_feats, n_edge_feats, n_hidden=64):\n",
        "        super(EdgeGINE, self).__init__()\n",
        "\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_node_feats = n_node_feats\n",
        "        self.n_edge_feats = n_edge_feats\n",
        "\n",
        "        # MLP to embed node and edges\n",
        "        self.node_emb = nn.Linear(self.n_node_feats, self.n_hidden)\n",
        "        self.edge_emb = nn.Linear(self.n_edge_feats, self.n_hidden)\n",
        "\n",
        "        # MLP that processes edge features, passed into GINEConv\n",
        "        nn_edge = Sequential(Linear(self.n_hidden, self.n_hidden), ReLU(), Linear(self.n_hidden, self.n_hidden))\n",
        "\n",
        "        # Two GINEConv layers using nn_edge when it needs to process edge attributes\n",
        "        self.gine1 = GINEConv(nn_edge, edge_dim=self.n_hidden, train_eps=True)\n",
        "        self.gine2 = GINEConv(nn_edge, edge_dim=self.n_hidden, train_eps=True)\n",
        "\n",
        "        # MLP for edge classification\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(3 * self.n_hidden, 128), # src, dest, edge\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        \"\"\"\n",
        "        x: Node features (or placeholder embeddings if None)\n",
        "        edge_index: Edge list (2, n_edges)\n",
        "        edge_attr: Edge features (n_edges, self.n_edge_feats)\n",
        "        \"\"\"\n",
        "        if x is None:  # If no node features, use trainable embeddings\n",
        "            x = torch.ones((edge_index.max().item() + 1, 1), device=device)\n",
        "\n",
        "        x = self.node_emb(x) # MLP\n",
        "        edge_attr = self.edge_emb(edge_attr) # MLP\n",
        "        x, edge_attr, edge_index = x.to(device), edge_attr.to(device), edge_index.to(device)\n",
        "\n",
        "        # Pass nodes and edges through GINE layers\n",
        "        x = self.gine1(x, edge_index, edge_attr)\n",
        "        x = F.relu(x)\n",
        "        x = self.gine2(x, edge_index, edge_attr)\n",
        "\n",
        "        # Get output for classification\n",
        "        src, dest = edge_index\n",
        "        src_embed = x[src]\n",
        "        dest_embed = x[dest]\n",
        "\n",
        "        edge_inputs = torch.cat([src_embed, dest_embed, edge_attr], dim=1)\n",
        "        edge_logits = self.mlp(edge_inputs).squeeze(1)\n",
        "\n",
        "        return edge_logits\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuOv1oly1FYf",
        "outputId": "783e223d-0398-4063-da6b-fc5d05c57528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import AveragePrecision\n",
        "\n",
        "# Move data to GPU if using\n",
        "train_data = train_data.to(device)\n",
        "val_data = val_data.to(device)\n",
        "test_data = test_data.to(device)\n",
        "all_data = all_data.to(device)\n",
        "\n",
        "# Create DataLoader (batch size=1 because we have one graph)\n",
        "all_loader = DataLoader([all_data], batch_size=1, shuffle=False)\n",
        "train_loader = DataLoader([train_data], batch_size=1, shuffle=True)\n",
        "val_loader = DataLoader([val_data], batch_size=1, shuffle=False)\n",
        "test_loader = DataLoader([test_data], batch_size=1, shuffle=False)\n",
        "\n",
        "# Create metrics\n",
        "accuracy = Accuracy(task=\"binary\").to(device) # 1/N sum(1(y=yhat))\n",
        "recall = Recall(task='binary').to(device) # TP / (TP+FN), or use BinaryRecall class?\n",
        "precision = Precision(task=\"binary\").to(device) # TP / (TP + FP)\n",
        "auroc = AUROC(task=\"binary\").to(device)\n",
        "pr_auc = AveragePrecision(task=\"binary\").to(device)\n",
        "\n",
        "# Initialize model & optimizer\n",
        "num_edge_features = len(edge_features)  # Your selected transaction features\n",
        "num_node_features = 1\n",
        "model = EdgeGINE(num_node_features, num_edge_features).to(device)\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# USe weighted BCE loss\n",
        "criterion = BCEWithLogitsLoss(pos_weight=torch.tensor([3], device=device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch8ZtyDR5qoS",
        "outputId": "7fa6a749-c0d8-44f1-d6dc-da26cf0514de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.01s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "def train(model, train_loader, optimizer, criterion, epochs=20):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        # Reset metrics\n",
        "        running_loss = 0.0\n",
        "        accuracy.reset(), recall.reset(), precision.reset(), auroc.reset(), pr_auc.reset()\n",
        "\n",
        "        for batch in train_loader:\n",
        "            batch = batch.to(device) # Batch to device\n",
        "            optimizer.zero_grad() # Zero gradients\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(batch.x, batch.edge_index, batch.edge_attr)\n",
        "            probs = torch.sigmoid(logits)  # Convert logits to probabilities\n",
        "            preds = (probs > 0.5).long()  # Convert to binary predictions\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(logits, batch.y.float())  # BCE expects float labels\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accumulate loss\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Update metrics\n",
        "            accuracy.update(preds, batch.y)\n",
        "            recall.update(preds, batch.y)\n",
        "            precision.update(preds, batch.y)\n",
        "            auroc.update(probs, batch.y)\n",
        "            pr_auc.update(probs, batch.y)\n",
        "\n",
        "        if epoch%100 == 0:\n",
        "          # Compute epoch-level metrics\n",
        "          epoch_acc = accuracy.compute()\n",
        "          epoch_recall = recall.compute()\n",
        "          epoch_precision = precision.compute()\n",
        "          epoch_auroc = auroc.compute()\n",
        "          epoch_pr_auc = pr_auc.compute()\n",
        "\n",
        "          print(f\"Epoch {epoch+1}/{epochs} | Loss: {running_loss / len(train_loader):.4f} | \"\n",
        "                f\"Acc: {epoch_acc:.4f} | Rec: {epoch_recall:.4f} | Prec: {epoch_precision:.4f} | AUROC: {epoch_auroc:.4f} | PR-AUC: {epoch_pr_auc:.4f} \")\n",
        "\n",
        "        # Validation loop\n",
        "        # validate(model, val_loader, criterion)\n",
        "\n",
        "# Validation loop\n",
        "def validate(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "\n",
        "    # Reset metrics\n",
        "    accuracy.reset(), recall.reset(), precision.reset(), auroc.reset(), pr_auc.reset()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            batch = batch.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(batch.x, batch.edge_index, batch.edge_attr)\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds = (probs > 0.5).long()\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(logits, batch.y.float())\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Update metrics\n",
        "            accuracy.update(preds, batch.y)\n",
        "            recall.update(preds, batch.y)\n",
        "            precision.update(preds, batch.y)\n",
        "            auroc.update(probs, batch.y)\n",
        "            pr_auc.update(probs, batch.y)\n",
        "\n",
        "    # Compute validation metrics\n",
        "    val_acc = accuracy.compute()\n",
        "    val_recall = recall.compute()\n",
        "    val_precision = precision.compute()\n",
        "    val_auroc = auroc.compute()\n",
        "    val_pr_auc = pr_auc.compute()\n",
        "\n",
        "    print(f\"             Val Loss: {val_loss / len(val_loader):.4f} | \"\n",
        "          f\"Acc: {val_acc:.4f} | Rec: {val_recall:.4f} | Prec: {val_precision:.4f} | AUROC: {val_auroc:.4f} | PR-AUC: {val_pr_auc:.4f} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf9W-jRoAnlc",
        "outputId": "6dc5ac98-c89c-4497-ea1c-3651c64ed2af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Training\n",
        "train(model, train_loader, optimizer, criterion, epochs=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "tbTIbJHtGA5i",
        "outputId": "ffed918d-062c-4395-9c42-ae476c421557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 868.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 512.12 MiB is free. Process 3056 has 14.24 GiB memory in use. Of the allocated memory 13.59 GiB is allocated by PyTorch, and 541.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-fd9b8ff403f1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-f85c605be4b2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion, epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert logits to probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to binary predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-c1458a5a8de3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Pass nodes and edges through GINE layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgine1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgine2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/gin_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, size)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# propagate_type: (x: OptPairTensor, edge_attr: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mx_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/torch_geometric.nn.conv.gin_conv_GINEConv_propagate_1lpalqua.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, edge_attr, size)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# End Message Forward Pre Hook #########################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         out = self.message(\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0mx_j\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_j\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0medge_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/gin_conv.py\u001b[0m in \u001b[0;36mmessage\u001b[0;34m(self, x_j, edge_attr)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0medge_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_j\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/dense/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 868.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 512.12 MiB is free. Process 3056 has 14.24 GiB memory in use. Of the allocated memory 13.59 GiB is allocated by PyTorch, and 541.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.1s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EdgeConv"
      ],
      "metadata": {
        "id": "uB5Q3ZL11Ve7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch_geometric.nn import EdgeConv\n",
        "# from torch.nn import Linear\n",
        "\n",
        "# class EdgeConvGNN(nn.Module):\n",
        "#     def __init__(self, num_node_features, self.n_edge_feats, self.n_hidden=64):\n",
        "#         super(EdgeConvGNN, self).__init__()\n",
        "\n",
        "#         self.edge_conv1 = EdgeConv(Sequential(Linear(2 * num_node_features, self.n_hidden), ReLU()))\n",
        "#         self.edge_conv2 = EdgeConv(Sequential(Linear(2 * self.n_hidden, self.n_hidden), ReLU()))\n",
        "\n",
        "#         self.mlp = nn.Sequential(\n",
        "#             nn.Linear(2 * self.n_hidden + self.n_edge_feats, 128),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(128, 64),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(64, 1),\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x, edge_index, edge_attr):\n",
        "#         x = selfself.n_hiddennv1(x, edge_index)\n",
        "#         x = F.relu(x)\n",
        "#         x = self.edge_conv2(x, edge_index)\n",
        "\n",
        "#         src, dest = edge_index\n",
        "#         src_embed = x[src]\n",
        "#         dest_embed = x[dest]\n",
        "\n",
        "#         edge_inputs = torch.cat([src_embed, dest_embed, edge_attr], dim=1)\n",
        "#         edge_logits = self.mlp(edge_inputs).squeeze(1)\n",
        "\n",
        "#         return edge_logits\n"
      ],
      "metadata": {
        "id": "GchXhxSS1YFs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}