{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Practice GNN"
      ],
      "metadata": {
        "id": "mCZwI-Z2ZQCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook configuration"
      ],
      "metadata": {
        "id": "U5njmE3R1nPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from tabulate import tabulate\n",
        "from tqdm import trange\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "from time import monotonic\n",
        "from pprint import pprint\n",
        "from google.colab import drive\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.nn import BCEWithLogitsLoss, Sequential, Linear, ReLU\n",
        "!pip install torch-geometric\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, EdgeConv, GINEConv\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "!pip install torchmetrics\n",
        "from torchmetrics.classification import Recall, Accuracy, AUROC, Precision\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "content_base = \"/content/drive\"\n",
        "drive.mount(content_base)\n",
        "\n",
        "# Project data\n",
        "data_dir = os.path.join(content_base, \"My Drive/Capstone/data\")\n",
        "data_file = os.path.join(data_dir, \"HI-Small_25.csv\")\n",
        "\n",
        "# # Project Source Code\n",
        "# src_path = os.path.join(content_base, \"My Drive/Capstone/src\")\n",
        "# sys.path.append(src_path)\n",
        "# from helpers import add_cell_timer\n",
        "# from pipeline import ModelPipeline\n",
        "\n",
        "# add_cell_timer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rlo9F0NmZ04j",
        "outputId": "c439441e-d447-4c18-d103-6601b7c28180"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.13)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.6.3)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.6.0+cu124)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colaboratory executes in an environment with a file system\n",
        "# that has a Linux topography, but where the user should work under\n",
        "# the `/content` directory\n",
        "COLAB_ROOT = \"/content\"\n",
        "\n",
        "REPO_URL = \"https://github.com/engie4800/dsi-capstone-spring-2025-TD-anti-money-laundering.git\"\n",
        "REPO_ROOT = os.path.join(COLAB_ROOT, REPO_URL.split(\"/\")[-1].split(\".\")[0])\n",
        "REPO_BRANCH = \"sophie\"\n",
        "\n",
        "# Clones the repository at `/content/dsi-capstone-spring-2025-TD-anti-money-laundering`\n",
        "if not os.path.exists(REPO_ROOT):\n",
        "  os.chdir(COLAB_ROOT)\n",
        "  !git clone {REPO_URL}\n",
        "\n",
        "# Pulls the latest code from the provided branch and adds the\n",
        "# analysis pipeline source code to the Python system path\n",
        "os.chdir(REPO_ROOT)\n",
        "!git pull\n",
        "!git checkout {REPO_BRANCH}\n",
        "sys.path.append(os.path.join(REPO_ROOT, \"Code/src\"))\n",
        "os.chdir(COLAB_ROOT)"
      ],
      "metadata": {
        "id": "TXY9iPVgflc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9ad64b2-e5d2-4ec8-fdbc-6dcd21371f40"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dsi-capstone-spring-2025-TD-anti-money-laundering'...\n",
            "remote: Enumerating objects: 507, done.\u001b[K\n",
            "remote: Counting objects: 100% (131/131), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 507 (delta 70), reused 72 (delta 44), pack-reused 376 (from 1)\u001b[K\n",
            "Receiving objects: 100% (507/507), 25.98 MiB | 16.34 MiB/s, done.\n",
            "Resolving deltas: 100% (237/237), done.\n",
            "Already up to date.\n",
            "Branch 'sophie' set up to track remote branch 'sophie' from 'origin'.\n",
            "Switched to a new branch 'sophie'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helpers import add_cell_timer\n",
        "from pipeline import ModelPipeline\n",
        "add_cell_timer()"
      ],
      "metadata": {
        "id": "CrlM3wUFj_EL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "Guq15nJi1hSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run initial full-dataset preprocessing"
      ],
      "metadata": {
        "id": "ZvOeaI31I97e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize pipeline with dataset\n",
        "pl = ModelPipeline(data_file)\n",
        "pl.run_preprocessing()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "pSS_Z8FTZ2kj",
        "outputId": "be85176a-7c6a-43e5-b480-2bf9827050fb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running preprocessing pipeline\u001b[33m...\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Running preprocessing pipeline<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating unique ids\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Creating unique ids<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Normalizing currency\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Normalizing currency<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting time features\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Extracting time features<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Adding cyclical encoding to time feats\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Adding cyclical encoding to time feats<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Applying label encoding\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Applying label encoding<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Label encoding applied to columns: \u001b[1m[\u001b[0m\u001b[32m'payment_type'\u001b[0m, \u001b[32m'day_of_week'\u001b[0m, \u001b[32m'from_bank'\u001b[0m, \u001b[32m'to_bank'\u001b[0m, \u001b[32m'sent_currency'\u001b[0m, \n",
              "\u001b[32m'received_currency'\u001b[0m\u001b[1m]\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Label encoding applied to columns: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'payment_type'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'day_of_week'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'from_bank'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'to_bank'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'sent_currency'</span>, \n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">'received_currency'</span><span style=\"font-weight: bold\">]</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting graph features\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Extracting graph features<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Using default weight columns: \u001b[1m[\u001b[0m\u001b[32m'sent_amount'\u001b[0m, \u001b[32m'received_amount'\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Using default weight columns: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'sent_amount'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'received_amount'</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Graph features computed using: \u001b[1m[\u001b[0m\u001b[32m'sent_amount'\u001b[0m, \u001b[32m'received_amount'\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Graph features computed using: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'sent_amount'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'received_amount'</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  **Note**, previously graph-based features were calculated using only `sent_amount` as edge weight \u001b[1m(\u001b[0monly based on \n",
              "outgoing transactions\u001b[1m)\u001b[0m. Now both sent and received amounts are included by default.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  **Note**, previously graph-based features were calculated using only `sent_amount` as edge weight <span style=\"font-weight: bold\">(</span>only based on \n",
              "outgoing transactions<span style=\"font-weight: bold\">)</span>. Now both sent and received amounts are included by default.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  New feature columns added: degree_centrality_sent_amount, degree_centrality_received_amount, \n",
              "pagerank_sent_amount, pagerank_received_amount\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  New feature columns added: degree_centrality_sent_amount, degree_centrality_received_amount, \n",
              "pagerank_sent_amount, pagerank_received_amount\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Preprocessing completed successfully!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preprocessing completed successfully!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'renamed'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'duplicates_removed'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'unique_ids_created'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'currency_normalized'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'time_features_extracted'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'cyclical_encoded'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'weekend_encoded'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'label_encoded'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'neighbor_context_computed'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'normalized'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'renamed'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'duplicates_removed'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'unique_ids_created'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'currency_normalized'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'time_features_extracted'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'cyclical_encoded'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'weekend_encoded'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'label_encoded'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'neighbor_context_computed'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'normalized'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 94.93s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_cols = ['from_bank', 'to_bank', 'received_amount', 'received_currency',\n",
        "#        'sent_amount', 'sent_currency', 'payment_type',\n",
        "#        'from_account_id', 'to_account_id', 'from_account_idx',\n",
        "#        'to_account_idx', 'sent_amount_usd', 'received_amount_usd',\n",
        "#        'hour_of_day', 'day_of_week', 'seconds_since_midnight', 'timestamp_int',\n",
        "#        'timestamp_scaled', 'day_sin', 'day_cos', 'time_of_day_sin',\n",
        "#        'time_of_day_cos', 'is_weekend']\n",
        "X_cols = ['from_account_idx', 'to_account_idx','from_bank','received_amount', 'sent_amount',\n",
        "          'sent_currency', 'payment_type','day_of_week','timestamp_int']\n",
        "y_col = 'is_laundering'\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = pl.split_train_test_val(X_cols, y_col, test_size=0.15, val_size=0.15, split_type='temporal_agg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ-rnKhXXXId",
        "outputId": "d933b773-aeb1-4d5e-8e2c-8677fb569a27"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split using temporal_agg method.\n",
            "Remember to mask labels in GNN evaluation.\n",
            " - Train: no mask \n",
            " - Val: mask y_lab[:t1] (only evaluate labels y_lab[t1:t2]) \n",
            " - Test: mask y_lab[:t2] (only evaluate labels y_lab[t2:])\n",
            "\n",
            "⏱️ Execution time: 1.23s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_features = ['received_amount', 'sent_amount', 'sent_currency',\n",
        "                 'payment_type','day_of_week','timestamp_int']\n",
        "node_features = ['from_bank']\n",
        "train_data, val_data, test_data = pl.generate_tensors(edge_features, node_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "1XvFGVCttaPk",
        "outputId": "d0cd0349-6c95-45a0-a81a-27a2695c8e4e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating tensors\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Generating tensors<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Dataset: train\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Dataset: train\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Index Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m888710\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, num_edges\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Index Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">888710</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, num_edges<span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Attribute Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m888710\u001b[0m, \u001b[1;36m6\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Attribute Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">888710</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Node Attribute Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m888710\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Node Attribute Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">888710</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Labels Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m888710\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Labels Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">888710</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Using provided node features: \u001b[1m[\u001b[0m\u001b[32m'from_bank'\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Using provided node features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'from_bank'</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Dataset: val\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Dataset: val\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Index Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1079148\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, num_edges\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Index Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1079148</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, num_edges<span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Attribute Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1079148\u001b[0m, \u001b[1;36m6\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Attribute Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1079148</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Node Attribute Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1079148\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Node Attribute Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1079148</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Labels Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1079148\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Labels Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1079148</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Using provided node features: \u001b[1m[\u001b[0m\u001b[32m'from_bank'\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Using provided node features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'from_bank'</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Dataset: test\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Dataset: test\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Index Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1269586\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, num_edges\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Index Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1269586</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, num_edges<span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Attribute Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1269586\u001b[0m, \u001b[1;36m6\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Attribute Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1269586</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Node Attribute Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1269586\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Node Attribute Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1269586</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Labels Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1269586\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Labels Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1269586</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Using provided node features: \u001b[1m[\u001b[0m\u001b[32m'from_bank'\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Using provided node features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'from_bank'</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.17s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GNNs"
      ],
      "metadata": {
        "id": "XYsAXFzI4fGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cannot use GCN or GAT!\n",
        "\n",
        "* The Graph Convolutional Network (GCN), implemented with `GCNConv`, only aggregates features from neighboring nodes and does not use edge attributes in its message passing.\n",
        "* Graph Attention Networks (GAT), implemented with `GATConv`, allows edge attention weights, which can indirectly incorporate edge attributes. Problem: If all nodes have the same feature vector (e.g., initialized to 1), then the computed attention scores will be the same for all edges. We'd need to modify GAT to use edge features meaningfully in the attention computation.\n",
        "\n",
        "`GINeConv`\n",
        "* Directly includes edge attributes in message passing using an MLP-based edge transformation.\n",
        "\n",
        "`EdgeConv`\n",
        "* dynamically computes edge embeddings and updates node features based on edges\n",
        "\n"
      ],
      "metadata": {
        "id": "ZykVSu2wzzra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GINeConv\n",
        "\n",
        "Modified GINConv that includes edge features in message passing.\n",
        "Update rule is:\n",
        "h (l+1) = h (l) + sum (MLP(h(l + e\n"
      ],
      "metadata": {
        "id": "jW94nuYtwism"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If on GPU, do as below\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK8WuSjbAUHO",
        "outputId": "4e954eb8-5f4e-402e-f4aa-c4df28cd9000"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "\n",
            "⏱️ Execution time: 0.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EdgeGINE(nn.Module):\n",
        "    def __init__(self, n_node_feats, n_edge_feats, n_hidden=64):\n",
        "        super(EdgeGINE, self).__init__()\n",
        "\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_node_feats = n_node_feats\n",
        "        self.n_edge_feats = n_edge_feats\n",
        "\n",
        "        # MLP to embed node and edges\n",
        "        self.node_emb = nn.Linear(self.n_node_feats, self.n_hidden)\n",
        "        self.edge_emb = nn.Linear(self.n_edge_feats, self.n_hidden)\n",
        "\n",
        "        # MLP that processes edge features, passed into GINEConv\n",
        "        nn_edge = Sequential(Linear(self.n_hidden, self.n_hidden), ReLU(), Linear(self.n_hidden, self.n_hidden))\n",
        "\n",
        "        # Two GINEConv layers using nn_edge when it needs to process edge attributes\n",
        "        self.gine1 = GINEConv(nn_edge, edge_dim=self.n_hidden, train_eps=True)\n",
        "        self.gine2 = GINEConv(nn_edge, edge_dim=self.n_hidden, train_eps=True)\n",
        "\n",
        "        # MLP for edge classification\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(3 * self.n_hidden, 128), # src, dest, edge\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        \"\"\"\n",
        "        x: Node features (or placeholder embeddings if None)\n",
        "        edge_index: Edge list (2, n_edges)\n",
        "        edge_attr: Edge features (n_edges, self.n_edge_feats)\n",
        "        \"\"\"\n",
        "        if x is None:  # If no node features, use trainable embeddings\n",
        "            x = torch.ones((edge_index.max().item() + 1, 1), device=device)\n",
        "\n",
        "        x = self.node_emb(x) # MLP\n",
        "        edge_attr = self.edge_emb(edge_attr) # MLP\n",
        "        x, edge_attr, edge_index = x.to(device), edge_attr.to(device), edge_index.to(device)\n",
        "\n",
        "        # Pass nodes and edges through GINE layers\n",
        "        x = self.gine1(x, edge_index, edge_attr)\n",
        "        x = F.relu(x)\n",
        "        x = self.gine2(x, edge_index, edge_attr)\n",
        "\n",
        "        # Get output for classification\n",
        "        src, dest = edge_index\n",
        "        src_embed = x[src]\n",
        "        dest_embed = x[dest]\n",
        "\n",
        "        edge_inputs = torch.cat([src_embed, dest_embed, edge_attr], dim=1)\n",
        "        edge_logits = self.mlp(edge_inputs).squeeze(1)\n",
        "\n",
        "        return edge_logits\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuOv1oly1FYf",
        "outputId": "e4f0440b-dbd4-4dbd-e413-11eaccf4c73d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import AveragePrecision, F1Score\n",
        "\n",
        "# Move data to GPU if using\n",
        "# train_data = train_data.to(device)\n",
        "# val_data = val_data.to(device)\n",
        "test_data = test_data.to(device)\n",
        "\n",
        "# Create DataLoader (batch size=1 because we have one graph)\n",
        "# train_loader = DataLoader([train_data], batch_size=1, shuffle=True)\n",
        "# val_loader = DataLoader([val_data], batch_size=1, shuffle=False)\n",
        "test_loader = DataLoader([test_data], batch_size=1, shuffle=False)\n",
        "\n",
        "# # Create metrics\n",
        "# accuracy = Accuracy(task=\"binary\").to(device) # 1/N sum(1(y=yhat))\n",
        "# recall = Recall(task='binary').to(device) # TP / (TP+FN), or use BinaryRecall class?\n",
        "# precision = Precision(task=\"binary\").to(device) # TP / (TP + FP)\n",
        "# auroc = AUROC(task=\"binary\").to(device)\n",
        "# pr_auc = AveragePrecision(task=\"binary\").to(device)\n",
        "# f1 = F1Score(task=\"binary\").to(device)\n",
        "\n",
        "# Initialize model & optimizer\n",
        "num_edge_features = len(edge_features)  # Your selected transaction features\n",
        "num_node_features = 1\n",
        "model = EdgeGINE(num_node_features, num_edge_features).to(device)\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Use focal loss to focus on rare positives\n",
        "class FocalLoss(torch.nn.Module):\n",
        "    def __init__(self, gamma=2.0, alpha=0.25):\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        bce_loss = F.binary_cross_entropy_with_logits(logits, targets, reduction=\"none\")\n",
        "        pt = torch.exp(-bce_loss)  # Probabilities of correct classification\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "class HybridLoss(torch.nn.Module):\n",
        "    \"\"\"Hybrid Loss that balances BCE (for accuracy) and Focal Loss (for recall)\"\"\"\n",
        "    def __init__(self, alpha=0.25, gamma=2.0, focal_weight=0.5):\n",
        "        super().__init__()\n",
        "        self.bce = torch.nn.BCEWithLogitsLoss()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.focal_weight = focal_weight  # Weighting factor between BCE and Focal Loss\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        # BCE Loss\n",
        "        bce_loss = self.bce(logits, targets.float())\n",
        "\n",
        "        # Focal Loss\n",
        "        probs = torch.sigmoid(logits)\n",
        "        bce_loss_per_sample = F.binary_cross_entropy_with_logits(logits, targets.float(), reduction=\"none\")\n",
        "        focal_loss = self.alpha * (1 - torch.exp(-bce_loss_per_sample)) ** self.gamma * bce_loss_per_sample\n",
        "        focal_loss = focal_loss.mean()\n",
        "\n",
        "        # Combine BCE and Focal Loss\n",
        "        total_loss = (1 - self.focal_weight) * bce_loss + self.focal_weight * focal_loss\n",
        "        return total_loss\n",
        "\n",
        "\n",
        "#criterion = FocalLoss(gamma=2.0, alpha=0.25)\n",
        "#criterion = BCEWithLogitsLoss(weight=torch.tensor([50.0],device=device))\n",
        "criterion = HybridLoss(focal_weight=0.3)  # Adjust weight (0.3-0.6 works well)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch8ZtyDR5qoS",
        "outputId": "0af48035-c653-499b-818d-39971892591f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.01s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = int((1-(0.3))*len(pl.df))\n",
        "t2 = int((1-0.15)*len(pl.df))\n",
        "\n",
        "# Create label masks for validation and test\n",
        "train_mask = torch.ones(len(y_test), dtype=torch.bool)  # Use all training labels\n",
        "val_mask = torch.zeros(len(y_test), dtype=torch.bool)\n",
        "test_mask = torch.zeros(len(y_test), dtype=torch.bool)\n",
        "\n",
        "# Unmask only the correct labels\n",
        "val_mask[t1:t2] = True  # Only evaluate labels y_val[t1:t2]\n",
        "test_mask[t2:] = True    # Only evaluate labels y_test[t2:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0Fm0BelNjhi",
        "outputId": "9c80bff0-829c-4427-9f54-c63d09a59d7e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.functional import accuracy, recall, precision, auroc, average_precision, f1_score\n",
        "\n",
        "# Training function with one forward pass for training and validation\n",
        "def train(model, optimizer, criterion, data, train_mask, val_mask, test_mask, threshold=0.5, epochs=20):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # **Forward pass once on the entire graph**\n",
        "        logits = model(data.x.to(device), data.edge_index.to(device), data.edge_attr.to(device))\n",
        "        probs = torch.sigmoid(logits)  # Convert logits to probabilities\n",
        "        preds = (probs > threshold).long()  # Convert to binary predictions\n",
        "\n",
        "\n",
        "        # **Training loss (only for training labels)**\n",
        "        train_loss = criterion(logits[train_mask], data.y[train_mask].float())\n",
        "\n",
        "        # **Backward pass & optimization**\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # **Validation loss (computed without gradient updates)**\n",
        "        with torch.no_grad():\n",
        "            val_loss = criterion(logits[val_mask], data.y[val_mask].float())\n",
        "\n",
        "        # **Compute train, val, and test metrics using the same model output**\n",
        "        def compute_metrics(preds, data, mask):\n",
        "          acc = accuracy(preds[mask], data.y[mask], task=\"binary\")\n",
        "          rec = recall(preds[mask], data.y[mask], task=\"binary\")\n",
        "          prec = precision(preds[mask], data.y[mask], task=\"binary\")\n",
        "          auroc_score = auroc(probs[mask], data.y[mask], task=\"binary\")\n",
        "          pr_auc_score = average_precision(probs[mask], data.y[mask], task=\"binary\")\n",
        "          f1 = f1_score(preds[mask], data.y[mask], task=\"binary\")\n",
        "          return acc, rec, prec, auroc_score, pr_auc_score, f1\n",
        "\n",
        "        train_acc, train_rec, train_prec, train_auroc, train_pr_auc, train_f1 = compute_metrics(preds, data, train_mask)\n",
        "        val_acc, val_rec, val_prec, val_auroc, val_pr_auc, val_f1 = compute_metrics(preds, data, val_mask)\n",
        "        test_acc, test_rec, test_prec, test_auroc, test_pr_auc, test_f1 = compute_metrics(preds, data, test_mask)\n",
        "\n",
        "        if epoch%50==0:\n",
        "              print(f\"Epoch {epoch+1}/{epochs} \"\n",
        "                f\"Train Loss: {train_loss.item():.4f}  | Val Loss: {val_loss.item():.4f} |  \"\n",
        "                f\"Train Acc: {train_acc:.4f}  | Val Acc: {val_acc:.4f}  | Test Acc: {test_acc:.4f} |  \"\n",
        "                f\"Train F1: {train_f1:.4f}  | Val F1: {val_f1:.4f}  | Test F1: {test_f1:.4f} |  \"\n",
        "                f\"Train PR-AUC: {train_pr_auc:.4f}  | Val PR-AUC: {val_pr_auc:.4f} | Test PR-AUC: {test_pr_auc:.4f} |  \"\n",
        "                f\"Train Prec: {train_prec:.4f}  | Val Prec: {val_prec:.4f}  | Test Prec: {test_prec:.4f} |  \"\n",
        "                f\"Train Rec: {train_rec:.4f}  | Val Rec: {val_rec:.4f}  | Test Rec: {test_rec:.4f} |  \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf9W-jRoAnlc",
        "outputId": "0eb232bb-eaf1-4803-dab6-4fb32e4ef68f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Training\n",
        "train(model, optimizer, criterion, test_data, train_mask, val_mask, test_mask, epochs=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbTIbJHtGA5i",
        "outputId": "c1a15a5c-e533-47b1-b64e-df6925edc94d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5000 Train Loss: 9659974.0000  | Val Loss: 10246719.0000 |  Train Acc: 0.9595  | Val Acc: 0.9575  | Test Acc: 0.9660 |  Train F1: 0.0028  | Val F1: 0.0015  | Test F1: 0.0080 |  Train PR-AUC: 0.0010  | Val PR-AUC: 0.0013 | Test PR-AUC: 0.0022 |  Train Prec: 0.0014  | Val Prec: 0.0008  | Test Prec: 0.0042 |  Train Rec: 0.0549  | Val Rec: 0.0243  | Test Rec: 0.0653 |  \n",
            "Epoch 51/5000 Train Loss: 431809.8125  | Val Loss: 549046.7500 |  Train Acc: 0.9990  | Val Acc: 0.9987  | Test Acc: 0.9979 |  Train F1: 0.0000  | Val F1: 0.0000  | Test F1: 0.0000 |  Train PR-AUC: 0.0010  | Val PR-AUC: 0.0013 | Test PR-AUC: 0.0021 |  Train Prec: 0.0000  | Val Prec: 0.0000  | Test Prec: 0.0000 |  Train Rec: 0.0000  | Val Rec: 0.0000  | Test Rec: 0.0000 |  \n",
            "Epoch 101/5000 Train Loss: 2203918.5000  | Val Loss: 2836762.7500 |  Train Acc: 0.9990  | Val Acc: 0.9987  | Test Acc: 0.9979 |  Train F1: 0.0000  | Val F1: 0.0000  | Test F1: 0.0000 |  Train PR-AUC: 0.0010  | Val PR-AUC: 0.0013 | Test PR-AUC: 0.0021 |  Train Prec: 0.0000  | Val Prec: 0.0000  | Test Prec: 0.0000 |  Train Rec: 0.0000  | Val Rec: 0.0000  | Test Rec: 0.0000 |  \n",
            "Epoch 151/5000 Train Loss: 626619.1250  | Val Loss: 798715.3750 |  Train Acc: 0.9990  | Val Acc: 0.9987  | Test Acc: 0.9979 |  Train F1: 0.0000  | Val F1: 0.0000  | Test F1: 0.0000 |  Train PR-AUC: 0.0010  | Val PR-AUC: 0.0013 | Test PR-AUC: 0.0021 |  Train Prec: 0.0000  | Val Prec: 0.0000  | Test Prec: 0.0000 |  Train Rec: 0.0000  | Val Rec: 0.0000  | Test Rec: 0.0000 |  \n",
            "Epoch 201/5000 Train Loss: 5586294.5000  | Val Loss: 264788.5000 |  Train Acc: 0.9458  | Val Acc: 0.9987  | Test Acc: 0.9979 |  Train F1: 0.0030  | Val F1: 0.0000  | Test F1: 0.0000 |  Train PR-AUC: 0.0011  | Val PR-AUC: 0.0013 | Test PR-AUC: 0.0021 |  Train Prec: 0.0015  | Val Prec: 0.0000  | Test Prec: 0.0000 |  Train Rec: 0.0811  | Val Rec: 0.0000  | Test Rec: 0.0000 |  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EdgeConv"
      ],
      "metadata": {
        "id": "uB5Q3ZL11Ve7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch_geometric.nn import EdgeConv\n",
        "# from torch.nn import Linear\n",
        "\n",
        "# class EdgeConvGNN(nn.Module):\n",
        "#     def __init__(self, num_node_features, self.n_edge_feats, self.n_hidden=64):\n",
        "#         super(EdgeConvGNN, self).__init__()\n",
        "\n",
        "#         self.edge_conv1 = EdgeConv(Sequential(Linear(2 * num_node_features, self.n_hidden), ReLU()))\n",
        "#         self.edge_conv2 = EdgeConv(Sequential(Linear(2 * self.n_hidden, self.n_hidden), ReLU()))\n",
        "\n",
        "#         self.mlp = nn.Sequential(\n",
        "#             nn.Linear(2 * self.n_hidden + self.n_edge_feats, 128),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(128, 64),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(64, 1),\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x, edge_index, edge_attr):\n",
        "#         x = selfself.n_hiddennv1(x, edge_index)\n",
        "#         x = F.relu(x)\n",
        "#         x = self.edge_conv2(x, edge_index)\n",
        "\n",
        "#         src, dest = edge_index\n",
        "#         src_embed = x[src]\n",
        "#         dest_embed = x[dest]\n",
        "\n",
        "#         edge_inputs = torch.cat([src_embed, dest_embed, edge_attr], dim=1)\n",
        "#         edge_logits = self.mlp(edge_inputs).squeeze(1)\n",
        "\n",
        "#         return edge_logits\n"
      ],
      "metadata": {
        "id": "GchXhxSS1YFs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}