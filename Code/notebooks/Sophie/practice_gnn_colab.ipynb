{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Practice GNN"
      ],
      "metadata": {
        "id": "mCZwI-Z2ZQCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook configuration"
      ],
      "metadata": {
        "id": "U5njmE3R1nPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from tabulate import tabulate\n",
        "from tqdm import trange\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "from time import monotonic\n",
        "from pprint import pprint\n",
        "from google.colab import drive\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.nn import BCEWithLogitsLoss, Sequential, Linear, ReLU\n",
        "!pip install torch-geometric\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, EdgeConv, GINEConv\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "!pip install torchmetrics\n",
        "from torchmetrics.classification import Recall, Accuracy, AUROC, Precision\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "content_base = \"/content/drive\"\n",
        "drive.mount(content_base)\n",
        "\n",
        "# Project data\n",
        "data_dir = os.path.join(content_base, \"My Drive/Capstone/data\")\n",
        "data_file = os.path.join(data_dir, \"HI-Small_25.csv\")\n",
        "\n",
        "# # Project Source Code\n",
        "# src_path = os.path.join(content_base, \"My Drive/Capstone/src\")\n",
        "# sys.path.append(src_path)\n",
        "# from helpers import add_cell_timer\n",
        "# from pipeline import ModelPipeline\n",
        "\n",
        "# add_cell_timer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rlo9F0NmZ04j",
        "outputId": "bf0fb677-b3d5-46d7-ee39-8391314fbd4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.14)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.7.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.6.0+cu124)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.14.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.7.0-py3-none-any.whl (960 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m960.9/960.9 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.2-py3-none-any.whl (28 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lightning-utilities-0.14.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchmetrics-1.7.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colaboratory executes in an environment with a file system\n",
        "# that has a Linux topography, but where the user should work under\n",
        "# the `/content` directory\n",
        "COLAB_ROOT = \"/content\"\n",
        "\n",
        "REPO_URL = \"https://github.com/engie4800/dsi-capstone-spring-2025-TD-anti-money-laundering.git\"\n",
        "REPO_ROOT = os.path.join(COLAB_ROOT, REPO_URL.split(\"/\")[-1].split(\".\")[0])\n",
        "REPO_BRANCH = \"sophie\"\n",
        "\n",
        "# Clones the repository at `/content/dsi-capstone-spring-2025-TD-anti-money-laundering`\n",
        "if not os.path.exists(REPO_ROOT):\n",
        "  os.chdir(COLAB_ROOT)\n",
        "  !git clone {REPO_URL}\n",
        "\n",
        "# Pulls the latest code from the provided branch and adds the\n",
        "# analysis pipeline source code to the Python system path\n",
        "os.chdir(REPO_ROOT)\n",
        "!git pull\n",
        "!git checkout {REPO_BRANCH}\n",
        "sys.path.append(os.path.join(REPO_ROOT, \"Code/src\"))\n",
        "os.chdir(COLAB_ROOT)"
      ],
      "metadata": {
        "id": "TXY9iPVgflc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76741ffb-8e51-4501-fe39-0bbf16e5d917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dsi-capstone-spring-2025-TD-anti-money-laundering'...\n",
            "remote: Enumerating objects: 520, done.\u001b[K\n",
            "remote: Counting objects: 100% (144/144), done.\u001b[K\n",
            "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
            "remote: Total 520 (delta 79), reused 80 (delta 48), pack-reused 376 (from 1)\u001b[K\n",
            "Receiving objects: 100% (520/520), 25.99 MiB | 16.30 MiB/s, done.\n",
            "Resolving deltas: 100% (246/246), done.\n",
            "Already up to date.\n",
            "Branch 'sophie' set up to track remote branch 'sophie' from 'origin'.\n",
            "Switched to a new branch 'sophie'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helpers import add_cell_timer\n",
        "from pipeline import ModelPipeline\n",
        "add_cell_timer()"
      ],
      "metadata": {
        "id": "CrlM3wUFj_EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "Guq15nJi1hSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run initial full-dataset preprocessing"
      ],
      "metadata": {
        "id": "ZvOeaI31I97e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize pipeline with dataset\n",
        "pl = ModelPipeline(data_file)\n",
        "pl.run_preprocessing()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "pSS_Z8FTZ2kj",
        "outputId": "2ee6a735-4773-4741-cc62-dd3a7cf0134a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running preprocessing pipeline\u001b[33m...\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Running preprocessing pipeline<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating unique ids\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Creating unique ids<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Normalizing currency\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Normalizing currency<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting time features\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Extracting time features<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Adding cyclical encoding to time feats\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Adding cyclical encoding to time feats<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Applying label encoding\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Applying label encoding<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Label encoding applied to columns: \u001b[1m[\u001b[0m\u001b[32m'payment_type'\u001b[0m, \u001b[32m'day_of_week'\u001b[0m, \u001b[32m'from_bank'\u001b[0m, \u001b[32m'to_bank'\u001b[0m, \u001b[32m'sent_currency'\u001b[0m, \n",
              "\u001b[32m'received_currency'\u001b[0m\u001b[1m]\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Label encoding applied to columns: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'payment_type'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'day_of_week'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'from_bank'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'to_bank'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'sent_currency'</span>, \n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">'received_currency'</span><span style=\"font-weight: bold\">]</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting graph features\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Extracting graph features<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Using default weight columns: \u001b[1m[\u001b[0m\u001b[32m'sent_amount'\u001b[0m, \u001b[32m'received_amount'\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Using default weight columns: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'sent_amount'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'received_amount'</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Graph features computed using: \u001b[1m[\u001b[0m\u001b[32m'sent_amount'\u001b[0m, \u001b[32m'received_amount'\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Graph features computed using: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'sent_amount'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'received_amount'</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  **Note**, previously graph-based features were calculated using only `sent_amount` as edge weight \u001b[1m(\u001b[0monly based on \n",
              "outgoing transactions\u001b[1m)\u001b[0m. Now both sent and received amounts are included by default.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  **Note**, previously graph-based features were calculated using only `sent_amount` as edge weight <span style=\"font-weight: bold\">(</span>only based on \n",
              "outgoing transactions<span style=\"font-weight: bold\">)</span>. Now both sent and received amounts are included by default.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  New feature columns added: degree_centrality_sent_amount, degree_centrality_received_amount, \n",
              "pagerank_sent_amount, pagerank_received_amount\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  New feature columns added: degree_centrality_sent_amount, degree_centrality_received_amount, \n",
              "pagerank_sent_amount, pagerank_received_amount\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Preprocessing completed successfully!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preprocessing completed successfully!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'renamed'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'duplicates_removed'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'unique_ids_created'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'currency_normalized'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'time_features_extracted'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'cyclical_encoded'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'weekend_encoded'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'label_encoded'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'neighbor_context_computed'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'normalized'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'renamed'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'duplicates_removed'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'unique_ids_created'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'currency_normalized'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'time_features_extracted'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'cyclical_encoded'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'weekend_encoded'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'label_encoded'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'neighbor_context_computed'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'normalized'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 99.67s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_cols = ['from_bank', 'to_bank', 'received_amount', 'received_currency',\n",
        "       'sent_amount', 'sent_currency', 'payment_type', 'degree_centrality_sent_amount',\n",
        "          'pagerank_sent_amount', 'degree_centrality_received_amount', 'pagerank_received_amount', 'from_account_idx',\n",
        "       'to_account_idx', 'sent_amount_usd', 'received_amount_usd',\n",
        "       'hour_of_day', 'day_of_week', 'seconds_since_midnight', 'timestamp_int',\n",
        "       'timestamp_scaled', 'day_sin', 'day_cos', 'time_of_day_sin',\n",
        "       'time_of_day_cos', 'is_weekend']\n",
        "# X_cols = ['from_account_idx', 'to_account_idx','from_bank','received_amount', 'sent_amount',\n",
        "#           'sent_currency', 'payment_type','day_of_week','timestamp_int']\n",
        "y_col = 'is_laundering'\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = pl.split_train_test_val(X_cols, y_col, test_size=0.15, val_size=0.15, split_type='temporal_agg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "vZ-rnKhXXXId",
        "outputId": "2c211dd7-acbd-49c5-c26c-5b5e1a28b8b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Data split using temporal_agg method.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Data split using temporal_agg method.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Remember to mask labels in GNN evaluation.\n",
              " - Train: no mask \n",
              " - Val: mask y_lab\u001b[1m[\u001b[0m:t1\u001b[1m]\u001b[0m \u001b[1m(\u001b[0monly evaluate labels y_lab\u001b[1m)\u001b[0m \n",
              " - Test: mask y_lab\u001b[1m[\u001b[0m:t2\u001b[1m]\u001b[0m \u001b[1m(\u001b[0monly evaluate labels y_lab\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Remember to mask labels in GNN evaluation.\n",
              " - Train: no mask \n",
              " - Val: mask y_lab<span style=\"font-weight: bold\">[</span>:t1<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">(</span>only evaluate labels y_lab<span style=\"font-weight: bold\">)</span> \n",
              " - Test: mask y_lab<span style=\"font-weight: bold\">[</span>:t2<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">(</span>only evaluate labels y_lab<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 1.19s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_feats = ['sent_amount_usd', 'received_amount_usd']\n",
        "X_train, X_test, X_val = pl.numerical_scaling(numerical_feats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj85C3uPud5g",
        "outputId": "3ce0df02-0b41-4b54-c086-d601a18c87cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.06s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_features = ['received_amount', 'received_currency',\n",
        "       'sent_amount', 'sent_currency', 'payment_type', 'sent_amount_usd', 'received_amount_usd',\n",
        "       'hour_of_day', 'day_of_week', 'seconds_since_midnight', 'timestamp_int',\n",
        "       'timestamp_scaled', 'day_sin', 'day_cos', 'time_of_day_sin',\n",
        "       'time_of_day_cos', 'is_weekend']\n",
        "# edge_features = ['received_amount', 'sent_amount', 'sent_currency',\n",
        "#                  'payment_type','day_of_week','timestamp_int']\n",
        "node_features = ['from_bank','degree_centrality_sent_amount','pagerank_sent_amount', 'degree_centrality_received_amount', 'pagerank_received_amount']\n",
        "train_data, val_data, test_data = pl.generate_tensors(edge_features, node_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "1XvFGVCttaPk",
        "outputId": "f2973a69-11dc-47fe-de3b-618b249a40e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating tensors\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Generating tensors<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Dataset: train\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Dataset: train\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Index Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m888710\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, num_edges\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Index Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">888710</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, num_edges<span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Attribute Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m888710\u001b[0m, \u001b[1;36m17\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Attribute Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">888710</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Node Attribute Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m888710\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Node Attribute Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">888710</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Labels Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m888710\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Labels Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">888710</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Using provided node features: \u001b[1m[\u001b[0m\u001b[32m'from_bank'\u001b[0m, \u001b[32m'degree_centrality_sent_amount'\u001b[0m, \u001b[32m'pagerank_sent_amount'\u001b[0m, \n",
              "\u001b[32m'degree_centrality_received_amount'\u001b[0m, \u001b[32m'pagerank_received_amount'\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Using provided node features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'from_bank'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'degree_centrality_sent_amount'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pagerank_sent_amount'</span>, \n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">'degree_centrality_received_amount'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pagerank_received_amount'</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Dataset: val\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Dataset: val\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Index Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1079148\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, num_edges\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Index Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1079148</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, num_edges<span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Attribute Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1079148\u001b[0m, \u001b[1;36m17\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Attribute Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1079148</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Node Attribute Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1079148\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Node Attribute Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1079148</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Labels Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1079148\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Labels Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1079148</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Using provided node features: \u001b[1m[\u001b[0m\u001b[32m'from_bank'\u001b[0m, \u001b[32m'degree_centrality_sent_amount'\u001b[0m, \u001b[32m'pagerank_sent_amount'\u001b[0m, \n",
              "\u001b[32m'degree_centrality_received_amount'\u001b[0m, \u001b[32m'pagerank_received_amount'\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Using provided node features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'from_bank'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'degree_centrality_sent_amount'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pagerank_sent_amount'</span>, \n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">'degree_centrality_received_amount'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pagerank_received_amount'</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Dataset: test\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Dataset: test\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Index Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1269586\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, num_edges\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Index Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1269586</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, num_edges<span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Attribute Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1269586\u001b[0m, \u001b[1;36m17\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Attribute Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1269586</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Node Attribute Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1269586\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Node Attribute Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1269586</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Labels Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1269586\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Labels Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1269586</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Using provided node features: \u001b[1m[\u001b[0m\u001b[32m'from_bank'\u001b[0m, \u001b[32m'degree_centrality_sent_amount'\u001b[0m, \u001b[32m'pagerank_sent_amount'\u001b[0m, \n",
              "\u001b[32m'degree_centrality_received_amount'\u001b[0m, \u001b[32m'pagerank_received_amount'\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Using provided node features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'from_bank'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'degree_centrality_sent_amount'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pagerank_sent_amount'</span>, \n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">'degree_centrality_received_amount'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pagerank_received_amount'</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.36s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GNNs"
      ],
      "metadata": {
        "id": "XYsAXFzI4fGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cannot use GCN or GAT!\n",
        "\n",
        "* The Graph Convolutional Network (GCN), implemented with `GCNConv`, only aggregates features from neighboring nodes and does not use edge attributes in its message passing.\n",
        "* Graph Attention Networks (GAT), implemented with `GATConv`, allows edge attention weights, which can indirectly incorporate edge attributes. Problem: If all nodes have the same feature vector (e.g., initialized to 1), then the computed attention scores will be the same for all edges. We'd need to modify GAT to use edge features meaningfully in the attention computation.\n",
        "\n",
        "`GINeConv`\n",
        "* Directly includes edge attributes in message passing using an MLP-based edge transformation.\n",
        "\n",
        "`EdgeConv`\n",
        "* dynamically computes edge embeddings and updates node features based on edges\n",
        "\n"
      ],
      "metadata": {
        "id": "ZykVSu2wzzra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GINeConv\n",
        "\n",
        "Modified GINConv that includes edge features in message passing.\n",
        "Update rule is:\n",
        "h (l+1) = h (l) + sum (MLP(h(l + e\n"
      ],
      "metadata": {
        "id": "jW94nuYtwism"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If on GPU, do as below\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK8WuSjbAUHO",
        "outputId": "ce90af18-9472-4f09-db0f-9ccd10fdc110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "\n",
            "⏱️ Execution time: 0.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EdgeGINE(nn.Module):\n",
        "    def __init__(self, n_node_feats, n_edge_feats, n_hidden=64):\n",
        "        super(EdgeGINE, self).__init__()\n",
        "\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_node_feats = n_node_feats\n",
        "        self.n_edge_feats = n_edge_feats\n",
        "\n",
        "        # Linear to embed node and edges\n",
        "        self.node_emb = nn.Linear(self.n_node_feats, self.n_hidden) # [num_nodes, n_hidden]\n",
        "        self.edge_emb = nn.Linear(self.n_edge_feats, self.n_hidden) # [num_edges, n_hidden]\n",
        "\n",
        "        # MLP that processes edge features, passed into GINEConv\n",
        "        nn_edge = Sequential(Linear(self.n_hidden, self.n_hidden), ReLU(), Linear(self.n_hidden, self.n_hidden))\n",
        "\n",
        "        # Two GINEConv layers using nn_edge when it needs to process edge attributes\n",
        "        self.gine1 = GINEConv(nn_edge, edge_dim=self.n_hidden, train_eps=True)\n",
        "        self.gine2 = GINEConv(nn_edge, edge_dim=self.n_hidden, train_eps=True)\n",
        "\n",
        "        # Edge updates MLPs\n",
        "        self.emlp1 = Sequential(\n",
        "                nn.Linear(3 * self.n_hidden, self.n_hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(self.n_hidden, self.n_hidden),\n",
        "            )\n",
        "        self.emlp2 = Sequential(\n",
        "                nn.Linear(3 * self.n_hidden, self.n_hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(self.n_hidden, self.n_hidden),\n",
        "            )\n",
        "\n",
        "        # MLP for edge classification\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(3 * self.n_hidden, 128), # src, dest, edge\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        \"\"\"\n",
        "        x: Node features (or placeholder embeddings if None)\n",
        "        edge_index: Edge list (2, n_edges)\n",
        "        edge_attr: Edge features (n_edges, self.n_edge_feats)\n",
        "        \"\"\"\n",
        "        src, dest = edge_index\n",
        "        if x is None:  # If no node features, use trainable embeddings\n",
        "            x = torch.ones((edge_index.max().item() + 1, 1), device=device)\n",
        "\n",
        "        # Create some initial embeddings for nodes and edges\n",
        "        x = self.node_emb(x) # MLP\n",
        "        edge_attr = self.edge_emb(edge_attr) # MLP\n",
        "        x, edge_attr, edge_index = x.to(device), edge_attr.to(device), edge_index.to(device)\n",
        "\n",
        "        # Pass nodes and edges through GINE layer1\n",
        "        x = x + F.relu(self.gine1(x, edge_index, edge_attr))\n",
        "\n",
        "        # Update edges with MLP1\n",
        "        edge_attr = edge_attr + self.emlp1(torch.cat([x[src], x[dest], edge_attr], dim=-1)) / 2\n",
        "\n",
        "        # Pass nodes and edges through GINE layer2\n",
        "        x = F.relu(self.gine1(x, edge_index, edge_attr))\n",
        "\n",
        "        # Update edges with MLP2\n",
        "        edge_attr = edge_attr + self.emlp2(torch.cat([x[src], x[dest], edge_attr], dim=-1)) / 2\n",
        "\n",
        "        # Get output for classification\n",
        "        src_embed, dest_embed = x[src], x[dest]\n",
        "        edge_inputs = torch.cat([src_embed, dest_embed, edge_attr], dim=1)\n",
        "        edge_logits = self.mlp(edge_inputs).squeeze(1)\n",
        "\n",
        "        return edge_logits\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuOv1oly1FYf",
        "outputId": "0db16385-93aa-460c-fb58-60fa9067abcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create data loaders - split into batches using `LinkNeighborLoader`, incorporating masking in the loading process & batching"
      ],
      "metadata": {
        "id": "1M3L-MnwMbSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LinkNeighborLoader args:\n",
        "\n",
        "**num_neighbors:** how many neighbors are sampled per node -- only sampling a subgraph around each edge in a batch. it is size [x,y] because we have 2 layers (sample x nodes in layer 1 and y nodes in layer 2).\n",
        "- Let’s say your batch contains 100 edges, and each edge touches two nodes (source and destination). Then LinkNeighborLoader will:\n",
        "  - Identify all unique nodes from those 100 edges\n",
        "  - For each of those nodes:\n",
        "      - Sample 10 neighbors (for layer 1)\n",
        "      - Then, for each of those neighbors, sample another 10 neighbors (for layer 2)\n",
        "  - Build a mini subgraph for this batch using only those sampled nodes and edges\n",
        "- Imagine you're doing link prediction for a social network:\n",
        "  - batch_size = 1024 means you're analyzing 1024 friend requests at a time\n",
        "  - num_neighbors = [10, 10] means for each person in the request, you look at:\n",
        "    - Their 10 direct friends\n",
        "    - And 10 friends-of-friends per direct friend"
      ],
      "metadata": {
        "id": "CQPkMxNxOMJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "\n",
        "batch_size=8192\n",
        "num_neighbors=10\n",
        "\n",
        "# Move data to GPU if using\n",
        "train_data = train_data.to(device)\n",
        "val_data = val_data.to(device)\n",
        "#test_data = test_data.to(device)\n",
        "\n",
        "tr_loader = LinkNeighborLoader(\n",
        "    tr_data,\n",
        "    num_neighbors=num_neighbors,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = LinkNeighborLoader(\n",
        "    val_data,\n",
        "    num_neighbors=num_neighbors,\n",
        "    edge_label_index=val_data.edge_index[:, val_inds],  # Only evaluate on these edges\n",
        "    edge_label=val_data.y[val_inds],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# te_loader = LinkNeighborLoader(\n",
        "#     te_data,\n",
        "#     num_neighbors=num_neighbors,\n",
        "#     edge_label_index=te_data.edge_index[:, te_inds],\n",
        "#     edge_label=te_data.y[te_inds],\n",
        "#     batch_size=args.batch_size,\n",
        "#     shuffle=False\n",
        "# )"
      ],
      "metadata": {
        "id": "GwnBlVBbMUhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import AveragePrecision, F1Score\n",
        "\n",
        "# Create DataLoader (batch size=1 because we have one graph)\n",
        "train_loader = DataLoader([train_data], batch_size=1, shuffle=True)\n",
        "val_loader = LinkNeighborLoader([val_data], batch_size=8192, num_neighbors=100, shuffle=False)\n",
        "# test_loader = LinkNeighborLoader([test_data], batch_size=1, shuffle=False)\n",
        "\n",
        "# # Create metrics\n",
        "# accuracy = Accuracy(task=\"binary\").to(device) # 1/N sum(1(y=yhat))\n",
        "# recall = Recall(task='binary').to(device) # TP / (TP+FN), or use BinaryRecall class?\n",
        "# precision = Precision(task=\"binary\").to(device) # TP / (TP + FP)\n",
        "# auroc = AUROC(task=\"binary\").to(device)\n",
        "# pr_auc = AveragePrecision(task=\"binary\").to(device)\n",
        "# f1 = F1Score(task=\"binary\").to(device)\n",
        "\n",
        "# Initialize model & optimizer\n",
        "num_edge_features = len(edge_features)  # Your selected transaction features\n",
        "num_node_features = 5\n",
        "model = EdgeGINE(num_node_features, num_edge_features).to(device)\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Use focal loss to focus on rare positives\n",
        "class FocalLoss(torch.nn.Module):\n",
        "    def __init__(self, gamma=2.0, alpha=0.25):\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        bce_loss = F.binary_cross_entropy_with_logits(logits, targets, reduction=\"none\")\n",
        "        pt = torch.exp(-bce_loss)  # Probabilities of correct classification\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "class HybridLoss(torch.nn.Module):\n",
        "    \"\"\"Hybrid Loss that balances BCE (for accuracy) and Focal Loss (for recall)\"\"\"\n",
        "    def __init__(self, alpha=0.25, gamma=2.0, focal_weight=0.5):\n",
        "        super().__init__()\n",
        "        self.bce = torch.nn.BCEWithLogitsLoss()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.focal_weight = focal_weight  # Weighting factor between BCE and Focal Loss\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        # BCE Loss\n",
        "        bce_loss = self.bce(logits, targets.float())\n",
        "\n",
        "        # Focal Loss\n",
        "        probs = torch.sigmoid(logits)\n",
        "        bce_loss_per_sample = F.binary_cross_entropy_with_logits(logits, targets.float(), reduction=\"none\")\n",
        "        focal_loss = self.alpha * (1 - torch.exp(-bce_loss_per_sample)) ** self.gamma * bce_loss_per_sample\n",
        "        focal_loss = focal_loss.mean()\n",
        "\n",
        "        # Combine BCE and Focal Loss\n",
        "        total_loss = (1 - self.focal_weight) * bce_loss + self.focal_weight * focal_loss\n",
        "        return total_loss\n",
        "\n",
        "\n",
        "#criterion = FocalLoss(gamma=2.0, alpha=0.25)\n",
        "criterion = BCEWithLogitsLoss(weight=torch.tensor([6.0],device=device))\n",
        "#criterion = HybridLoss(focal_weight=0.3)  # Adjust weight (0.3-0.6 works well)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch8ZtyDR5qoS",
        "outputId": "ddd465dd-2fc2-45a4-fad1-15755283324b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.01s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.functional import accuracy, recall, precision, auroc, average_precision, f1_score\n",
        "\n",
        "# Training function with one forward pass for training and validation\n",
        "def train(model, optimizer, criterion, tr_loader, val_loader, train_mask, val_mask, test_mask, threshold=0.5, epochs=20):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = total_examples = 0\n",
        "        preds, ground_truths = [], []\n",
        "\n",
        "        for batch in tqdm(tr_loader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            batch = batch.to(device)\n",
        "\n",
        "            # **Forward pass once on the entire graph**\n",
        "            batch_logits = model(batch.x, batch.edge_index, batch.edge_attr)\n",
        "            batch_probs = torch.sigmoid(batch_logits)  # Convert logits to probabilities\n",
        "            batch_preds = (batch_probs > threshold).long()  # Convert to binary predictions\n",
        "            preds.append(batch_preds)\n",
        "            ground_truths.append(batch.y)\n",
        "\n",
        "            # **Compute loss**\n",
        "            batch_loss = criterion(batch_logits[train_mask], batch.y[train_mask].float())\n",
        "\n",
        "            # **Training loss (only for training labels)**\n",
        "            train_loss = criterion(logits[train_mask], data.y[train_mask].float())\n",
        "\n",
        "        # **Backward pass & optimization**\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # **Validation loss (computed without gradient updates)**\n",
        "        with torch.no_grad():\n",
        "            val_loss = criterion(logits[val_mask], data.y[val_mask].float())\n",
        "\n",
        "        # **Compute train, val, and test metrics using the same model output**\n",
        "        def compute_metrics(preds, data, mask):\n",
        "          acc = accuracy(preds[mask], data.y[mask], task=\"binary\")\n",
        "          rec = recall(preds[mask], data.y[mask], task=\"binary\")\n",
        "          prec = precision(preds[mask], data.y[mask], task=\"binary\")\n",
        "          auroc_score = auroc(probs[mask], data.y[mask], task=\"binary\")\n",
        "          pr_auc_score = average_precision(probs[mask], data.y[mask], task=\"binary\")\n",
        "          f1 = f1_score(preds[mask], data.y[mask], task=\"binary\")\n",
        "          return acc, rec, prec, auroc_score, pr_auc_score, f1\n",
        "\n",
        "        train_acc, train_rec, train_prec, train_auroc, train_pr_auc, train_f1 = compute_metrics(preds, data, train_mask)\n",
        "        val_acc, val_rec, val_prec, val_auroc, val_pr_auc, val_f1 = compute_metrics(preds, data, val_mask)\n",
        "        # test_acc, test_rec, test_prec, test_auroc, test_pr_auc, test_f1 = compute_metrics(preds, data, test_mask)\n",
        "\n",
        "        if epoch%50==0:\n",
        "              print(f\"Epoch {epoch+1}/{epochs} \"\n",
        "                f\"Train Loss: {train_loss.item():.4f}  | Val Loss: {val_loss.item():.4f} |  \"\n",
        "                f\"Train Acc: {train_acc:.4f}  | Val Acc: {val_acc:.4f} |  \"\n",
        "                f\"Train F1: {train_f1:.4f}  | Val F1: {val_f1:.4f} |  \"\n",
        "                f\"Train PR-AUC: {train_pr_auc:.4f}  | Val PR-AUC: {val_pr_auc:.4f} |  \"\n",
        "                f\"Train Prec: {train_prec:.4f}  | Val Prec: {val_prec:.4f} |  \"\n",
        "                f\"Train Rec: {train_rec:.4f}  | Val Rec: {val_rec:.4f} |  \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf9W-jRoAnlc",
        "outputId": "182fa2bc-d557-4ef1-f078-6e92e96c99a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Training\n",
        "train(model, optimizer, criterion, val_data, train_mask, val_mask, test_mask, epochs=25000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "tbTIbJHtGA5i",
        "outputId": "7ab394c1-fa46-4fd7-cc9f-6892a6d5caa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 30.12 MiB is free. Process 15620 has 14.71 GiB memory in use. Of the allocated memory 12.75 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-10de9627a878>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-89bb322a1d1a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, data, train_mask, val_mask, test_mask, threshold, epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# **Forward pass once on the entire graph**\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert logits to probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to binary predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-e1d0c4d9f536>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Get output for classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0msrc_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0medge_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrc_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0medge_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 30.12 MiB is free. Process 15620 has 14.71 GiB memory in use. Of the allocated memory 12.75 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EdgeConv"
      ],
      "metadata": {
        "id": "uB5Q3ZL11Ve7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch_geometric.nn import EdgeConv\n",
        "# from torch.nn import Linear\n",
        "\n",
        "# class EdgeConvGNN(nn.Module):\n",
        "#     def __init__(self, num_node_features, self.n_edge_feats, self.n_hidden=64):\n",
        "#         super(EdgeConvGNN, self).__init__()\n",
        "\n",
        "#         self.edge_conv1 = EdgeConv(Sequential(Linear(2 * num_node_features, self.n_hidden), ReLU()))\n",
        "#         self.edge_conv2 = EdgeConv(Sequential(Linear(2 * self.n_hidden, self.n_hidden), ReLU()))\n",
        "\n",
        "#         self.mlp = nn.Sequential(\n",
        "#             nn.Linear(2 * self.n_hidden + self.n_edge_feats, 128),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(128, 64),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(64, 1),\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x, edge_index, edge_attr):\n",
        "#         x = selfself.n_hiddennv1(x, edge_index)\n",
        "#         x = F.relu(x)\n",
        "#         x = self.edge_conv2(x, edge_index)\n",
        "\n",
        "#         src, dest = edge_index\n",
        "#         src_embed = x[src]\n",
        "#         dest_embed = x[dest]\n",
        "\n",
        "#         edge_inputs = torch.cat([src_embed, dest_embed, edge_attr], dim=1)\n",
        "#         edge_logits = self.mlp(edge_inputs).squeeze(1)\n",
        "\n",
        "#         return edge_logits\n"
      ],
      "metadata": {
        "id": "GchXhxSS1YFs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}