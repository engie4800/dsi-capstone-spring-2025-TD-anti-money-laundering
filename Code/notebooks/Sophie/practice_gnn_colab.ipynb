{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Practice GNN"
      ],
      "metadata": {
        "id": "mCZwI-Z2ZQCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook configuration"
      ],
      "metadata": {
        "id": "U5njmE3R1nPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from tabulate import tabulate\n",
        "from tqdm import trange\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "from time import monotonic\n",
        "from pprint import pprint\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.nn import BCEWithLogitsLoss, Sequential, Linear, ReLU\n",
        "!pip install torch==2.5.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install torch-scatter torch-sparse pyg-lib torch-geometric \\\n",
        "  -f https://data.pyg.org/whl/torch-2.5.1+cu118.html\n",
        "from torch_geometric.nn import GINEConv\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader, LinkNeighborLoader\n",
        "!pip install torchmetrics\n",
        "from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score, BinaryAveragePrecision\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "content_base = \"/content/drive\"\n",
        "drive.mount(content_base)\n",
        "\n",
        "# Project data\n",
        "data_dir = os.path.join(content_base, \"My Drive/Capstone/data\")\n",
        "data_file = os.path.join(data_dir, \"subset_transactions2.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rlo9F0NmZ04j",
        "outputId": "946638a8-ee66-4254-f51a-d3f698d97d96"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.11/dist-packages (2.5.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (11.8.86)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1) (3.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.5.1+cu118.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt25cu118)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt25cu118)\n",
            "Requirement already satisfied: pyg-lib in /usr/local/lib/python3.11/dist-packages (0.4.0+pt25cu118)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.14.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.14)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.7.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.5.1+cu118)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.14.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.8.86)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.7.0-py3-none-any.whl (960 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m960.9/960.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.2-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.14.2 torchmetrics-1.7.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colaboratory executes in an environment with a file system\n",
        "# that has a Linux topography, but where the user should work under\n",
        "# the `/content` directory\n",
        "COLAB_ROOT = \"/content\"\n",
        "\n",
        "REPO_URL = \"https://github.com/engie4800/dsi-capstone-spring-2025-TD-anti-money-laundering.git\"\n",
        "REPO_ROOT = os.path.join(COLAB_ROOT, REPO_URL.split(\"/\")[-1].split(\".\")[0])\n",
        "REPO_BRANCH = \"sophie\"\n",
        "\n",
        "# Clones the repository at `/content/dsi-capstone-spring-2025-TD-anti-money-laundering`\n",
        "if not os.path.exists(REPO_ROOT):\n",
        "  os.chdir(COLAB_ROOT)\n",
        "  !git clone {REPO_URL}\n",
        "\n",
        "# Pulls the latest code from the provided branch and adds the\n",
        "# analysis pipeline source code to the Python system path\n",
        "os.chdir(REPO_ROOT)\n",
        "!git pull\n",
        "!git checkout {REPO_BRANCH}\n",
        "sys.path.append(os.path.join(REPO_ROOT, \"Code/src\"))\n",
        "os.chdir(COLAB_ROOT)"
      ],
      "metadata": {
        "id": "TXY9iPVgflc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de706cbf-92b3-44c5-b037-6a8f21f86247"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dsi-capstone-spring-2025-TD-anti-money-laundering'...\n",
            "remote: Enumerating objects: 643, done.\u001b[K\n",
            "remote: Counting objects: 100% (114/114), done.\u001b[K\n",
            "remote: Compressing objects: 100% (77/77), done.\u001b[K\n",
            "remote: Total 643 (delta 56), reused 44 (delta 35), pack-reused 529 (from 2)\u001b[K\n",
            "Receiving objects: 100% (643/643), 26.53 MiB | 54.01 MiB/s, done.\n",
            "Resolving deltas: 100% (320/320), done.\n",
            "Already up to date.\n",
            "Branch 'sophie' set up to track remote branch 'sophie' from 'origin'.\n",
            "Switched to a new branch 'sophie'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helpers import add_cell_timer\n",
        "from pipeline import ModelPipeline\n",
        "add_cell_timer()"
      ],
      "metadata": {
        "id": "CrlM3wUFj_EL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "Guq15nJi1hSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run initial full-dataset preprocessing"
      ],
      "metadata": {
        "id": "ZvOeaI31I97e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pl = ModelPipeline(data_file)\n",
        "pl.run_preprocessing()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Z_iVT9AOdfSY",
        "outputId": "a2a6a4b3-2e62-4558-f551-32301568cdcb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running preprocessing pipeline\u001b[33m...\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Running preprocessing pipeline<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating unique ids\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Creating unique ids<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Normalizing currency\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Normalizing currency<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting time features\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Extracting time features<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Adding cyclical encoding to time feats\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Adding cyclical encoding to time feats<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Applying label encoding\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Applying label encoding<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Label encoding applied to columns: \u001b[1m[\u001b[0m\u001b[32m'payment_type'\u001b[0m, \u001b[32m'day_of_week'\u001b[0m, \u001b[32m'from_bank'\u001b[0m, \u001b[32m'to_bank'\u001b[0m, \u001b[32m'sent_currency'\u001b[0m, \n",
              "\u001b[32m'received_currency'\u001b[0m\u001b[1m]\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Label encoding applied to columns: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'payment_type'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'day_of_week'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'from_bank'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'to_bank'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'sent_currency'</span>, \n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">'received_currency'</span><span style=\"font-weight: bold\">]</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Preprocessing completed successfully!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preprocessing completed successfully!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'renamed'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'duplicates_removed'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'unique_ids_created'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'currency_normalized'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'time_features_extracted'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'cyclical_encoded'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'weekend_encoded'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'label_encoded'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[32m'normalized'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'renamed'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'duplicates_removed'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'unique_ids_created'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'currency_normalized'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'time_features_extracted'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'cyclical_encoded'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'weekend_encoded'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'label_encoded'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'normalized'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 22.27s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "node_features = [\n",
        "    # TODO\n",
        "    # A list of tuples with this structure >>>\n",
        "    # (column to include, treatment/method, column rename)\n",
        "\n",
        "    ('from_bank', 'first', None),\n",
        "]\n",
        "\n",
        "pl.extract_nodes(node_features, add_graph_features=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EJUhJmleig4H",
        "outputId": "88fbacec-b6f2-4e5d-aa33-1607e1d5b2ea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting nodes\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Extracting nodes<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating a Data Frame containing \u001b[1;36m107583\u001b[0m nodes\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Creating a Data Frame containing <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">107583</span> nodes\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.02s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pl.df = pl.df.sort_values(by='timestamp_int')\n",
        "pl.df = pl.df.reset_index(drop=True)\n",
        "pl.df['edge_id'] = pl.df.index\n",
        "X_cols = ['edge_id','from_bank', 'to_bank', 'received_amount', 'received_currency',\n",
        "       'sent_amount', 'sent_currency', 'payment_type', 'from_account_idx',\n",
        "       'to_account_idx', 'sent_amount_usd', 'received_amount_usd',\n",
        "       'hour_of_day', 'day_of_week', 'seconds_since_midnight', 'timestamp_int',\n",
        "       'timestamp_scaled', 'day_sin', 'day_cos', 'time_of_day_sin',\n",
        "       'time_of_day_cos', 'is_weekend']\n",
        "y_col = 'is_laundering'\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = pl.split_train_test_val(X_cols, y_col, test_size=0.15, val_size=0.15, split_type='temporal_agg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vZ-rnKhXXXId",
        "outputId": "ae4b9028-cdc8-456a-f61f-081523d1307b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Data split using temporal_agg method.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Data split using temporal_agg method.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Remember to mask labels in GNN evaluation.\n",
              " - Train: no mask \n",
              " - Val: mask y_lab\u001b[1m[\u001b[0m:t1\u001b[1m]\u001b[0m \u001b[1m(\u001b[0monly evaluate labels y_lab\u001b[1m)\u001b[0m \n",
              " - Test: mask y_lab\u001b[1m[\u001b[0m:t2\u001b[1m]\u001b[0m \u001b[1m(\u001b[0monly evaluate labels y_lab\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Remember to mask labels in GNN evaluation.\n",
              " - Train: no mask \n",
              " - Val: mask y_lab<span style=\"font-weight: bold\">[</span>:t1<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">(</span>only evaluate labels y_lab<span style=\"font-weight: bold\">)</span> \n",
              " - Test: mask y_lab<span style=\"font-weight: bold\">[</span>:t2<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">(</span>only evaluate labels y_lab<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 1.16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_feats = ['sent_amount_usd', 'received_amount_usd', 'timestamp_scaled']\n",
        "X_train, X_test, X_val = pl.numerical_scaling(numerical_feats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj85C3uPud5g",
        "outputId": "c691dcec-8803-424d-ed71-177fe4d224b6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.08s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_features = ['edge_id','received_amount', 'received_currency','sent_amount',\n",
        "                 'sent_currency', 'payment_type', 'sent_amount_usd',\n",
        "                 'hour_of_day', 'day_of_week', 'seconds_since_midnight',\n",
        "                 'timestamp_scaled']\n",
        "node_features = ['from_bank'] #,'degree_centrality_sent_amount','pagerank_sent_amount', 'degree_centrality_received_amount', 'pagerank_received_amount']\n",
        "train_data, val_data, test_data = pl.generate_tensors(edge_features,node_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1XvFGVCttaPk",
        "outputId": "5aaaa3c4-26a7-4bc3-b089-95b0ad36e0db"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating tensors\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Generating tensors<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Dataset: train\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Dataset: train\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Index Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m875630\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, num_edges\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Index Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">875630</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, num_edges<span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Attribute Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m875630\u001b[0m, \u001b[1;36m11\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Attribute Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">875630</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Node Attribute Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m107583\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Node Attribute Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">107583</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Labels Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m875630\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Labels Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">875630</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Dataset: val\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Dataset: val\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Index Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1063265\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, num_edges\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Index Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1063265</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, num_edges<span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Attribute Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1063265\u001b[0m, \u001b[1;36m11\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Attribute Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1063265</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Node Attribute Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m107583\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Node Attribute Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">107583</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Labels Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1063265\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Labels Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1063265</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Dataset: test\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Dataset: test\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Index Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1250901\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, num_edges\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Index Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1250901</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, num_edges<span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Attribute Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1250901\u001b[0m, \u001b[1;36m11\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Attribute Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1250901</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Node Attribute Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m107583\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Node Attribute Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">107583</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Edge Labels Shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1250901\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mshould be \u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Edge Labels Shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1250901</span><span style=\"font-weight: bold\">])</span> <span style=\"font-weight: bold\">(</span>should be <span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.25s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GNNs"
      ],
      "metadata": {
        "id": "XYsAXFzI4fGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cannot use GCN or GAT!\n",
        "\n",
        "* The Graph Convolutional Network (GCN), implemented with `GCNConv`, only aggregates features from neighboring nodes and does not use edge attributes in its message passing.\n",
        "* Graph Attention Networks (GAT), implemented with `GATConv`, allows edge attention weights, which can indirectly incorporate edge attributes. Problem: If all nodes have the same feature vector (e.g., initialized to 1), then the computed attention scores will be the same for all edges. We'd need to modify GAT to use edge features meaningfully in the attention computation.\n",
        "\n",
        "`GINeConv`\n",
        "* Directly includes edge attributes in message passing using an MLP-based edge transformation.\n",
        "\n",
        "`EdgeConv`\n",
        "* dynamically computes edge embeddings and updates node features based on edges\n",
        "\n",
        "**We'll be using GINeConv moving forward.**"
      ],
      "metadata": {
        "id": "ZykVSu2wzzra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If on GPU, do as below\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK8WuSjbAUHO",
        "outputId": "13982f36-5bc2-4c4a-c927-285bad73e143"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "\n",
            "⏱️ Execution time: 0.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "dMhq078Or-kt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EdgeGINE(nn.Module):\n",
        "    def __init__(self, n_node_feats, n_edge_feats, n_hidden=64):\n",
        "        super(EdgeGINE, self).__init__()\n",
        "\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_node_feats = n_node_feats\n",
        "        self.n_edge_feats = n_edge_feats\n",
        "\n",
        "        # Linear to embed node and edges\n",
        "        self.node_emb = nn.Linear(self.n_node_feats, self.n_hidden) # [num_nodes, n_hidden]\n",
        "        self.edge_emb = nn.Linear(self.n_edge_feats, self.n_hidden) # [num_edges, n_hidden]\n",
        "\n",
        "        # MLP that processes edge features, passed into GINEConv\n",
        "        nn_edge = Sequential(Linear(self.n_hidden, self.n_hidden), ReLU(), Linear(self.n_hidden, self.n_hidden))\n",
        "\n",
        "        # Two GINEConv layers using nn_edge when it needs to process edge attributes\n",
        "        self.gine1 = GINEConv(nn_edge, edge_dim=self.n_hidden, train_eps=True)\n",
        "        self.gine2 = GINEConv(nn_edge, edge_dim=self.n_hidden, train_eps=True)\n",
        "\n",
        "        # Edge updates MLPs\n",
        "        self.emlp1 = Sequential(\n",
        "                nn.Linear(3 * self.n_hidden, self.n_hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(self.n_hidden, self.n_hidden),\n",
        "            )\n",
        "        self.emlp2 = Sequential(\n",
        "                nn.Linear(3 * self.n_hidden, self.n_hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(self.n_hidden, self.n_hidden),\n",
        "            )\n",
        "\n",
        "        # MLP for edge classification\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(3 * self.n_hidden, 128), # src, dest, edge\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        \"\"\"\n",
        "        x: Node features (or placeholder embeddings if None)\n",
        "        edge_index: Edge list (2, n_edges)\n",
        "        edge_attr: Edge features (n_edges, self.n_edge_feats)\n",
        "        \"\"\"\n",
        "        src, dest = edge_index\n",
        "        if x is None:  # If no node features, use trainable embeddings\n",
        "            x = torch.ones((edge_index.max().item() + 1, 1), device=device)\n",
        "\n",
        "        # Create some initial embeddings for nodes and edges\n",
        "        x = self.node_emb(x) # MLP\n",
        "        edge_attr = self.edge_emb(edge_attr) # MLP\n",
        "        x, edge_attr, edge_index = x.to(device), edge_attr.to(device), edge_index.to(device)\n",
        "\n",
        "        # Pass nodes and edges through GINE layer1\n",
        "        x = x + F.relu(self.gine1(x, edge_index, edge_attr))\n",
        "\n",
        "        # Update edges with MLP1\n",
        "        edge_attr = edge_attr + self.emlp1(torch.cat([x[src], x[dest], edge_attr], dim=-1)) / 2\n",
        "\n",
        "        # Pass nodes and edges through GINE layer2\n",
        "        x = F.relu(self.gine1(x, edge_index, edge_attr))\n",
        "\n",
        "        # Update edges with MLP2\n",
        "        edge_attr = edge_attr + self.emlp2(torch.cat([x[src], x[dest], edge_attr], dim=-1)) / 2\n",
        "\n",
        "        # Get output for classification\n",
        "        src_embed, dest_embed = x[src], x[dest]\n",
        "        edge_inputs = torch.cat([src_embed, dest_embed, edge_attr], dim=1)\n",
        "        edge_logits = self.mlp(edge_inputs).squeeze(1)\n",
        "\n",
        "        return edge_logits\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuOv1oly1FYf",
        "outputId": "74f91a2a-c070-4b76-8009-4e47d45f3b52"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create data loaders with `LinkNeighborLoader`\n",
        "Goal: Create data loaders - split into batches using `LinkNeighborLoader`, incorporating masking in the loading process & batching\n",
        "\n",
        "**LinkNeighborLoader:**\n",
        "\n",
        "**num_neighbors:** how many neighbors are sampled per node -- only sampling a subgraph around each edge in a batch. it is size [x,y] because we have 2 layers (sample x nodes in layer 1 and y nodes in layer 2).\n",
        "- Let’s say your batch contains 100 edges, and each edge touches two nodes (source and destination). Then LinkNeighborLoader will:\n",
        "  - Identify all unique nodes from those 100 edges\n",
        "  - For each of those nodes:\n",
        "      - Sample 10 neighbors (for layer 1)\n",
        "      - Then, for each of those neighbors, sample another 10 neighbors (for layer 2)\n",
        "  - Build a mini subgraph for this batch using only those sampled nodes and edges\n",
        "- Imagine you're doing link prediction for a social network:\n",
        "  - batch_size = 1024 means you're analyzing 1024 friend requests at a time\n",
        "  - num_neighbors = [10, 10] means for each person in the request, you look at:\n",
        "    - Their 10 direct friends\n",
        "    - And 10 friends-of-friends per direct friend"
      ],
      "metadata": {
        "id": "xuqmCJSuroDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move data to GPU if using\n",
        "tr_data = train_data.to(device)\n",
        "val_data = val_data.to(device)\n",
        "te_data = test_data.to(device)\n",
        "\n",
        "batch_size=8192\n",
        "num_neighbors=[100,100]\n",
        "\n",
        "t1 = int(len(pl.df) * 0.7)\n",
        "t2 = int(len(pl.df) * 0.85)\n",
        "\n",
        "# Indices of *labels* we will evaluate for each loader\n",
        "tr_inds = torch.tensor(np.arange(0, t1), device=device)\n",
        "val_inds = torch.tensor(np.arange(t1, t2), device=device)\n",
        "te_inds = torch.tensor(np.arange(t2, len(pl.df)), device=device)\n",
        "\n",
        "# Create data loaders, and restrict evaluation to correct edges for val and test\n",
        "tr_loader = LinkNeighborLoader(data=tr_data, dataset=[tr_data], edge_label_index=tr_data.edge_index, edge_label=tr_data.y,\n",
        "                               num_neighbors=num_neighbors, batch_size=batch_size, shuffle=True)\n",
        "val_loader = LinkNeighborLoader(data=val_data,dataset=[val_data], num_neighbors=num_neighbors, edge_label_index=val_data.edge_index[:, val_inds],\n",
        "                                edge_label=val_data.y[val_inds], batch_size=batch_size, shuffle=False)\n",
        "te_loader =  LinkNeighborLoader(data=te_data,dataset=[te_data], num_neighbors=num_neighbors, edge_label_index=te_data.edge_index[:, te_inds],\n",
        "                        edge_label=te_data.y[te_inds], batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "GwnBlVBbMUhb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12b454c8-ef9f-4994-cb13-befd3bf01f9b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.05s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model & optimizer\n",
        "num_edge_features = len(edge_features)-1 # num edge feats - edge_id\n",
        "num_node_features = 1\n",
        "model = EdgeGINE(num_node_features, num_edge_features).to(device)\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "criterion = BCEWithLogitsLoss(pos_weight=torch.tensor([10.0], device=device))\n",
        "\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6kO8RdcjVFo",
        "outputId": "87fe98ed-6d2a-4b12-d310-09f87f3dcee2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83523\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EdgeGINE(\n",
              "  (node_emb): Linear(in_features=1, out_features=64, bias=True)\n",
              "  (edge_emb): Linear(in_features=10, out_features=64, bias=True)\n",
              "  (gine1): GINEConv(nn=Sequential(\n",
              "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
              "  ))\n",
              "  (gine2): GINEConv(nn=Sequential(\n",
              "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
              "  ))\n",
              "  (emlp1): Sequential(\n",
              "    (0): Linear(in_features=192, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
              "  )\n",
              "  (emlp2): Sequential(\n",
              "    (0): Linear(in_features=192, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
              "  )\n",
              "  (mlp): Sequential(\n",
              "    (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.01s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "fVR6KaSpsd71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, loss_fn, tr_loader, val_loader, threshold=0.5, epochs=20):\n",
        "\n",
        "    # Metrics\n",
        "    acc_fn = BinaryAccuracy(threshold=threshold).to(device)\n",
        "    prec_fn = BinaryPrecision(threshold=threshold).to(device)\n",
        "    rec_fn = BinaryRecall(threshold=threshold).to(device)\n",
        "    f1_fn = BinaryF1Score(threshold=threshold).to(device)\n",
        "    pr_auc_fn = BinaryAveragePrecision().to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_preds, train_targets, train_probs = [], [], []\n",
        "\n",
        "        for batch in tqdm(tr_loader, desc=f\"Epoch {epoch+1} Training\"):\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Get indices of seed edges for this batch\n",
        "            batch_input_ids = batch.input_id.detach().cpu()  # maps to tr_inds\n",
        "            batch_edge_inds = tr_inds[batch_input_ids]       # global edge indices\n",
        "            batch_edge_ids = tr_data.edge_attr[batch_edge_inds, 0].cpu()  # edge ID column\n",
        "\n",
        "            # Find which edges in this batch are seed edges\n",
        "            edge_ids_in_batch = batch.edge_attr[:, 0].detach().cpu()\n",
        "            mask = torch.isin(edge_ids_in_batch, batch_edge_ids).to(device)\n",
        "\n",
        "            # Remove edge_id from features before forward pass\n",
        "            batch.edge_attr = batch.edge_attr[:, 1:]\n",
        "\n",
        "            # Forward pass of model\n",
        "            logits = model(batch.x, batch.edge_index, batch.edge_attr)\n",
        "            logits = logits[mask] # Restrict to seed edges\n",
        "            target = batch.y[mask] # Restrict to seed edges\n",
        "            batch_probs = torch.sigmoid(logits)\n",
        "            batch_preds = (batch_probs > threshold).long()\n",
        "\n",
        "            # Calculate batch loss & backpropagate\n",
        "            loss = loss_fn(logits, target.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Running results\n",
        "            train_loss += loss.item() * logits.size(0)\n",
        "            train_preds.append(batch_preds)\n",
        "            train_targets.append(target)\n",
        "            train_probs.append(batch_probs)\n",
        "\n",
        "        # Concatenate all training results\n",
        "        train_preds = torch.cat(train_preds)\n",
        "        train_targets = torch.cat(train_targets)\n",
        "        train_probs = torch.cat(train_probs)\n",
        "        train_loss /= len(train_targets)\n",
        "\n",
        "        # Compute training metrics\n",
        "        train_acc = acc_fn(train_preds, train_targets)\n",
        "        train_prec = prec_fn(train_preds, train_targets)\n",
        "        train_rec = rec_fn(train_preds, train_targets)\n",
        "        train_f1 = f1_fn(train_preds, train_targets)\n",
        "        train_pr_auc = pr_auc_fn(train_probs, train_targets)\n",
        "\n",
        "        # === Validation ===\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_preds, val_targets, val_probs = [], [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} Validation\"):\n",
        "                batch = batch.to(device)\n",
        "\n",
        "                # Get indices of seed edges for this batch\n",
        "                batch_input_ids = batch.input_id.detach().cpu()\n",
        "                batch_edge_inds = val_inds[batch_input_ids]\n",
        "                batch_edge_ids = val_data.edge_attr[batch_edge_inds, 0].cpu()\n",
        "\n",
        "                # Find which edges in this batch are seed edges\n",
        "                edge_ids_in_batch = batch.edge_attr[:, 0].detach().cpu()\n",
        "                mask = torch.isin(edge_ids_in_batch, batch_edge_ids).to(device)\n",
        "\n",
        "                # Remove edge_id from features before forward pass\n",
        "                batch.edge_attr = batch.edge_attr[:, 1:]\n",
        "\n",
        "                # Forward pass of model\n",
        "                logits = model(batch.x, batch.edge_index, batch.edge_attr)\n",
        "                logits = logits[mask]\n",
        "                target = batch.y[mask]\n",
        "                batch_probs = torch.sigmoid(logits)\n",
        "                batch_preds = (batch_probs > threshold).long()\n",
        "\n",
        "                # Calculate loss\n",
        "                loss = criterion(logits, target.float())\n",
        "\n",
        "                # Running results\n",
        "                val_loss += loss.item() * logits.size(0)\n",
        "                val_preds.append(batch_preds)\n",
        "                val_targets.append(target)\n",
        "                val_probs.append(batch_probs)\n",
        "\n",
        "        val_preds = torch.cat(val_preds)\n",
        "        val_targets = torch.cat(val_targets)\n",
        "        val_probs = torch.cat(val_probs)\n",
        "        val_loss /= len(val_targets)\n",
        "\n",
        "        val_acc = acc_fn(val_preds, val_targets)\n",
        "        val_prec = prec_fn(val_preds, val_targets)\n",
        "        val_rec = rec_fn(val_preds, val_targets)\n",
        "        val_f1 = f1_fn(val_preds, val_targets)\n",
        "        val_pr_auc = pr_auc_fn(val_probs, val_targets)\n",
        "\n",
        "        # Print every epoch\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "        print(f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "        print(f\"Train F1: {train_f1:.4f} | Val F1: {val_f1:.4f}\")\n",
        "        print(f\"Train PR-AUC: {train_pr_auc:.4f} | Val PR-AUC: {val_pr_auc:.4f}\")\n",
        "        print(f\"Train Prec: {train_prec:.4f} | Val Prec: {val_prec:.4f}\")\n",
        "        print(f\"Train Rec: {train_rec:.4f} | Val Rec: {val_rec:.4f}\")\n",
        "        print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf9W-jRoAnlc",
        "outputId": "923c1cb9-c30b-4401-9862-093b0fea8eb6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Execution time: 0.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Training\n",
        "train(model, optimizer, criterion, tr_loader, val_loader, threshold=0.5, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbTIbJHtGA5i",
        "outputId": "2d6aaf4c-118b-47f6-8cba-628f0ae4d5b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 Training: 100%|██████████| 107/107 [00:20<00:00,  5.33it/s]\n",
            "Epoch 1 Validation: 100%|██████████| 23/23 [00:01<00:00, 11.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "Train Loss: 56177.4435 | Val Loss: 48.6337\n",
            "Train Acc: 0.9510 | Val Acc: 0.9929\n",
            "Train F1: 0.0063 | Val F1: 0.0074\n",
            "Train PR-AUC: 0.0033 | Val PR-AUC: 0.0058\n",
            "Train Prec: 0.0034 | Val Prec: 0.0081\n",
            "Train Rec: 0.0474 | Val Rec: 0.0069\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 Training: 100%|██████████| 107/107 [00:20<00:00,  5.34it/s]\n",
            "Epoch 2 Validation: 100%|██████████| 23/23 [00:01<00:00, 11.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/50\n",
            "Train Loss: 39.1981 | Val Loss: 0.3005\n",
            "Train Acc: 0.9950 | Val Acc: 0.9959\n",
            "Train F1: 0.0050 | Val F1: 0.0000\n",
            "Train PR-AUC: 0.0042 | Val PR-AUC: 0.0040\n",
            "Train Prec: 0.0075 | Val Prec: 0.0000\n",
            "Train Rec: 0.0038 | Val Rec: 0.0000\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 Training: 100%|██████████| 107/107 [00:20<00:00,  5.31it/s]\n",
            "Epoch 3 Validation: 100%|██████████| 23/23 [00:01<00:00, 11.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/50\n",
            "Train Loss: 0.3008 | Val Loss: 0.2005\n",
            "Train Acc: 0.9966 | Val Acc: 0.9960\n",
            "Train F1: 0.0007 | Val F1: 0.0000\n",
            "Train PR-AUC: 0.0034 | Val PR-AUC: 0.0040\n",
            "Train Prec: 0.0175 | Val Prec: 0.0000\n",
            "Train Rec: 0.0003 | Val Rec: 0.0000\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 Training: 100%|██████████| 107/107 [00:20<00:00,  5.32it/s]\n",
            "Epoch 4 Validation: 100%|██████████| 23/23 [00:01<00:00, 11.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/50\n",
            "Train Loss: 0.2036 | Val Loss: 0.1790\n",
            "Train Acc: 0.9966 | Val Acc: 0.9960\n",
            "Train F1: 0.0007 | Val F1: 0.0000\n",
            "Train PR-AUC: 0.0034 | Val PR-AUC: 0.0040\n",
            "Train Prec: 0.0233 | Val Prec: 0.0000\n",
            "Train Rec: 0.0003 | Val Rec: 0.0000\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 Training: 100%|██████████| 107/107 [00:20<00:00,  5.31it/s]\n",
            "Epoch 5 Validation: 100%|██████████| 23/23 [00:01<00:00, 11.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/50\n",
            "Train Loss: 0.1651 | Val Loss: 0.1698\n",
            "Train Acc: 0.9967 | Val Acc: 0.9961\n",
            "Train F1: 0.0000 | Val F1: 0.0000\n",
            "Train PR-AUC: 0.0034 | Val PR-AUC: 0.0040\n",
            "Train Prec: 0.0000 | Val Prec: 0.0000\n",
            "Train Rec: 0.0000 | Val Rec: 0.0000\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 Training: 100%|██████████| 107/107 [00:20<00:00,  5.31it/s]\n",
            "Epoch 6 Validation: 100%|██████████| 23/23 [00:02<00:00, 11.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/50\n",
            "Train Loss: 0.1523 | Val Loss: 0.4439\n",
            "Train Acc: 0.9967 | Val Acc: 0.9961\n",
            "Train F1: 0.0000 | Val F1: 0.0000\n",
            "Train PR-AUC: 0.0034 | Val PR-AUC: 0.0040\n",
            "Train Prec: 0.0000 | Val Prec: 0.0000\n",
            "Train Rec: 0.0000 | Val Rec: 0.0000\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 Training: 100%|██████████| 107/107 [00:20<00:00,  5.30it/s]\n",
            "Epoch 7 Validation: 100%|██████████| 23/23 [00:01<00:00, 11.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/50\n",
            "Train Loss: 0.1804 | Val Loss: 0.1701\n",
            "Train Acc: 0.9966 | Val Acc: 0.9959\n",
            "Train F1: 0.0000 | Val F1: 0.0000\n",
            "Train PR-AUC: 0.0034 | Val PR-AUC: 0.0039\n",
            "Train Prec: 0.0000 | Val Prec: 0.0000\n",
            "Train Rec: 0.0000 | Val Rec: 0.0000\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 Training: 100%|██████████| 107/107 [00:20<00:00,  5.30it/s]\n",
            "Epoch 8 Validation: 100%|██████████| 23/23 [00:01<00:00, 11.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/50\n",
            "Train Loss: 0.1485 | Val Loss: 0.1686\n",
            "Train Acc: 0.9967 | Val Acc: 0.9960\n",
            "Train F1: 0.0000 | Val F1: 0.0000\n",
            "Train PR-AUC: 0.0033 | Val PR-AUC: 0.0039\n",
            "Train Prec: 0.0000 | Val Prec: 0.0000\n",
            "Train Rec: 0.0000 | Val Rec: 0.0000\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 Training: 100%|██████████| 107/107 [00:20<00:00,  5.28it/s]\n",
            "Epoch 9 Validation: 100%|██████████| 23/23 [00:01<00:00, 11.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/50\n",
            "Train Loss: 0.1467 | Val Loss: 0.1680\n",
            "Train Acc: 0.9967 | Val Acc: 0.9960\n",
            "Train F1: 0.0000 | Val F1: 0.0000\n",
            "Train PR-AUC: 0.0034 | Val PR-AUC: 0.0039\n",
            "Train Prec: 0.0000 | Val Prec: 0.0000\n",
            "Train Rec: 0.0000 | Val Rec: 0.0000\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 Training: 100%|██████████| 107/107 [00:20<00:00,  5.26it/s]\n",
            "Epoch 10 Validation: 100%|██████████| 23/23 [00:01<00:00, 11.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/50\n",
            "Train Loss: 0.1464 | Val Loss: 0.1675\n",
            "Train Acc: 0.9967 | Val Acc: 0.9960\n",
            "Train F1: 0.0000 | Val F1: 0.0000\n",
            "Train PR-AUC: 0.0035 | Val PR-AUC: 0.0039\n",
            "Train Prec: 0.0000 | Val Prec: 0.0000\n",
            "Train Rec: 0.0000 | Val Rec: 0.0000\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 Training:  70%|███████   | 75/107 [00:14<00:06,  5.32it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Alternative loss functions"
      ],
      "metadata": {
        "id": "kc0UMVbcj8FY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Use focal loss to focus on rare positives\n",
        "# class FocalLoss(torch.nn.Module):\n",
        "#     def __init__(self, gamma=2.0, alpha=0.25):\n",
        "#         super().__init__()\n",
        "#         self.gamma = gamma\n",
        "#         self.alpha = alpha\n",
        "\n",
        "#     def forward(self, logits, targets):\n",
        "#         bce_loss = F.binary_cross_entropy_with_logits(logits, targets, reduction=\"none\")\n",
        "#         pt = torch.exp(-bce_loss)  # Probabilities of correct classification\n",
        "#         focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
        "#         return focal_loss.mean()\n",
        "\n",
        "# class HybridLoss(torch.nn.Module):\n",
        "#     \"\"\"Hybrid Loss that balances BCE (for accuracy) and Focal Loss (for recall)\"\"\"\n",
        "#     def __init__(self, alpha=0.25, gamma=2.0, focal_weight=0.5):\n",
        "#         super().__init__()\n",
        "#         self.bce = torch.nn.BCEWithLogitsLoss()\n",
        "#         self.alpha = alpha\n",
        "#         self.gamma = gamma\n",
        "#         self.focal_weight = focal_weight  # Weighting factor between BCE and Focal Loss\n",
        "\n",
        "#     def forward(self, logits, targets):\n",
        "#         # BCE Loss\n",
        "#         bce_loss = self.bce(logits, targets.float())\n",
        "\n",
        "#         # Focal Loss\n",
        "#         probs = torch.sigmoid(logits)\n",
        "#         bce_loss_per_sample = F.binary_cross_entropy_with_logits(logits, targets.float(), reduction=\"none\")\n",
        "#         focal_loss = self.alpha * (1 - torch.exp(-bce_loss_per_sample)) ** self.gamma * bce_loss_per_sample\n",
        "#         focal_loss = focal_loss.mean()\n",
        "\n",
        "#         # Combine BCE and Focal Loss\n",
        "#         total_loss = (1 - self.focal_weight) * bce_loss + self.focal_weight * focal_loss\n",
        "#         return total_loss\n",
        "\n",
        "# criterion = FocalLoss(gamma=2.0, alpha=0.25)\n",
        "#criterion = HybridLoss(focal_weight=0.3)  # Adjust weight (0.3-0.6 works well)"
      ],
      "metadata": {
        "id": "GBrGftrdj2Ka"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}