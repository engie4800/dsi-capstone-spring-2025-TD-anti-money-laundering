{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch-geometric torch-sparse torch-scatter torch-cluster pyg-lib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Izp8pSiQJ75",
        "outputId": "af82f39f-e15e-44a8-a065-8394324c0e99"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping pyg-lib as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.5.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GQ8yeKZQmrk",
        "outputId": "6dbb3201-12bb-42a2-ed6e-ff8107fb6abc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl (908.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.1%2Bcu124-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1) (3.0.2)\n",
            "Installing collected packages: triton, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-2.5.1+cu124 torchaudio-2.5.1+cu124 torchvision-0.20.1+cu124 triton-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric \\\n",
        "  torch-sparse \\\n",
        "  torch-scatter \\\n",
        "  torch-cluster \\\n",
        "  pyg-lib \\\n",
        "  -f https://data.pyg.org/whl/torch-2.5.1+cu124.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWLNQ03AQP26",
        "outputId": "7c068ef6-fb90-4d97-ab2a-53c57ef1c079"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.5.1+cu124.html\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_sparse-0.6.18%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_scatter-2.1.2%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_cluster-1.6.3%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyg-lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/pyg_lib-0.4.0%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.14)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.14.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter, pyg-lib, torch-sparse, torch-cluster, torch-geometric\n",
            "Successfully installed pyg-lib-0.4.0+pt25cu124 torch-cluster-1.6.3+pt25cu124 torch-geometric-2.6.1 torch-scatter-2.1.2+pt25cu124 torch-sparse-0.6.18+pt25cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import GCNConv, GINEConv, BatchNorm, Linear, GATConv, PNAConv, RGCNConv, to_hetero, summary\n",
        "from torch_geometric.data import Data, HeteroData\n",
        "from torch_geometric.typing import OptTensor\n",
        "from torch_geometric.utils import degree\n",
        "from torch_geometric.transforms import BaseTransform\n",
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import tqdm\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import json\n",
        "from typing import Union\n",
        "from google.colab import drive\n",
        "\n",
        "content_base = \"/content/drive\"\n",
        "drive.mount(content_base)\n",
        "\n",
        "data_dir = os.path.join(content_base, \"My Drive/Capstone/data\")\n",
        "data_file = os.path.join(data_dir, \"HI-Small_25.csv\")"
      ],
      "metadata": {
        "id": "Q4WhlQriybXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5222ad00-6bd4-4df5-d77f-8534c23c96f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from types import SimpleNamespace\n",
        "\n",
        "args = SimpleNamespace(\n",
        "    # Adaptations\n",
        "    emlps=False,\n",
        "    reverse_mp=False,\n",
        "    ports=False,\n",
        "    tds=False,\n",
        "    ego=False,\n",
        "\n",
        "    # Model parameters\n",
        "    batch_size=8192,\n",
        "    n_epochs=100,\n",
        "    num_neighs=[100, 100],\n",
        "\n",
        "    # Misc\n",
        "    seed=1,\n",
        "    tqdm=False,\n",
        "    data='Small_HI',\n",
        "    model='gin',\n",
        "    testing=False,\n",
        "    save_model=False,\n",
        "    unique_name=False,\n",
        "    finetune=False,\n",
        "    inference=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "_1tMIvGZw9jJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Format Data"
      ],
      "metadata": {
        "id": "pkpw1I-767un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inPath = data_file\n",
        "outPath = \"formatted_transactions.csv\""
      ],
      "metadata": {
        "id": "qckZt58A69ZE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw = pd.read_csv(inPath, dtype=str)\n",
        "raw.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLsWUQ657cp7",
        "outputId": "6f7cf767-b187-418a-8d4d-842e0e66c564"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1269587, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "currency = dict()\n",
        "paymentFormat = dict()\n",
        "bankAcc = dict()\n",
        "account = dict()\n",
        "\n",
        "def get_dict_val(name, collection):\n",
        "    if name in collection:\n",
        "        val = collection[name]\n",
        "    else:\n",
        "        val = len(collection)\n",
        "        collection[name] = val\n",
        "    return val\n",
        "\n",
        "header = \"EdgeID,from_id,to_id,Timestamp,\\\n",
        "Amount Sent,Sent Currency,Amount Received,Received Currency,\\\n",
        "Payment Format,Is Laundering\\n\"\n",
        "\n",
        "firstTs = -1"
      ],
      "metadata": {
        "id": "2n2uKyUz8N45"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(outPath, 'w') as writer:\n",
        "    writer.write(header)\n",
        "\n",
        "    for i, row in raw.iterrows():\n",
        "        datetime_object = datetime.strptime(row[\"Timestamp\"], '%Y/%m/%d %H:%M')\n",
        "        ts = datetime_object.timestamp()\n",
        "        day = datetime_object.day\n",
        "        month = datetime_object.month\n",
        "        year = datetime_object.year\n",
        "        hour = datetime_object.hour\n",
        "        minute = datetime_object.minute\n",
        "\n",
        "        if firstTs == -1:\n",
        "            startTime = datetime(year, month, day)\n",
        "            firstTs = startTime.timestamp() - 10\n",
        "\n",
        "        ts = ts - firstTs\n",
        "\n",
        "        cur1 = get_dict_val(row[\"Receiving Currency\"], currency)\n",
        "        cur2 = get_dict_val(row[\"Payment Currency\"], currency)\n",
        "\n",
        "        fmt = get_dict_val(row[\"Payment Format\"], paymentFormat)\n",
        "\n",
        "        fromAccIdStr = row[\"From Bank\"] + row.iloc[2]\n",
        "        fromId = get_dict_val(fromAccIdStr, account)\n",
        "\n",
        "        toAccIdStr = row[\"To Bank\"] + row.iloc[4]\n",
        "        toId = get_dict_val(toAccIdStr, account)\n",
        "\n",
        "        amountReceivedOrig = float(row[\"Amount Received\"])\n",
        "        amountPaidOrig = float(row[\"Amount Paid\"])\n",
        "\n",
        "        isl = int(row[\"Is Laundering\"])\n",
        "\n",
        "        line = f'{i},{fromId},{toId},{ts},{amountPaidOrig},{cur2},{amountReceivedOrig},{cur1},{fmt},{isl}\\n'\n",
        "        writer.write(line)\n",
        "\n",
        "formatted = pd.read_csv(outPath)\n",
        "formatted = formatted.sort_values(by=\"Timestamp\")\n",
        "formatted.to_csv(outPath, index=False)"
      ],
      "metadata": {
        "id": "1RddqiZF8TrW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formatted.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tjkufd4-IzxK",
        "outputId": "d305a6ad-148e-4af8-f87b-3cc4b6e729b0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          EdgeID  from_id   to_id  Timestamp  Amount Sent  Sent Currency  \\\n",
              "792040    792040   307178  307178       10.0       120.17             10   \n",
              "161159    161159   159644  159645       10.0         0.01              4   \n",
              "1088474  1088474   126804  126804       10.0    430660.08              2   \n",
              "1088464  1088464   145444  214590       10.0       752.17              4   \n",
              "534152    534152   254735  254735       10.0         7.57              9   \n",
              "\n",
              "         Amount Received  Received Currency  Payment Format  Is Laundering  \n",
              "792040            120.17                 10               0              0  \n",
              "161159              0.01                  4               1              0  \n",
              "1088474        430660.08                  2               0              0  \n",
              "1088464           752.17                  4               2              0  \n",
              "534152              7.57                  9               0              0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce4c7cb5-ed9f-4e20-a694-8bd3c707cc76\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EdgeID</th>\n",
              "      <th>from_id</th>\n",
              "      <th>to_id</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Amount Sent</th>\n",
              "      <th>Sent Currency</th>\n",
              "      <th>Amount Received</th>\n",
              "      <th>Received Currency</th>\n",
              "      <th>Payment Format</th>\n",
              "      <th>Is Laundering</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>792040</th>\n",
              "      <td>792040</td>\n",
              "      <td>307178</td>\n",
              "      <td>307178</td>\n",
              "      <td>10.0</td>\n",
              "      <td>120.17</td>\n",
              "      <td>10</td>\n",
              "      <td>120.17</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161159</th>\n",
              "      <td>161159</td>\n",
              "      <td>159644</td>\n",
              "      <td>159645</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>4</td>\n",
              "      <td>0.01</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1088474</th>\n",
              "      <td>1088474</td>\n",
              "      <td>126804</td>\n",
              "      <td>126804</td>\n",
              "      <td>10.0</td>\n",
              "      <td>430660.08</td>\n",
              "      <td>2</td>\n",
              "      <td>430660.08</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1088464</th>\n",
              "      <td>1088464</td>\n",
              "      <td>145444</td>\n",
              "      <td>214590</td>\n",
              "      <td>10.0</td>\n",
              "      <td>752.17</td>\n",
              "      <td>4</td>\n",
              "      <td>752.17</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534152</th>\n",
              "      <td>534152</td>\n",
              "      <td>254735</td>\n",
              "      <td>254735</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.57</td>\n",
              "      <td>9</td>\n",
              "      <td>7.57</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce4c7cb5-ed9f-4e20-a694-8bd3c707cc76')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce4c7cb5-ed9f-4e20-a694-8bd3c707cc76 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce4c7cb5-ed9f-4e20-a694-8bd3c707cc76');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a0aca7c9-2ad1-4e1e-975e-894b754ba294\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a0aca7c9-2ad1-4e1e-975e-894b754ba294')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a0aca7c9-2ad1-4e1e-975e-894b754ba294 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "formatted"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing and Data Loading"
      ],
      "metadata": {
        "id": "vZtvqoXf69v7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed: int = 0) -> None:\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
      ],
      "metadata": {
        "id": "5y2H-fu0yOKv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_adj_nodes_with_times(data):\n",
        "    num_nodes = data.num_nodes\n",
        "    timestamps = torch.zeros((data.edge_index.shape[1], 1)) if data.timestamps is None else data.timestamps.reshape((-1,1))\n",
        "    edges = torch.cat((data.edge_index.T, timestamps), dim=1) if not isinstance(data, HeteroData) else torch.cat((data['node', 'to', 'node'].edge_index.T, timestamps), dim=1)\n",
        "    adj_list_out = dict([(i, []) for i in range(num_nodes)])\n",
        "    adj_list_in = dict([(i, []) for i in range(num_nodes)])\n",
        "    for u,v,t in edges:\n",
        "        u,v,t = int(u), int(v), int(t)\n",
        "        adj_list_out[u] += [(v, t)]\n",
        "        adj_list_in[v] += [(u, t)]\n",
        "    return adj_list_in, adj_list_out\n",
        "\n",
        "def to_adj_edges_with_times(data):\n",
        "    num_nodes = data.num_nodes\n",
        "    timestamps = torch.zeros((data.edge_index.shape[1], 1)) if data.timestamps is None else data.timestamps.reshape((-1,1))\n",
        "    edges = torch.cat((data.edge_index.T, timestamps), dim=1)\n",
        "    # calculate adjacent edges with times per node\n",
        "    adj_edges_out = dict([(i, []) for i in range(num_nodes)])\n",
        "    adj_edges_in = dict([(i, []) for i in range(num_nodes)])\n",
        "    for i, (u,v,t) in enumerate(edges):\n",
        "        u,v,t = int(u), int(v), int(t)\n",
        "        adj_edges_out[u] += [(i, v, t)]\n",
        "        adj_edges_in[v] += [(i, u, t)]\n",
        "    return adj_edges_in, adj_edges_out\n",
        "\n",
        "def ports(edge_index, adj_list):\n",
        "    ports = torch.zeros(edge_index.shape[1], 1)\n",
        "    ports_dict = {}\n",
        "    for v, nbs in adj_list.items():\n",
        "        if len(nbs) < 1: continue\n",
        "        a = np.array(nbs)\n",
        "        a = a[a[:, -1].argsort()]\n",
        "        _, idx = np.unique(a[:,[0]],return_index=True,axis=0)\n",
        "        nbs_unique = a[np.sort(idx)][:,0]\n",
        "        for i, u in enumerate(nbs_unique):\n",
        "            ports_dict[(u,v)] = i\n",
        "    for i, e in enumerate(edge_index.T):\n",
        "        ports[i] = ports_dict[tuple(e.numpy())]\n",
        "    return ports\n",
        "\n",
        "def time_deltas(data, adj_edges_list):\n",
        "    time_deltas = torch.zeros(data.edge_index.shape[1], 1)\n",
        "    if data.timestamps is None:\n",
        "        return time_deltas\n",
        "    for v, edges in adj_edges_list.items():\n",
        "        if len(edges) < 1: continue\n",
        "        a = np.array(edges)\n",
        "        a = a[a[:, -1].argsort()]\n",
        "        a_tds = [0] + [a[i+1,-1] - a[i,-1] for i in range(a.shape[0]-1)]\n",
        "        tds = np.hstack((a[:,0].reshape(-1,1), np.array(a_tds).reshape(-1,1)))\n",
        "        for i,td in tds:\n",
        "            time_deltas[i] = td\n",
        "    return time_deltas\n",
        "\n",
        "class GraphData(Data):\n",
        "    '''This is the homogenous graph object we use for GNN training if reverse MP is not enabled'''\n",
        "    def __init__(\n",
        "        self, x: OptTensor = None, edge_index: OptTensor = None, edge_attr: OptTensor = None, y: OptTensor = None, pos: OptTensor = None,\n",
        "        readout: str = 'edge',\n",
        "        num_nodes: int = None,\n",
        "        timestamps: OptTensor = None,\n",
        "        node_timestamps: OptTensor = None,\n",
        "        **kwargs\n",
        "      ):\n",
        "\n",
        "        super().__init__(x, edge_index, edge_attr, y, pos, **kwargs)\n",
        "        self.readout = readout\n",
        "        self.loss_fn = 'ce'\n",
        "        self.num_nodes = int(self.x.shape[0])\n",
        "        self.node_timestamps = node_timestamps\n",
        "        if timestamps is not None:\n",
        "            self.timestamps = timestamps\n",
        "        elif edge_attr is not None:\n",
        "            self.timestamps = edge_attr[:,0].clone()\n",
        "        else:\n",
        "            self.timestamps = None\n",
        "\n",
        "    def add_ports(self):\n",
        "        '''Adds port numberings to the edge features'''\n",
        "        reverse_ports = True\n",
        "        adj_list_in, adj_list_out = to_adj_nodes_with_times(self)\n",
        "        in_ports = ports(self.edge_index, adj_list_in)\n",
        "        out_ports = [ports(self.edge_index.flipud(), adj_list_out)] if reverse_ports else []\n",
        "        self.edge_attr = torch.cat([self.edge_attr, in_ports] + out_ports, dim=1)\n",
        "        return self\n",
        "\n",
        "    def add_time_deltas(self):\n",
        "        '''Adds time deltas (i.e. the time between subsequent transactions) to the edge features'''\n",
        "        reverse_tds = True\n",
        "        adj_list_in, adj_list_out = to_adj_edges_with_times(self)\n",
        "        in_tds = time_deltas(self, adj_list_in)\n",
        "        out_tds = [time_deltas(self, adj_list_out)] if reverse_tds else []\n",
        "        self.edge_attr = torch.cat([self.edge_attr, in_tds] + out_tds, dim=1)\n",
        "        return self\n",
        "\n",
        "class HeteroGraphData(HeteroData):\n",
        "    '''This is the heterogenous graph object we use for GNN training if reverse MP is enabled'''\n",
        "    def __init__(\n",
        "        self,\n",
        "        readout: str = 'edge',\n",
        "        **kwargs\n",
        "        ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.readout = readout\n",
        "\n",
        "    @property\n",
        "    def num_nodes(self):\n",
        "        return self['node'].x.shape[0]\n",
        "\n",
        "    @property\n",
        "    def timestamps(self):\n",
        "        return self['node', 'to', 'node'].timestamps\n",
        "\n",
        "    def add_ports(self):\n",
        "        '''Adds port numberings to the edge features'''\n",
        "        adj_list_in, adj_list_out = to_adj_nodes_with_times(self)\n",
        "        in_ports = ports(self['node', 'to', 'node'].edge_index, adj_list_in)\n",
        "        out_ports = ports(self['node', 'rev_to', 'node'].edge_index, adj_list_out)\n",
        "        self['node', 'to', 'node'].edge_attr = torch.cat([self['node', 'to', 'node'].edge_attr, in_ports], dim=1)\n",
        "        self['node', 'rev_to', 'node'].edge_attr = torch.cat([self['node', 'rev_to', 'node'].edge_attr, out_ports], dim=1)\n",
        "        return self\n",
        "\n",
        "    def add_time_deltas(self):\n",
        "        '''Adds time deltas (i.e. the time between subsequent transactions) to the edge features'''\n",
        "        adj_list_in, adj_list_out = to_adj_edges_with_times(self)\n",
        "        in_tds = time_deltas(self, adj_list_in)\n",
        "        out_tds = time_deltas(self, adj_list_out)\n",
        "        self['node', 'to', 'node'].edge_attr = torch.cat([self['node', 'to', 'node'].edge_attr, in_tds], dim=1)\n",
        "        self['node', 'rev_to', 'node'].edge_attr = torch.cat([self['node', 'rev_to', 'node'].edge_attr, out_tds], dim=1)\n",
        "        return self\n",
        "\n",
        "def z_norm(data):\n",
        "    std = data.std(0).unsqueeze(0)\n",
        "    std = torch.where(std == 0, torch.tensor(1, dtype=torch.float32).cpu(), std)\n",
        "    return (data - data.mean(0).unsqueeze(0)) / std\n",
        "\n",
        "def create_hetero_obj(x,  y,  edge_index,  edge_attr, timestamps, args):\n",
        "    '''Creates a heterogenous graph object for reverse message passing'''\n",
        "    data = HeteroGraphData()\n",
        "\n",
        "    data['node'].x = x\n",
        "    data['node', 'to', 'node'].edge_index = edge_index\n",
        "    data['node', 'rev_to', 'node'].edge_index = edge_index.flipud()\n",
        "    data['node', 'to', 'node'].edge_attr = edge_attr\n",
        "    data['node', 'rev_to', 'node'].edge_attr = edge_attr\n",
        "\n",
        "    if args.ports:\n",
        "        data['node', 'rev_to', 'node'].edge_attr[:, [-1, -2]] = data['node', 'rev_to', 'node'].edge_attr[:, [-2, -1]]\n",
        "    data['node', 'to', 'node'].y = y\n",
        "    data['node', 'to', 'node'].timestamps = timestamps\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "LAWJrAgb-M6n"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(args):\n",
        "    '''Loads the AML transaction data.\n",
        "\n",
        "    1. The data is loaded from the csv and the necessary features are chosen.\n",
        "    2. The data is split into training, validation and test data.\n",
        "    3. PyG Data objects are created with the respective data splits.\n",
        "    '''\n",
        "\n",
        "    transaction_file = \"./formatted_transactions.csv\" #replace this with your path to the respective AML data objects\n",
        "    df_edges = pd.read_csv(transaction_file)\n",
        "\n",
        "    print(f'Available Edge Features: {df_edges.columns.tolist()}')\n",
        "\n",
        "    df_edges['Timestamp'] = df_edges['Timestamp'] - df_edges['Timestamp'].min()\n",
        "\n",
        "    max_n_id = df_edges.loc[:, ['from_id', 'to_id']].to_numpy().max() + 1\n",
        "    df_nodes = pd.DataFrame({'NodeID': np.arange(max_n_id), 'Feature': np.ones(max_n_id)})\n",
        "    timestamps = torch.Tensor(df_edges['Timestamp'].to_numpy())\n",
        "    y = torch.LongTensor(df_edges['Is Laundering'].to_numpy())\n",
        "\n",
        "    print(f\"Illicit ratio = {sum(y)} / {len(y)} = {sum(y) / len(y) * 100:.2f}%\")\n",
        "    print(f\"Number of nodes (holdings doing transcations) = {df_nodes.shape[0]}\")\n",
        "    print(f\"Number of transactions = {df_edges.shape[0]}\")\n",
        "\n",
        "    edge_features = ['Timestamp', 'Amount Received', 'Received Currency', 'Payment Format']\n",
        "    node_features = ['Feature']\n",
        "\n",
        "    print(f'Edge features being used: {edge_features}')\n",
        "    print(f'Node features being used: {node_features} (\"Feature\" is a placeholder feature of all 1s)')\n",
        "\n",
        "    x = torch.tensor(df_nodes.loc[:, node_features].to_numpy()).float()\n",
        "    edge_index = torch.LongTensor(df_edges.loc[:, ['from_id', 'to_id']].to_numpy().T)\n",
        "    edge_attr = torch.tensor(df_edges.loc[:, edge_features].to_numpy()).float()\n",
        "\n",
        "    n_days = int(timestamps.max() / (3600 * 24) + 1)\n",
        "    n_samples = y.shape[0]\n",
        "    print(f'number of days and transactions in the data: {n_days} days, {n_samples} transactions')\n",
        "\n",
        "    #data splitting\n",
        "    daily_irs, weighted_daily_irs, daily_inds, daily_trans = [], [], [], [] #irs = illicit ratios, inds = indices, trans = transactions\n",
        "    for day in range(n_days):\n",
        "        l = day * 24 * 3600\n",
        "        r = (day + 1) * 24 * 3600\n",
        "        day_inds = torch.where((timestamps >= l) & (timestamps < r))[0]\n",
        "        daily_irs.append(y[day_inds].float().mean())\n",
        "        weighted_daily_irs.append(y[day_inds].float().mean() * day_inds.shape[0] / n_samples)\n",
        "        daily_inds.append(day_inds)\n",
        "        daily_trans.append(day_inds.shape[0])\n",
        "\n",
        "    split_per = [0.6, 0.2, 0.2]\n",
        "    daily_totals = np.array(daily_trans)\n",
        "    d_ts = daily_totals\n",
        "    I = list(range(len(d_ts)))\n",
        "    split_scores = dict()\n",
        "    for i,j in itertools.combinations(I, 2):\n",
        "        if j >= i:\n",
        "            split_totals = [d_ts[:i].sum(), d_ts[i:j].sum(), d_ts[j:].sum()]\n",
        "            split_totals_sum = np.sum(split_totals)\n",
        "            split_props = [v/split_totals_sum for v in split_totals]\n",
        "            split_error = [abs(v-t)/t for v,t in zip(split_props, split_per)]\n",
        "            score = max(split_error) #- (split_totals_sum/total) + 1\n",
        "            split_scores[(i,j)] = score\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    i,j = min(split_scores, key=split_scores.get)\n",
        "    #split contains a list for each split (train, validation and test) and each list contains the days that are part of the respective split\n",
        "    split = [list(range(i)), list(range(i, j)), list(range(j, len(daily_totals)))]\n",
        "    print(f'Calculate split: {split}')\n",
        "\n",
        "    #Now, we seperate the transactions based on their indices in the timestamp array\n",
        "    split_inds = {k: [] for k in range(3)}\n",
        "    for i in range(3):\n",
        "        for day in split[i]:\n",
        "            split_inds[i].append(daily_inds[day]) #split_inds contains a list for each split (tr,val,te) which contains the indices of each day seperately\n",
        "\n",
        "    tr_inds = torch.cat(split_inds[0])\n",
        "    val_inds = torch.cat(split_inds[1])\n",
        "    te_inds = torch.cat(split_inds[2])\n",
        "\n",
        "    print(f\"Total train samples: {tr_inds.shape[0] / y.shape[0] * 100 :.2f}% || IR: \"\n",
        "            f\"{y[tr_inds].float().mean() * 100 :.2f}% || Train days: {split[0][:5]}\")\n",
        "    print(f\"Total val samples: {val_inds.shape[0] / y.shape[0] * 100 :.2f}% || IR: \"\n",
        "        f\"{y[val_inds].float().mean() * 100:.2f}% || Val days: {split[1][:5]}\")\n",
        "    print(f\"Total test samples: {te_inds.shape[0] / y.shape[0] * 100 :.2f}% || IR: \"\n",
        "        f\"{y[te_inds].float().mean() * 100:.2f}% || Test days: {split[2][:5]}\")\n",
        "\n",
        "    #Creating the final data objects\n",
        "    tr_x, val_x, te_x = x, x, x\n",
        "    e_tr = tr_inds.numpy()\n",
        "    e_val = np.concatenate([tr_inds, val_inds])\n",
        "\n",
        "    tr_edge_index,  tr_edge_attr,  tr_y,  tr_edge_times  = edge_index[:,e_tr],  edge_attr[e_tr],  y[e_tr],  timestamps[e_tr]\n",
        "    val_edge_index, val_edge_attr, val_y, val_edge_times = edge_index[:,e_val], edge_attr[e_val], y[e_val], timestamps[e_val]\n",
        "    te_edge_index,  te_edge_attr,  te_y,  te_edge_times  = edge_index,          edge_attr,        y,        timestamps\n",
        "\n",
        "    tr_data = GraphData (x=tr_x,  y=tr_y,  edge_index=tr_edge_index,  edge_attr=tr_edge_attr,  timestamps=tr_edge_times )\n",
        "    val_data = GraphData(x=val_x, y=val_y, edge_index=val_edge_index, edge_attr=val_edge_attr, timestamps=val_edge_times)\n",
        "    te_data = GraphData (x=te_x,  y=te_y,  edge_index=te_edge_index,  edge_attr=te_edge_attr,  timestamps=te_edge_times )\n",
        "\n",
        "    #Adding ports and time-deltas if applicable\n",
        "    if args.ports:\n",
        "        print(f\"Start: adding ports\")\n",
        "        tr_data.add_ports()\n",
        "        val_data.add_ports()\n",
        "        te_data.add_ports()\n",
        "        print(f\"Done: adding ports\")\n",
        "\n",
        "    if args.tds:\n",
        "        print(f\"Start: adding time-deltas\")\n",
        "        tr_data.add_time_deltas()\n",
        "        val_data.add_time_deltas()\n",
        "        te_data.add_time_deltas()\n",
        "        print(f\"Done: adding time-deltas\")\n",
        "\n",
        "    #Normalize data\n",
        "    tr_data.x = val_data.x = te_data.x = z_norm(tr_data.x)\n",
        "    if not args.model == 'rgcn':\n",
        "        tr_data.edge_attr, val_data.edge_attr, te_data.edge_attr = z_norm(tr_data.edge_attr), z_norm(val_data.edge_attr), z_norm(te_data.edge_attr)\n",
        "    else:\n",
        "        tr_data.edge_attr[:, :-1], val_data.edge_attr[:, :-1], te_data.edge_attr[:, :-1] = z_norm(tr_data.edge_attr[:, :-1]), z_norm(val_data.edge_attr[:, :-1]), z_norm(te_data.edge_attr[:, :-1])\n",
        "\n",
        "    #Create heterogenous if reverese MP is enabled\n",
        "    #TODO: if I observe wierd behaviour, maybe add .detach.clone() to all torch tensors, but I don't think they're attached to any computation graph just yet\n",
        "    if args.reverse_mp:\n",
        "        tr_data = create_hetero_obj(tr_data.x,  tr_data.y,  tr_data.edge_index,  tr_data.edge_attr, tr_data.timestamps, args)\n",
        "        val_data = create_hetero_obj(val_data.x,  val_data.y,  val_data.edge_index,  val_data.edge_attr, val_data.timestamps, args)\n",
        "        te_data = create_hetero_obj(te_data.x,  te_data.y,  te_data.edge_index,  te_data.edge_attr, te_data.timestamps, args)\n",
        "\n",
        "    print(f'train data object: {tr_data}')\n",
        "    print(f'validation data object: {val_data}')\n",
        "    print(f'test data object: {te_data}')\n",
        "\n",
        "    return tr_data, val_data, te_data, tr_inds, val_inds, te_inds"
      ],
      "metadata": {
        "id": "FpT-ZMxq3BTX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data, val_data, te_data, tr_inds, val_inds, te_inds = get_data(args)"
      ],
      "metadata": {
        "id": "LlY9Xc6OAE5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb72cba2-189f-44fc-d23c-6a743409530a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available Edge Features: ['EdgeID', 'from_id', 'to_id', 'Timestamp', 'Amount Sent', 'Sent Currency', 'Amount Received', 'Received Currency', 'Payment Format', 'Is Laundering']\n",
            "Illicit ratio = 1294 / 1269587 = 0.10%\n",
            "Number of nodes (holdings doing transcations) = 355002\n",
            "Number of transactions = 1269587\n",
            "Edge features being used: ['Timestamp', 'Amount Received', 'Received Currency', 'Payment Format']\n",
            "Node features being used: ['Feature'] (\"Feature\" is a placeholder feature of all 1s)\n",
            "number of days and transactions in the data: 18 days, 1269587 transactions\n",
            "Calculate split: [[0, 1, 2, 3, 4, 5], [6, 7], [8, 9, 10, 11, 12, 13, 14, 15, 16, 17]]\n",
            "Total train samples: 63.99% || IR: 0.08% || Train days: [0, 1, 2, 3, 4]\n",
            "Total val samples: 19.00% || IR: 0.11% || Val days: [6, 7]\n",
            "Total test samples: 17.00% || IR: 0.18% || Test days: [8, 9, 10, 11, 12]\n",
            "train data object: GraphData(x=[355002, 1], edge_index=[2, 812432], edge_attr=[812432, 4], y=[812432], readout='edge', loss_fn='ce', num_nodes=355002, timestamps=[812432])\n",
            "validation data object: GraphData(x=[355002, 1], edge_index=[2, 1053698], edge_attr=[1053698, 4], y=[1053698], readout='edge', loss_fn='ce', num_nodes=355002, timestamps=[1053698])\n",
            "test data object: GraphData(x=[355002, 1], edge_index=[2, 1269587], edge_attr=[1269587, 4], y=[1269587], readout='edge', loss_fn='ce', num_nodes=355002, timestamps=[1269587])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tr_data)\n",
        "print(te_data)\n",
        "print(val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58ZaywL3JtsU",
        "outputId": "77689c97-eea9-42de-c55d-7ce6bc683899"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GraphData(x=[355002, 1], edge_index=[2, 812432], edge_attr=[812432, 4], y=[812432], readout='edge', loss_fn='ce', num_nodes=355002, timestamps=[812432])\n",
            "GraphData(x=[355002, 1], edge_index=[2, 1269587], edge_attr=[1269587, 4], y=[1269587], readout='edge', loss_fn='ce', num_nodes=355002, timestamps=[1269587])\n",
            "GraphData(x=[355002, 1], edge_index=[2, 1053698], edge_attr=[1053698, 4], y=[1053698], readout='edge', loss_fn='ce', num_nodes=355002, timestamps=[1053698])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "HjYyjhjwLqLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GINe(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_gnn_layers, n_classes=2,\n",
        "                n_hidden=100, edge_updates=False, residual=True,\n",
        "                edge_dim=None, dropout=0.0, final_dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.n_hidden = n_hidden\n",
        "        self.num_gnn_layers = num_gnn_layers\n",
        "        self.edge_updates = edge_updates\n",
        "        self.final_dropout = final_dropout\n",
        "\n",
        "        self.node_emb = nn.Linear(num_features, n_hidden)\n",
        "        self.edge_emb = nn.Linear(edge_dim, n_hidden)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.emlps = nn.ModuleList()\n",
        "        self.batch_norms = nn.ModuleList()\n",
        "\n",
        "        for _ in range(self.num_gnn_layers):\n",
        "            conv = GINEConv(nn.Sequential(\n",
        "                nn.Linear(self.n_hidden, self.n_hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(self.n_hidden, self.n_hidden)\n",
        "                ), edge_dim=self.n_hidden)\n",
        "\n",
        "            if self.edge_updates: self.emlps.append(nn.Sequential(\n",
        "                nn.Linear(3 * self.n_hidden, self.n_hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(self.n_hidden, self.n_hidden),\n",
        "            ))\n",
        "            self.convs.append(conv)\n",
        "            self.batch_norms.append(BatchNorm(n_hidden))\n",
        "\n",
        "        self.mlp = nn.Sequential(Linear(n_hidden*3, 50), nn.ReLU(), nn.Dropout(self.final_dropout),Linear(50, 25), nn.ReLU(), nn.Dropout(self.final_dropout),\n",
        "                              Linear(25, n_classes))\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        src, dst = edge_index\n",
        "\n",
        "        x = self.node_emb(x)\n",
        "        edge_attr = self.edge_emb(edge_attr)\n",
        "\n",
        "        for i in range(self.num_gnn_layers):\n",
        "            x = (x + F.relu(self.batch_norms[i](self.convs[i](x, edge_index, edge_attr)))) / 2\n",
        "            if self.edge_updates:\n",
        "                edge_attr = edge_attr + self.emlps[i](torch.cat([x[src], x[dst], edge_attr], dim=-1)) / 2\n",
        "\n",
        "        x = x[edge_index.T].reshape(-1, 2 * self.n_hidden).relu()\n",
        "        x = torch.cat((x, edge_attr.view(-1, edge_attr.shape[1])), 1)\n",
        "        out = x\n",
        "\n",
        "        return self.mlp(out)\n",
        "\n",
        "class GATe(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_gnn_layers, n_classes=2, n_hidden=100, n_heads=4, edge_updates=False, edge_dim=None, dropout=0.0, final_dropout=0.5):\n",
        "        super().__init__()\n",
        "        # GAT specific code\n",
        "        tmp_out = n_hidden // n_heads\n",
        "        n_hidden = tmp_out * n_heads\n",
        "\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_heads = n_heads\n",
        "        self.num_gnn_layers = num_gnn_layers\n",
        "        self.edge_updates = edge_updates\n",
        "        self.dropout = dropout\n",
        "        self.final_dropout = final_dropout\n",
        "\n",
        "        self.node_emb = nn.Linear(num_features, n_hidden)\n",
        "        self.edge_emb = nn.Linear(edge_dim, n_hidden)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.emlps = nn.ModuleList()\n",
        "        self.batch_norms = nn.ModuleList()\n",
        "\n",
        "        for _ in range(self.num_gnn_layers):\n",
        "            conv = GATConv(self.n_hidden, tmp_out, self.n_heads, concat = True, dropout = self.dropout, add_self_loops = True, edge_dim=self.n_hidden)\n",
        "            if self.edge_updates: self.emlps.append(nn.Sequential(nn.Linear(3 * self.n_hidden, self.n_hidden),nn.ReLU(),nn.Linear(self.n_hidden, self.n_hidden),))\n",
        "            self.convs.append(conv)\n",
        "            self.batch_norms.append(BatchNorm(n_hidden))\n",
        "\n",
        "        self.mlp = nn.Sequential(Linear(n_hidden*3, 50), nn.ReLU(), nn.Dropout(self.final_dropout),Linear(50, 25), nn.ReLU(), nn.Dropout(self.final_dropout),Linear(25, n_classes))\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        src, dst = edge_index\n",
        "\n",
        "        x = self.node_emb(x)\n",
        "        edge_attr = self.edge_emb(edge_attr)\n",
        "\n",
        "        for i in range(self.num_gnn_layers):\n",
        "            x = (x + F.relu(self.batch_norms[i](self.convs[i](x, edge_index, edge_attr)))) / 2\n",
        "            if self.edge_updates:\n",
        "                edge_attr = edge_attr + self.emlps[i](torch.cat([x[src], x[dst], edge_attr], dim=-1)) / 2\n",
        "\n",
        "        # logging.debug(f\"x.shape = {x.shape}, x[edge_index.T].shape = {x[edge_index.T].shape}\")\n",
        "        x = x[edge_index.T].reshape(-1, 2 * self.n_hidden).relu()\n",
        "        # logging.debug(f\"x.shape = {x.shape}\")\n",
        "        x = torch.cat((x, edge_attr.view(-1, edge_attr.shape[1])), 1)\n",
        "        # logging.debug(f\"x.shape = {x.shape}\")\n",
        "        out = x\n",
        "\n",
        "        return self.mlp(out)\n",
        "\n",
        "class PNA(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_gnn_layers, n_classes=2,\n",
        "                n_hidden=100, edge_updates=True,\n",
        "                edge_dim=None, dropout=0.0, final_dropout=0.5, deg=None):\n",
        "        super().__init__()\n",
        "        n_hidden = int((n_hidden // 5) * 5)\n",
        "        self.n_hidden = n_hidden\n",
        "        self.num_gnn_layers = num_gnn_layers\n",
        "        self.edge_updates = edge_updates\n",
        "        self.final_dropout = final_dropout\n",
        "\n",
        "        aggregators = ['mean', 'min', 'max', 'std']\n",
        "        scalers = ['identity', 'amplification', 'attenuation']\n",
        "\n",
        "        self.node_emb = nn.Linear(num_features, n_hidden)\n",
        "        self.edge_emb = nn.Linear(edge_dim, n_hidden)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.emlps = nn.ModuleList()\n",
        "        self.batch_norms = nn.ModuleList()\n",
        "        for _ in range(self.num_gnn_layers):\n",
        "            conv = PNAConv(in_channels=n_hidden, out_channels=n_hidden,\n",
        "                           aggregators=aggregators, scalers=scalers, deg=deg,\n",
        "                           edge_dim=n_hidden, towers=5, pre_layers=1, post_layers=1,\n",
        "                           divide_input=False)\n",
        "            if self.edge_updates: self.emlps.append(nn.Sequential(\n",
        "                nn.Linear(3 * self.n_hidden, self.n_hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(self.n_hidden, self.n_hidden),\n",
        "            ))\n",
        "            self.convs.append(conv)\n",
        "            self.batch_norms.append(BatchNorm(n_hidden))\n",
        "\n",
        "        self.mlp = nn.Sequential(Linear(n_hidden*3, 50), nn.ReLU(), nn.Dropout(self.final_dropout),Linear(50, 25), nn.ReLU(), nn.Dropout(self.final_dropout),\n",
        "                              Linear(25, n_classes))\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        src, dst = edge_index\n",
        "\n",
        "        x = self.node_emb(x)\n",
        "        edge_attr = self.edge_emb(edge_attr)\n",
        "\n",
        "        for i in range(self.num_gnn_layers):\n",
        "            x = (x + F.relu(self.batch_norms[i](self.convs[i](x, edge_index, edge_attr)))) / 2\n",
        "            if self.edge_updates:\n",
        "                edge_attr = edge_attr + self.emlps[i](torch.cat([x[src], x[dst], edge_attr], dim=-1)) / 2\n",
        "\n",
        "        # logging.debug(f\"x.shape = {x.shape}, x[edge_index.T].shape = {x[edge_index.T].shape}\")\n",
        "        x = x[edge_index.T].reshape(-1, 2 * self.n_hidden).relu()\n",
        "        # logging.debug(f\"x.shape = {x.shape}\")\n",
        "        x = torch.cat((x, edge_attr.view(-1, edge_attr.shape[1])), 1)\n",
        "        # logging.debug(f\"x.shape = {x.shape}\")\n",
        "        out = x\n",
        "        return self.mlp(out)\n",
        "\n",
        "class RGCN(nn.Module):\n",
        "    def __init__(self, num_features, edge_dim, num_relations, num_gnn_layers, n_classes=2,\n",
        "                n_hidden=100, edge_update=False,\n",
        "                residual=True,\n",
        "                dropout=0.0, final_dropout=0.5, n_bases=-1):\n",
        "        super(RGCN, self).__init__()\n",
        "\n",
        "        self.num_features = num_features\n",
        "        self.num_gnn_layers = num_gnn_layers\n",
        "        self.n_hidden = n_hidden\n",
        "        self.residual = residual\n",
        "        self.dropout = dropout\n",
        "        self.final_dropout = final_dropout\n",
        "        self.n_classes = n_classes\n",
        "        self.edge_update = edge_update\n",
        "        self.num_relations = num_relations\n",
        "        self.n_bases = n_bases\n",
        "\n",
        "        self.node_emb = nn.Linear(num_features, n_hidden)\n",
        "        self.edge_emb = nn.Linear(edge_dim, n_hidden)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.bns = nn.ModuleList()\n",
        "        self.mlp = nn.ModuleList()\n",
        "\n",
        "        if self.edge_update:\n",
        "            self.emlps = nn.ModuleList()\n",
        "            self.emlps.append(nn.Sequential(\n",
        "                nn.Linear(3 * self.n_hidden, self.n_hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(self.n_hidden, self.n_hidden),\n",
        "            ))\n",
        "\n",
        "        for _ in range(self.num_gnn_layers):\n",
        "            conv = RGCNConv(self.n_hidden, self.n_hidden, num_relations, num_bases=self.n_bases)\n",
        "            self.convs.append(conv)\n",
        "            self.bns.append(nn.BatchNorm1d(self.n_hidden))\n",
        "\n",
        "            if self.edge_update:\n",
        "                self.emlps.append(nn.Sequential(\n",
        "                    nn.Linear(3 * self.n_hidden, self.n_hidden),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(self.n_hidden, self.n_hidden),\n",
        "                ))\n",
        "\n",
        "        self.mlp = nn.Sequential(Linear(n_hidden*3, 50), nn.ReLU(), nn.Dropout(self.final_dropout), Linear(50, 25), nn.ReLU(), nn.Dropout(self.final_dropout),\n",
        "                              Linear(25, n_classes))\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                m.reset_parameters()\n",
        "            elif isinstance(m, RGCNConv):\n",
        "                m.reset_parameters()\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                m.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        edge_type = edge_attr[:, -1].long()\n",
        "        #edge_attr = edge_attr[:, :-1]\n",
        "        src, dst = edge_index\n",
        "\n",
        "        x = self.node_emb(x)\n",
        "        edge_attr = self.edge_emb(edge_attr)\n",
        "\n",
        "        for i in range(self.num_gnn_layers):\n",
        "            x =  (x + F.relu(self.bns[i](self.convs[i](x, edge_index, edge_type)))) / 2\n",
        "            if self.edge_update:\n",
        "                edge_attr = (edge_attr + F.relu(self.emlps[i](torch.cat([x[src], x[dst], edge_attr], dim=-1)))) / 2\n",
        "\n",
        "        x = x[edge_index.T].reshape(-1, 2 * self.n_hidden).relu()\n",
        "        x = torch.cat((x, edge_attr.view(-1, edge_attr.shape[1])), 1)\n",
        "        x = self.mlp(x)\n",
        "        out = x\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "hC7xBSRtL_hi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "gaFMBjJvLtAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Utility Functions"
      ],
      "metadata": {
        "id": "gX5NIxGhMXmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AddEgoIds(BaseTransform):\n",
        "    r\"\"\"Add IDs to the centre nodes of the batch.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, data: Union[Data, HeteroData]):\n",
        "        x = data.x if not isinstance(data, HeteroData) else data['node'].x\n",
        "        device = x.device\n",
        "        ids = torch.zeros((x.shape[0], 1), device=device)\n",
        "        if not isinstance(data, HeteroData):\n",
        "            nodes = torch.unique(data.edge_label_index.view(-1)).to(device)\n",
        "        else:\n",
        "            nodes = torch.unique(data['node', 'to', 'node'].edge_label_index.view(-1)).to(device)\n",
        "        ids[nodes] = 1\n",
        "        if not isinstance(data, HeteroData):\n",
        "            data.x = torch.cat([x, ids], dim=1)\n",
        "        else:\n",
        "            data['node'].x = torch.cat([x, ids], dim=1)\n",
        "\n",
        "        return data\n",
        "\n",
        "def extract_param(parameter_name: str, args) -> float:\n",
        "    \"\"\"\n",
        "    Extract the value of the specified parameter for the given model.\n",
        "\n",
        "    Args:\n",
        "    - parameter_name (str): Name of the parameter (e.g., \"lr\").\n",
        "    - args (argparser): Arguments given to this specific run.\n",
        "\n",
        "    Returns:\n",
        "    - float: Value of the specified parameter.\n",
        "    \"\"\"\n",
        "    # file_path = './model_settings.json'\n",
        "    # with open(file_path, \"r\") as file:\n",
        "    #     data = json.load(file)\n",
        "    data = {\n",
        "      \"gin\": {\n",
        "        \"params\": {\n",
        "          \"lr\": 0.006213266113989207, \"n_hidden\": 66.00315515631006, \"n_mlp_layers\": 1, \"n_gnn_layers\": 2, \"loss\": \"ce\",\n",
        "          \"w_ce1\": 1.0000182882773443, \"w_ce2\": 6.275014431494497, \"norm_method\": \"z_normalize\", \"dropout\": 0.00983468338330501, \"final_dropout\": 0.10527690625126304\n",
        "        },\n",
        "        \"bayes_opt_params\": {\n",
        "          \"lr\": [0.002, 0.007], \"n_hidden\": [66.0, 66.01], \"n_mlp_layers\": [1, 1.001], \"n_gnn_layers\": [2.0, 2.001], \"loss\": [0.0, 0.1],\n",
        "          \"w_ce1\": [1, 1.001], \"w_ce2\": [6, 12], \"norm_method\": [0, 0.001], \"dropout\": [0, 0.05], \"final_dropout\": [0, 0.2]\n",
        "        },\n",
        "        \"header\": \"run,tb,lr,n_hidden,n_mlp_layers,n_gnn_layers,loss,w_ce1,w_ce2,norm_method,dropout,final_dropout,epoch,tr_acc,tr_prec,tr_rec,tr_f1,tr_auc,val_acc,val_prec,val_rec,val_f1,val_auc,te_acc,te_prec,te_rec,te_f1,te_auc\\n\"\n",
        "      },\n",
        "      \"pna\": {\n",
        "        \"params\": {\n",
        "          \"lr\": 0.0006116418195373612, \"n_hidden\": 20, \"n_mlp_layers\": 1, \"n_gnn_layers\": 2, \"loss\": \"ce\", \"w_ce1\": 1.0003967674742307,\n",
        "          \"w_ce2\": 7.077633468006714, \"norm_method\": \"z_normalize\", \"dropout\": 0.08340440094051481, \"final_dropout\": 0.28812979737686323\n",
        "        },\n",
        "        \"bayes_opt_params\": {\n",
        "          \"lr\": [0.0001, 0.001], \"n_hidden\": [16, 64], \"n_mlp_layers\": [1, 1.001], \"n_gnn_layers\": [2.00, 2.01], \"loss\": [0.0, 0.1],\n",
        "          \"w_ce1\": [1, 1.001], \"w_ce2\": [6, 12], \"norm_method\": [0, 0.1], \"dropout\": [0.0, 0.2], \"final_dropout\": [0.0, 0.4]\n",
        "        },\n",
        "        \"header\": \"run,tb,lr,n_hidden,n_mlp_layers,n_gnn_layers,loss,w_ce1,w_ce2,norm_method,dropout,final_dropout,epoch,tr_acc,tr_prec,tr_rec,tr_f1,tr_auc,val_acc,val_prec,val_rec,val_f1,val_auc,te_acc,te_prec,te_rec,te_f1,te_auc\\n\"\n",
        "      },\n",
        "      \"gat\": {\n",
        "        \"params\": {\n",
        "          \"lr\": 0.006, \"n_hidden\": 64, \"n_heads\": 4, \"n_mlp_layers\": 1, \"n_gnn_layers\": 2, \"loss\": \"ce\", \"w_ce1\": 1, \"w_ce2\": 6,\n",
        "          \"norm_method\": \"z_normalize\", \"dropout\": 0.009, \"final_dropout\": 0.1\n",
        "        },\n",
        "        \"bayes_opt_params\": {\n",
        "          \"lr\": [0.01, 0.04], \"n_hidden\": [4, 24], \"n_heads\": [1.5, 4.5], \"n_mlp_layers\": [1, 1.001], \"n_gnn_layers\": [3, 7],\n",
        "          \"loss\": [0, 0.1], \"w_ce1\": [1, 1.001], \"w_ce2\": [1, 10], \"norm_method\": [0, 0.1], \"dropout\": [0, 0.5], \"final_dropout\": [0, 0.8]\n",
        "        },\n",
        "        \"header\": \"run,tb,lr,n_hidden,n_heads,n_mlp_layers,n_gnn_layers,loss,w_ce1,w_ce2,norm_method,dropout,final_dropout,epoch,tr_acc,tr_prec,tr_rec,tr_f1,tr_auc,val_acc,val_prec,val_rec,val_f1,val_auc,te_acc,te_prec,te_rec,te_f1,te_auc\\n\"\n",
        "      },\n",
        "      \"mlp\": {\n",
        "        \"params\": {\n",
        "          \"lr\": 0.006213266113989207, \"n_hidden\": 66.00315515631006, \"n_mlp_layers\": 1, \"n_gnn_layers\": 2, \"loss\": \"ce\", \"w_ce1\": 1.0000182882773443,\n",
        "          \"w_ce2\": 9.23, \"norm_method\": \"z_normalize\", \"dropout\": 0.00983468338330501, \"final_dropout\": 0.10527690625126304\n",
        "        },\n",
        "        \"bayes_opt_params\": {\n",
        "          \"lr\": [0.006, 0.0064], \"n_hidden\": [66.0, 66.01], \"n_mlp_layers\": [1, 1.001], \"n_gnn_layers\": [2.0, 2.001], \"loss\": [0.0, 0.1],\n",
        "          \"w_ce1\": [1, 1.001], \"w_ce2\": [6, 12], \"norm_method\": [0, 0.001], \"dropout\": [0, 0.05], \"final_dropout\": [0, 0.2]\n",
        "        },\n",
        "        \"header\": \"run,tb,lr,n_hidden,n_mlp_layers,n_gnn_layers,loss,w_ce1,w_ce2,norm_method,dropout,final_dropout,epoch,tr_acc,tr_prec,tr_rec,tr_f1,tr_auc,val_acc,val_prec,val_rec,val_f1,val_auc,te_acc,te_prec,te_rec,te_f1,te_auc\\n\"\n",
        "      },\n",
        "      \"rgcn\": {\n",
        "        \"params\": {\n",
        "          \"lr\": 0.006213266113989207, \"n_hidden\": 66.00315515631006, \"n_mlp_layers\": 1, \"n_gnn_layers\": 2, \"loss\": \"ce\", \"w_ce1\": 1.0000182882773443,\n",
        "          \"w_ce2\": 9.23, \"norm_method\": \"z_normalize\", \"dropout\": 0.00983468338330501, \"final_dropout\": 0.10527690625126304\n",
        "        },\n",
        "        \"bayes_opt_params\": {\n",
        "          \"lr\": [0.006, 0.0064], \"n_hidden\": [66.0, 66.01], \"n_mlp_layers\": [1, 1.001], \"n_gnn_layers\": [2.0, 2.001], \"loss\": [0.0, 0.1],\n",
        "          \"w_ce1\": [1, 1.001], \"w_ce2\": [6, 12], \"norm_method\": [0, 0.001], \"dropout\": [0, 0.05], \"final_dropout\": [0, 0.2]\n",
        "        },\n",
        "        \"header\": \"run,tb,lr,n_hidden,n_mlp_layers,n_gnn_layers,loss,w_ce1,w_ce2,norm_method,dropout,final_dropout,epoch,tr_acc,tr_prec,tr_rec,tr_f1,tr_auc,val_acc,val_prec,val_rec,val_f1,val_auc,te_acc,te_prec,te_rec,te_f1,te_auc\\n\"\n",
        "      }\n",
        "    }\n",
        "\n",
        "    return data.get(args.model, {}).get(\"params\", {}).get(parameter_name, None)\n",
        "\n",
        "def add_arange_ids(data_list):\n",
        "    '''\n",
        "    Add the index as an id to the edge features to find seed edges in training, validation and testing.\n",
        "\n",
        "    Args:\n",
        "    - data_list (str): List of tr_data, val_data and te_data.\n",
        "    '''\n",
        "    for data in data_list:\n",
        "        if isinstance(data, HeteroData):\n",
        "            data['node', 'to', 'node'].edge_attr = torch.cat([torch.arange(data['node', 'to', 'node'].edge_attr.shape[0]).view(-1, 1), data['node', 'to', 'node'].edge_attr], dim=1)\n",
        "            offset = data['node', 'to', 'node'].edge_attr.shape[0]\n",
        "            data['node', 'rev_to', 'node'].edge_attr = torch.cat([torch.arange(offset, data['node', 'rev_to', 'node'].edge_attr.shape[0] + offset).view(-1, 1), data['node', 'rev_to', 'node'].edge_attr], dim=1)\n",
        "        else:\n",
        "            data.edge_attr = torch.cat([torch.arange(data.edge_attr.shape[0]).view(-1, 1), data.edge_attr], dim=1)\n",
        "\n",
        "def get_loaders(tr_data, val_data, te_data, tr_inds, val_inds, te_inds, transform, args):\n",
        "    if isinstance(tr_data, HeteroData):\n",
        "        tr_edge_label_index = tr_data['node', 'to', 'node'].edge_index\n",
        "        tr_edge_label = tr_data['node', 'to', 'node'].y\n",
        "\n",
        "\n",
        "        tr_loader =  LinkNeighborLoader(tr_data, num_neighbors=args.num_neighs,\n",
        "                                    edge_label_index=(('node', 'to', 'node'), tr_edge_label_index),\n",
        "                                    edge_label=tr_edge_label, batch_size=args.batch_size, shuffle=True, transform=transform)\n",
        "\n",
        "        val_edge_label_index = val_data['node', 'to', 'node'].edge_index[:,val_inds]\n",
        "        val_edge_label = val_data['node', 'to', 'node'].y[val_inds]\n",
        "\n",
        "\n",
        "        val_loader =  LinkNeighborLoader(val_data, num_neighbors=args.num_neighs,\n",
        "                                    edge_label_index=(('node', 'to', 'node'), val_edge_label_index),\n",
        "                                    edge_label=val_edge_label, batch_size=args.batch_size, shuffle=False, transform=transform)\n",
        "\n",
        "        te_edge_label_index = te_data['node', 'to', 'node'].edge_index[:,te_inds]\n",
        "        te_edge_label = te_data['node', 'to', 'node'].y[te_inds]\n",
        "\n",
        "\n",
        "        te_loader =  LinkNeighborLoader(te_data, num_neighbors=args.num_neighs,\n",
        "                                    edge_label_index=(('node', 'to', 'node'), te_edge_label_index),\n",
        "                                    edge_label=te_edge_label, batch_size=args.batch_size, shuffle=False, transform=transform)\n",
        "    else:\n",
        "        tr_loader =  LinkNeighborLoader(tr_data, num_neighbors=args.num_neighs, batch_size=args.batch_size, shuffle=True, transform=transform)\n",
        "        val_loader = LinkNeighborLoader(val_data,num_neighbors=args.num_neighs, edge_label_index=val_data.edge_index[:, val_inds],\n",
        "                                        edge_label=val_data.y[val_inds], batch_size=args.batch_size, shuffle=False, transform=transform)\n",
        "        te_loader =  LinkNeighborLoader(te_data,num_neighbors=args.num_neighs, edge_label_index=te_data.edge_index[:, te_inds],\n",
        "                                edge_label=te_data.y[te_inds], batch_size=args.batch_size, shuffle=False, transform=transform)\n",
        "\n",
        "    return tr_loader, val_loader, te_loader\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_homo(loader, inds, model, data, device, args):\n",
        "    '''Evaluates the model performane for homogenous graph data.'''\n",
        "    preds = []\n",
        "    ground_truths = []\n",
        "    for batch in tqdm.tqdm(loader, disable=not args.tqdm):\n",
        "        #select the seed edges from which the batch was created\n",
        "        inds = inds.detach().cpu()\n",
        "        batch_edge_inds = inds[batch.input_id.detach().cpu()]\n",
        "        batch_edge_ids = loader.data.edge_attr.detach().cpu()[batch_edge_inds, 0]\n",
        "        mask = torch.isin(batch.edge_attr[:, 0].detach().cpu(), batch_edge_ids)\n",
        "\n",
        "        #add the seed edges that have not been sampled to the batch\n",
        "        missing = ~torch.isin(batch_edge_ids, batch.edge_attr[:, 0].detach().cpu())\n",
        "\n",
        "        if missing.sum() != 0 and (args.data == 'Small_J' or args.data == 'Small_Q'):\n",
        "            missing_ids = batch_edge_ids[missing].int()\n",
        "            n_ids = batch.n_id\n",
        "            add_edge_index = data.edge_index[:, missing_ids].detach().clone()\n",
        "            node_mapping = {value.item(): idx for idx, value in enumerate(n_ids)}\n",
        "            add_edge_index = torch.tensor([[node_mapping[val.item()] for val in row] for row in add_edge_index])\n",
        "            add_edge_attr = data.edge_attr[missing_ids, :].detach().clone()\n",
        "            add_y = data.y[missing_ids].detach().clone()\n",
        "\n",
        "            batch.edge_index = torch.cat((batch.edge_index, add_edge_index), 1)\n",
        "            batch.edge_attr = torch.cat((batch.edge_attr, add_edge_attr), 0)\n",
        "            batch.y = torch.cat((batch.y, add_y), 0)\n",
        "\n",
        "            mask = torch.cat((mask, torch.ones(add_y.shape[0], dtype=torch.bool)))\n",
        "\n",
        "        #remove the unique edge id from the edge features, as it's no longer needed\n",
        "        batch.edge_attr = batch.edge_attr[:, 1:]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            batch.to(device)\n",
        "            out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
        "            out = out[mask]\n",
        "            pred = out.argmax(dim=-1)\n",
        "            preds.append(pred)\n",
        "            ground_truths.append(batch.y[mask])\n",
        "    pred = torch.cat(preds, dim=0).cpu().numpy()\n",
        "    ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "    f1 = f1_score(ground_truth, pred)\n",
        "\n",
        "    return f1\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_hetero(loader, inds, model, data, device, args):\n",
        "    '''Evaluates the model performane for heterogenous graph data.'''\n",
        "    preds = []\n",
        "    ground_truths = []\n",
        "    for batch in tqdm.tqdm(loader, disable=not args.tqdm):\n",
        "        #select the seed edges from which the batch was created\n",
        "        inds = inds.detach().cpu()\n",
        "        batch_edge_inds = inds[batch['node', 'to', 'node'].input_id.detach().cpu()]\n",
        "        batch_edge_ids = loader.data['node', 'to', 'node'].edge_attr.detach().cpu()[batch_edge_inds, 0]\n",
        "        mask = torch.isin(batch['node', 'to', 'node'].edge_attr[:, 0].detach().cpu(), batch_edge_ids)\n",
        "\n",
        "        #add the seed edges that have not been sampled to the batch\n",
        "        missing = ~torch.isin(batch_edge_ids, batch['node', 'to', 'node'].edge_attr[:, 0].detach().cpu())\n",
        "\n",
        "        if missing.sum() != 0 and (args.data == 'Small_J' or args.data == 'Small_Q'):\n",
        "            missing_ids = batch_edge_ids[missing].int()\n",
        "            n_ids = batch['node'].n_id\n",
        "            add_edge_index = data['node', 'to', 'node'].edge_index[:, missing_ids].detach().clone()\n",
        "            node_mapping = {value.item(): idx for idx, value in enumerate(n_ids)}\n",
        "            add_edge_index = torch.tensor([[node_mapping[val.item()] for val in row] for row in add_edge_index])\n",
        "            add_edge_attr = data['node', 'to', 'node'].edge_attr[missing_ids, :].detach().clone()\n",
        "            add_y = data['node', 'to', 'node'].y[missing_ids].detach().clone()\n",
        "\n",
        "            batch['node', 'to', 'node'].edge_index = torch.cat((batch['node', 'to', 'node'].edge_index, add_edge_index), 1)\n",
        "            batch['node', 'to', 'node'].edge_attr = torch.cat((batch['node', 'to', 'node'].edge_attr, add_edge_attr), 0)\n",
        "            batch['node', 'to', 'node'].y = torch.cat((batch['node', 'to', 'node'].y, add_y), 0)\n",
        "\n",
        "            mask = torch.cat((mask, torch.ones(add_y.shape[0], dtype=torch.bool)))\n",
        "\n",
        "        #remove the unique edge id from the edge features, as it's no longer needed\n",
        "        batch['node', 'to', 'node'].edge_attr = batch['node', 'to', 'node'].edge_attr[:, 1:]\n",
        "        batch['node', 'rev_to', 'node'].edge_attr = batch['node', 'rev_to', 'node'].edge_attr[:, 1:]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            batch.to(device)\n",
        "            out = model(batch.x_dict, batch.edge_index_dict, batch.edge_attr_dict)\n",
        "            out = out[('node', 'to', 'node')]\n",
        "            out = out[mask]\n",
        "            pred = out.argmax(dim=-1)\n",
        "            preds.append(pred)\n",
        "            ground_truths.append(batch['node', 'to', 'node'].y[mask])\n",
        "    pred = torch.cat(preds, dim=0).cpu().numpy()\n",
        "    ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "    f1 = f1_score(ground_truth, pred)\n",
        "\n",
        "    return f1\n",
        "\n",
        "def save_model(model, optimizer, epoch, args, data_config):\n",
        "    # Save the model in a dictionary\n",
        "    torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict()\n",
        "                }, f'{data_config[\"paths\"][\"model_to_save\"]}/checkpoint_{args.unique_name}{\"\" if not args.finetune else \"_finetuned\"}.tar')\n",
        "\n",
        "def load_model(model, device, args, config, data_config):\n",
        "    checkpoint = torch.load(f'{data_config[\"paths\"][\"model_to_load\"]}/checkpoint_{args.unique_name}.tar')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    return model, optimizer"
      ],
      "metadata": {
        "id": "CJplEY-fMcMp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Workflow"
      ],
      "metadata": {
        "id": "p5OZsbTLMZg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_homo(tr_loader, val_loader, te_loader, tr_inds, val_inds, te_inds, model, optimizer, loss_fn, args, config, device, val_data, te_data, data_config):\n",
        "    #training\n",
        "    best_val_f1 = 0\n",
        "    for epoch in range(config.epochs):\n",
        "        total_loss = total_examples = 0\n",
        "        preds = []\n",
        "        ground_truths = []\n",
        "        for batch in tqdm.tqdm(tr_loader, disable=not args.tqdm):\n",
        "            optimizer.zero_grad()\n",
        "            #select the seed edges from which the batch was created\n",
        "            inds = tr_inds.detach().cpu()\n",
        "            batch_edge_inds = inds[batch.input_id.detach().cpu()]\n",
        "            batch_edge_ids = tr_loader.data.edge_attr.detach().cpu()[batch_edge_inds, 0]\n",
        "            mask = torch.isin(batch.edge_attr[:, 0].detach().cpu(), batch_edge_ids)\n",
        "\n",
        "            #remove the unique edge id from the edge features, as it's no longer needed\n",
        "            batch.edge_attr = batch.edge_attr[:, 1:]\n",
        "\n",
        "            batch.to(device)\n",
        "            out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
        "            pred = out[mask]\n",
        "            ground_truth = batch.y[mask]\n",
        "            preds.append(pred.argmax(dim=-1))\n",
        "            ground_truths.append(ground_truth)\n",
        "            loss = loss_fn(pred, ground_truth)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += float(loss) * pred.numel()\n",
        "            total_examples += pred.numel()\n",
        "\n",
        "        pred = torch.cat(preds, dim=0).detach().cpu().numpy()\n",
        "        ground_truth = torch.cat(ground_truths, dim=0).detach().cpu().numpy()\n",
        "        f1 = f1_score(ground_truth, pred)\n",
        "        # wandb.log({\"f1/train\": f1}, step=epoch)\n",
        "        print(f'Train F1: {f1:.4f}')\n",
        "\n",
        "        #evaluate\n",
        "        val_f1 = evaluate_homo(val_loader, val_inds, model, val_data, device, args)\n",
        "        te_f1 = evaluate_homo(te_loader, te_inds, model, te_data, device, args)\n",
        "\n",
        "        # wandb.log({\"f1/validation\": val_f1}, step=epoch)\n",
        "        # wandb.log({\"f1/test\": te_f1}, step=epoch)\n",
        "        print(f'Validation F1: {val_f1:.4f}')\n",
        "        print(f'Test F1: {te_f1:.4f}')\n",
        "\n",
        "        if epoch == 0:\n",
        "            print({\"best_test_f1\": te_f1})\n",
        "        elif val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            print({\"best_test_f1\": te_f1})\n",
        "            if args.save_model:\n",
        "                save_model(model, optimizer, epoch, args, data_config)\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_hetero(tr_loader, val_loader, te_loader, tr_inds, val_inds, te_inds, model, optimizer, loss_fn, args, config, device, val_data, te_data, data_config):\n",
        "    #training\n",
        "    best_val_f1 = 0\n",
        "    for epoch in range(config.epochs):\n",
        "        total_loss = total_examples = 0\n",
        "        preds = []\n",
        "        ground_truths = []\n",
        "        for batch in tqdm.tqdm(tr_loader, disable=not args.tqdm):\n",
        "            optimizer.zero_grad()\n",
        "            #select the seed edges from which the batch was created\n",
        "            inds = tr_inds.detach().cpu()\n",
        "            batch_edge_inds = inds[batch['node', 'to', 'node'].input_id.detach().cpu()]\n",
        "            batch_edge_ids = tr_loader.data['node', 'to', 'node'].edge_attr.detach().cpu()[batch_edge_inds, 0]\n",
        "            mask = torch.isin(batch['node', 'to', 'node'].edge_attr[:, 0].detach().cpu(), batch_edge_ids)\n",
        "\n",
        "            #remove the unique edge id from the edge features, as it's no longer needed\n",
        "            batch['node', 'to', 'node'].edge_attr = batch['node', 'to', 'node'].edge_attr[:, 1:]\n",
        "            batch['node', 'rev_to', 'node'].edge_attr = batch['node', 'rev_to', 'node'].edge_attr[:, 1:]\n",
        "\n",
        "            batch.to(device)\n",
        "            out = model(batch.x_dict, batch.edge_index_dict, batch.edge_attr_dict)\n",
        "            out = out[('node', 'to', 'node')]\n",
        "            pred = out[mask]\n",
        "            ground_truth = batch['node', 'to', 'node'].y[mask]\n",
        "            preds.append(pred.argmax(dim=-1))\n",
        "            ground_truths.append(batch['node', 'to', 'node'].y[mask])\n",
        "            loss = loss_fn(pred, ground_truth)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += float(loss) * pred.numel()\n",
        "            total_examples += pred.numel()\n",
        "\n",
        "        pred = torch.cat(preds, dim=0).detach().cpu().numpy()\n",
        "        ground_truth = torch.cat(ground_truths, dim=0).detach().cpu().numpy()\n",
        "        f1 = f1_score(ground_truth, pred)\n",
        "        # wandb.log({\"f1/train\": f1}, step=epoch)\n",
        "        print(f'Train F1: {f1:.4f}')\n",
        "\n",
        "        #evaluate\n",
        "        val_f1 = evaluate_hetero(val_loader, val_inds, model, val_data, device, args)\n",
        "        te_f1 = evaluate_hetero(te_loader, te_inds, model, te_data, device, args)\n",
        "\n",
        "        # wandb.log({\"f1/validation\": val_f1}, step=epoch)\n",
        "        # wandb.log({\"f1/test\": te_f1}, step=epoch)\n",
        "        print(f'Validation F1: {val_f1:.4f}')\n",
        "        print(f'Test F1: {te_f1:.4f}')\n",
        "\n",
        "        if epoch == 0:\n",
        "            print({\"best_test_f1\": te_f1})\n",
        "        elif val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            print({\"best_test_f1\": te_f1})\n",
        "            if args.save_model:\n",
        "                save_model(model, optimizer, epoch, args, data_config)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "7PwAL8s4NG2C"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(sample_batch, config, args):\n",
        "    n_feats = sample_batch.x.shape[1] if not isinstance(sample_batch, HeteroData) else sample_batch['node'].x.shape[1]\n",
        "    e_dim = (sample_batch.edge_attr.shape[1] - 1) if not isinstance(sample_batch, HeteroData) else (sample_batch['node', 'to', 'node'].edge_attr.shape[1] - 1)\n",
        "\n",
        "    if args.model == \"gin\":\n",
        "        model = GINe(\n",
        "                num_features=n_feats, num_gnn_layers=config.n_gnn_layers, n_classes=2,\n",
        "                n_hidden=round(config.n_hidden), residual=False, edge_updates=args.emlps, edge_dim=e_dim,\n",
        "                dropout=config.dropout, final_dropout=config.final_dropout\n",
        "                )\n",
        "    elif args.model == \"gat\":\n",
        "        model = GATe(\n",
        "                num_features=n_feats, num_gnn_layers=config.n_gnn_layers, n_classes=2,\n",
        "                n_hidden=round(config.n_hidden), n_heads=round(config.n_heads),\n",
        "                edge_updates=args.emlps, edge_dim=e_dim,\n",
        "                dropout=config.dropout, final_dropout=config.final_dropout\n",
        "                )\n",
        "    elif args.model == \"pna\":\n",
        "        if not isinstance(sample_batch, HeteroData):\n",
        "            d = degree(sample_batch.edge_index[1], dtype=torch.long)\n",
        "        else:\n",
        "            index = torch.cat((sample_batch['node', 'to', 'node'].edge_index[1], sample_batch['node', 'rev_to', 'node'].edge_index[1]), 0)\n",
        "            d = degree(index, dtype=torch.long)\n",
        "        deg = torch.bincount(d, minlength=1)\n",
        "        model = PNA(\n",
        "            num_features=n_feats, num_gnn_layers=config.n_gnn_layers, n_classes=2,\n",
        "            n_hidden=round(config.n_hidden), edge_updates=args.emlps, edge_dim=e_dim,\n",
        "            dropout=config.dropout, deg=deg, final_dropout=config.final_dropout\n",
        "            )\n",
        "    elif config.model == \"rgcn\":\n",
        "        model = RGCN(\n",
        "            num_features=n_feats, edge_dim=e_dim, num_relations=8, num_gnn_layers=round(config.n_gnn_layers),\n",
        "            n_classes=2, n_hidden=round(config.n_hidden),\n",
        "            edge_update=args.emlps, dropout=config.dropout, final_dropout=config.final_dropout, n_bases=None #(maybe)\n",
        "        )\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_gnn(tr_data, val_data, te_data, tr_inds, val_inds, te_inds, args, data_config):\n",
        "    #set device\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    config = SimpleNamespace(\n",
        "        epochs=args.n_epochs,\n",
        "        batch_size=args.batch_size,\n",
        "        model=args.model,\n",
        "        data=args.data,\n",
        "        num_neighbors=args.num_neighs,\n",
        "\n",
        "        lr=extract_param(\"lr\", args),\n",
        "        n_hidden=extract_param(\"n_hidden\", args),\n",
        "        n_gnn_layers=extract_param(\"n_gnn_layers\", args),\n",
        "\n",
        "        loss=\"ce\",\n",
        "        w_ce1=extract_param(\"w_ce1\", args),\n",
        "        w_ce2=extract_param(\"w_ce2\", args),\n",
        "\n",
        "        dropout=extract_param(\"dropout\", args),\n",
        "        final_dropout=extract_param(\"final_dropout\", args),\n",
        "        n_heads=extract_param(\"n_heads\", args) if args.model == 'gat' else None\n",
        "    )\n",
        "    # config={\n",
        "    #     \"epochs\": args.n_epochs,\n",
        "    #     \"batch_size\": args.batch_size,\n",
        "    #     \"model\": args.model,\n",
        "    #     \"data\": args.data,\n",
        "    #     \"num_neighbors\": args.num_neighs,\n",
        "    #     \"lr\": extract_param(\"lr\", args),\n",
        "    #     \"n_hidden\": extract_param(\"n_hidden\", args),\n",
        "    #     \"n_gnn_layers\": extract_param(\"n_gnn_layers\", args),\n",
        "    #     \"loss\": \"ce\",\n",
        "    #     \"w_ce1\": extract_param(\"w_ce1\", args),\n",
        "    #     \"w_ce2\": extract_param(\"w_ce2\", args),\n",
        "    #     \"dropout\": extract_param(\"dropout\", args),\n",
        "    #     \"final_dropout\": extract_param(\"final_dropout\", args),\n",
        "    #     \"n_heads\": extract_param(\"n_heads\", args) if args.model == 'gat' else None\n",
        "    # }\n",
        "\n",
        "    #set the transform if ego ids should be used\n",
        "    if args.ego:\n",
        "        transform = AddEgoIds()\n",
        "    else:\n",
        "        transform = None\n",
        "\n",
        "    #add the unique ids to later find the seed edges\n",
        "    add_arange_ids([tr_data, val_data, te_data])\n",
        "\n",
        "    tr_loader, val_loader, te_loader = get_loaders(tr_data, val_data, te_data, tr_inds, val_inds, te_inds, transform, args)\n",
        "\n",
        "    #get the model\n",
        "    sample_batch = next(iter(tr_loader))\n",
        "    model = get_model(sample_batch, config, args)\n",
        "\n",
        "    if args.reverse_mp:\n",
        "        model = to_hetero(model, te_data.metadata(), aggr='mean')\n",
        "\n",
        "    if args.finetune:\n",
        "        model, optimizer = load_model(model, device, args, config, data_config)\n",
        "    else:\n",
        "        model.to(device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
        "\n",
        "    sample_batch.to(device)\n",
        "    sample_x = sample_batch.x if not isinstance(sample_batch, HeteroData) else sample_batch.x_dict\n",
        "    sample_edge_index = sample_batch.edge_index if not isinstance(sample_batch, HeteroData) else sample_batch.edge_index_dict\n",
        "    if isinstance(sample_batch, HeteroData):\n",
        "        sample_batch['node', 'to', 'node'].edge_attr = sample_batch['node', 'to', 'node'].edge_attr[:, 1:]\n",
        "        sample_batch['node', 'rev_to', 'node'].edge_attr = sample_batch['node', 'rev_to', 'node'].edge_attr[:, 1:]\n",
        "    else:\n",
        "        sample_batch.edge_attr = sample_batch.edge_attr[:, 1:]\n",
        "    sample_edge_attr = sample_batch.edge_attr if not isinstance(sample_batch, HeteroData) else sample_batch.edge_attr_dict\n",
        "    print(summary(model, sample_x, sample_edge_index, sample_edge_attr))\n",
        "\n",
        "    loss_fn = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor([config.w_ce1, config.w_ce2]).to(device))\n",
        "\n",
        "    if args.reverse_mp:\n",
        "        model = train_hetero(tr_loader, val_loader, te_loader, tr_inds, val_inds, te_inds, model, optimizer, loss_fn, args, config, device, val_data, te_data, data_config)\n",
        "    else:\n",
        "        model = train_homo(tr_loader, val_loader, te_loader, tr_inds, val_inds, te_inds, model, optimizer, loss_fn, args, config, device, val_data, te_data, data_config)\n",
        "\n",
        "    # wandb.finish()"
      ],
      "metadata": {
        "id": "c2Z2JC9RKpeq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_config = {\n",
        "  \"paths\": {\n",
        "    \"aml_data\": \"/path/to/aml_data\",\n",
        "    \"model_to_load\": \"/path/to/model_you_want_to_load (e.g for inference or fine-tuning)\",\n",
        "    \"model_to_save\": \"/path/to/model_save_location (where you want to store the model you are going to train)\"\n",
        "  }\n",
        "}\n",
        "\n",
        "train_gnn(tr_data, val_data, te_data, tr_inds, val_inds, te_inds, args, data_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBqvM7elK6B-",
        "outputId": "b0107878-05c1-4170-b3fe-d3daf25d303a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------+--------------------------------------+----------------+----------+\n",
            "| Layer                           | Input Shape                          | Output Shape   | #Param   |\n",
            "|---------------------------------+--------------------------------------+----------------+----------|\n",
            "| GINe                            | [30422, 1], [2, 80212], [80212, 8]   | [80212, 2]     | 38,799   |\n",
            "| ├─(node_emb)Linear              | [30422, 1]                           | [30422, 66]    | 132      |\n",
            "| ├─(edge_emb)Linear              | [80212, 8]                           | [80212, 66]    | 594      |\n",
            "| ├─(convs)ModuleList             | --                                   | --             | 26,532   |\n",
            "| │    └─(0)GINEConv              | [30422, 66], [2, 80212], [80212, 66] | [30422, 66]    | 13,266   |\n",
            "| │    └─(1)GINEConv              | [30422, 66], [2, 80212], [80212, 66] | [30422, 66]    | 13,266   |\n",
            "| ├─(emlps)ModuleList             | --                                   | --             | --       |\n",
            "| ├─(batch_norms)ModuleList       | --                                   | --             | 264      |\n",
            "| │    └─(0)BatchNorm             | [30422, 66]                          | [30422, 66]    | 132      |\n",
            "| │    │    └─(module)BatchNorm1d | [30422, 66]                          | [30422, 66]    | 132      |\n",
            "| │    └─(1)BatchNorm             | [30422, 66]                          | [30422, 66]    | 132      |\n",
            "| │    │    └─(module)BatchNorm1d | [30422, 66]                          | [30422, 66]    | 132      |\n",
            "| ├─(mlp)Sequential               | [80212, 198]                         | [80212, 2]     | 11,277   |\n",
            "| │    └─(0)Linear                | [80212, 198]                         | [80212, 50]    | 9,950    |\n",
            "| │    └─(1)ReLU                  | [80212, 50]                          | [80212, 50]    | --       |\n",
            "| │    └─(2)Dropout               | [80212, 50]                          | [80212, 50]    | --       |\n",
            "| │    └─(3)Linear                | [80212, 50]                          | [80212, 25]    | 1,275    |\n",
            "| │    └─(4)ReLU                  | [80212, 25]                          | [80212, 25]    | --       |\n",
            "| │    └─(5)Dropout               | [80212, 25]                          | [80212, 25]    | --       |\n",
            "| │    └─(6)Linear                | [80212, 25]                          | [80212, 2]     | 52       |\n",
            "+---------------------------------+--------------------------------------+----------------+----------+\n",
            "Train F1: 0.0013\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "{'best_test_f1': 0.0}\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n",
            "Train F1: 0.0000\n",
            "Validation F1: 0.0000\n",
            "Test F1: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "730oj-NFONiK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}