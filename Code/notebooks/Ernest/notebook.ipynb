{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta, datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/test.csv\")\n",
    "data.rename(columns={\"Account\": \"From Account\", \"Account.1\": \"To Account\"}, inplace=True)\n",
    "\n",
    "# Extract relevant columns\n",
    "from_accounts = data['From Account']\n",
    "to_accounts = data['To Account']\n",
    "amount_paid = data['Amount Paid']\n",
    "\n",
    "# Map account IDs to unique indices\n",
    "account_map = {account: idx for idx, account in enumerate(set(from_accounts) | set(to_accounts))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate edge index using the mapped account indices\n",
    "edge_index = torch.tensor([[account_map[from_account], account_map[to_account]] \n",
    "                           for from_account, to_account in zip(from_accounts, to_accounts)], dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Generate edge-level features (amount paid)\n",
    "edge_amounts = torch.tensor(data['Amount Paid'].values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Construct node features based on total transaction amount per node (as before)\n",
    "node_features = {}\n",
    "for node in account_map.values():\n",
    "    node_features[node] = sum([edge_amounts[i] for i, (u, v) in enumerate(zip(from_accounts, to_accounts)) if account_map[u] == node or account_map[v] == node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert node features to tensor\n",
    "node_feature_values = list(node_features.values())\n",
    "node_features_tensor = torch.tensor(node_feature_values, dtype=torch.float).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([17051, 1]), torch.Size([2, 10000]), torch.Size([10000]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add labels (Is Laundering) as target\n",
    "labels = torch.tensor(data['Is Laundering'].values, dtype=torch.float)\n",
    "\n",
    "# Construct graph data for PyTorch Geometric\n",
    "from torch_geometric.data import Data\n",
    "graph_data = Data(x=node_features_tensor, edge_index=edge_index, edge_attr=edge_amounts, y=labels)\n",
    "\n",
    "# Check the shapes of the generated data\n",
    "graph_data.x.shape, graph_data.edge_index.shape, graph_data.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test mask based on number of nodes (data.y length)\n",
    "num_nodes = graph_data.x.shape[0]\n",
    "train_mask, test_mask = train_test_split(range(num_nodes), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create masks for train and test sets\n",
    "graph_data.train_mask = torch.tensor(train_mask, dtype=torch.bool)\n",
    "graph_data.test_mask = torch.tensor(test_mask, dtype=torch.bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GNN model\n",
    "class SimpleGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SimpleGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "        self.fc = nn.Linear(output_dim, 1)  # Binary output (money laundering or not)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Training the model\n",
    "def train_model(data, model, criterion, optimizer, epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output[data.train_mask].squeeze(), data.y[data.train_mask].float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "def test_model(model, data):\n",
    "    model.eval()  # Switch to evaluation mode\n",
    "    with torch.no_grad():  # No gradients are needed during testing\n",
    "        output = model(data)\n",
    "        # Apply sigmoid to get probabilities\n",
    "        pred = torch.sigmoid(output[data.test_mask].squeeze())\n",
    "        # Calculate accuracy\n",
    "        correct = (pred.round() == data.y[data.test_mask].float()).sum()\n",
    "        accuracy = correct / len(data.y[data.test_mask])\n",
    "        print(f\"Test Accuracy: {accuracy.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "input_dim = node_features_tensor.shape[1]\n",
    "hidden_dim = 16\n",
    "output_dim = 8\n",
    "model = SimpleGNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [13640] at index 0 does not match the shape of the indexed tensor [17051, 1] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[43], line 25\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(data, model, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     24\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[0;32m---> 25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(\u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(), data\u001b[38;5;241m.\u001b[39my[data\u001b[38;5;241m.\u001b[39mtrain_mask]\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [13640] at index 0 does not match the shape of the indexed tensor [17051, 1] at index 0"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(graph_data, model, criterion, optimizer, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "test_model(model, graph_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add edges based on From Account -> To Account\n",
    "for i in range(len(from_accounts)):\n",
    "    G.add_edge(from_accounts[i], to_accounts[i], amount=amount_paid[i])\n",
    "\n",
    "# Generate node-level features (for simplicity, we'll use the total amount involved in transactions as a feature)\n",
    "node_features = {}\n",
    "for node in G.nodes():\n",
    "    # Sum of transaction amounts related to each node\n",
    "    node_features[node] = sum([G[u][v]['amount'] for u, v in G.in_edges(node)] + \n",
    "                              [G[u][v]['amount'] for u, v in G.out_edges(node)])\n",
    "\n",
    "# Convert node features to tensor\n",
    "node_feature_values = list(node_features.values())\n",
    "node_features_tensor = torch.tensor(node_feature_values, dtype=torch.float).view(-1, 1)\n",
    "\n",
    "# Generate edge-level features (amount paid)\n",
    "edges = list(G.edges())\n",
    "edge_index = torch.tensor([[from_accounts.tolist().index(u), from_accounts.tolist().index(v)] for u, v in edges], dtype=torch.long).t().contiguous()\n",
    "edge_amounts = [G[u][v]['amount'] for u, v in edges]\n",
    "edge_features = torch.tensor(edge_amounts, dtype=torch.float)\n",
    "\n",
    "# Add labels (Is Laundering) as target\n",
    "labels = torch.tensor(data['Is Laundering'].values, dtype=torch.float)\n",
    "\n",
    "# Construct graph data for PyTorch Geometric\n",
    "from torch_geometric.data import Data\n",
    "graph_data = Data(x=node_features_tensor, edge_index=edge_index, edge_attr=edge_features, y=labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
